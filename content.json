{"meta":{"title":"AIR","subtitle":"A research team studying artificial intelligence","description":"AIR","author":"AIR@USC","url":"http://uscair.club","root":"/"},"pages":[{"title":"关于","date":"2020-02-06T08:22:15.191Z","updated":"2020-02-06T08:22:15.191Z","comments":true,"path":"about/index.html","permalink":"http://uscair.club/about/index.html","excerpt":"","text":"AIR@USCContact Address: the University of South China - 28 Changsheng West Road- Hunan, China E-mail: airusc@foxmail.com QQ：3458038461 Blog: https://uscair.club Introduction:A professional team studying artificial intelligence and robotics Instructor:Dr. Mao Yu Honor One First Prize &amp; Two Third Prizes, [The 15th Hunan University Student Computer Program Design Competition] Aug. 2019 One Second Prize &amp; Three Third Prizes,[“Soft Silver Robot Cup” China robot skill competition] Dec. 2018 EssayGrade 16 Qiu Zhongxi published EI paper as first author"},{"title":"所有分类","date":"2020-02-06T08:16:28.355Z","updated":"2020-02-06T08:16:28.355Z","comments":true,"path":"categories/index.html","permalink":"http://uscair.club/categories/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2020-02-06T08:17:31.100Z","updated":"2020-02-06T08:17:31.100Z","comments":true,"path":"tags/index.html","permalink":"http://uscair.club/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"OpenCV—Python:（三）绘制几何形状","slug":"OpenCV——Python_(三）绘制几何形状","date":"2020-03-29T14:51:40.984Z","updated":"2020-03-29T14:51:40.984Z","comments":true,"path":"2020/03/29/OpenCV——Python_(三）绘制几何形状/","link":"","permalink":"http://uscair.club/2020/03/29/OpenCV%E2%80%94%E2%80%94Python_(%E4%B8%89%EF%BC%89%E7%BB%98%E5%88%B6%E5%87%A0%E4%BD%95%E5%BD%A2%E7%8A%B6/","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#-*- coding:utf-8 -*-import numpy as npimport cv2 as cv#draw line#Create a black imageimg=np.zeros((512,512,3),np.uint8) #(512,512,3)前两个参数代表建立图像大小,第一个是高，第二个是长，3代表RGB通道，可以出现彩色图像 #1是默认值，为灰度图像#Draw a diagonal blue line with thickness of 5 px'''cv :: line（InputOutputArray img,Point pt1,Point pt2,const Scalar＆color,int thickness = 1,int lineType = LINE_8,int shift = 0） 绘制连接两个点的线段.'''# IMG 图片。# PT1 线段的第一点。# PT2 线段的第二点。# 颜色 线条颜色。# 厚度 线的粗细。# 线型 线的类型。请参见LineTypes。# 转移 点坐标中的小数位数。cv.line(img,(0,0),(511,511),(255,0,0),5)#cv.imshow(\"Line\",img)#Draw a rectanglecv.rectangle(img,(384,0),(510,128),(0,255,0),3)#cv.imshow(\"Rectangel\",img)#Draw a circlecv.circle(img,(384+63,64),63,(255,255,255),2)#Draw an ellipse#img=cv.ellipse(img, center, axes, angle, startAngle, endAngle, color[, thickness[, lineType[, shift]]] )# img 图片。# center 椭圆的中心。# axes 椭圆主轴大小的一半。# angle 椭圆旋转角度（以度为单位)，顺时针方向旋转# startAngle 椭圆弧的起始角度（以度为单位）。# endAngle 椭圆弧的终止角度（以度为单位）。# color 椭圆颜色。# thickness 椭圆弧的轮廓粗细，如果是正的。否则，这表示将绘制填充的椭圆扇区。# lineType 椭圆边界的类型。# shift 中心坐标和轴值的小数位数。cv.ellipse(img,(256,256),(100,50),0,0,180,(255,255,255),-1)#Drawing Polygonpts=np.array([[10,5],[20,30],[70,20],[50,10]],np.int32)pts=pts.reshape((-1,1,2))cv.polylines(img,[pts],1,(0,255,255))#如果第三个参数为False，您将获得连接所有点的折线，而不是闭合形状。#Adding Text to Images# img = cv.putText( img, text, org, fontFace, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]] )# img 图片。# text 要绘制的文本字符串。# org 图像中文本字符串的左下角。# fontFace 字体类型，请参阅HersheyFonts。# fontScale 字体比例因子乘以字体特定的基本大小。# color 文字颜色# thickness 用于绘制文本的线条的粗细。# lineType 线型。请参见LineTypes# bottomLeftOrigin 如果为true，则图像数据原点位于左下角。否则，它位于左上角。font=cv.FONT_HERSHEY_SIMPLEXcv.putText(img,\"OpenCV\",(10,450),font,4,(255,255,0),2,cv.LINE_AA)cv.imshow(\"Img\",img)cv.waitKey(0)","categories":[{"name":"数字图像处理","slug":"数字图像处理","permalink":"http://uscair.club/categories/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://uscair.club/tags/OpenCV/"}],"author":{"name":"Adans"}},{"title":"机器学习基础（1）","slug":"机器学习基础(1)","date":"2020-03-29T14:13:16.740Z","updated":"2020-03-29T14:13:16.740Z","comments":true,"path":"2020/03/29/机器学习基础(1)/","link":"","permalink":"http://uscair.club/2020/03/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80(1)/","excerpt":"","text":"关于机器学习的定义（用英文会好一点）：1.Arthur Samuel:Field of study that gives computers the ability to learn without explicitly programmed. 2.Tom Mitchell:A computer program is said to learn from experience E with respect to some task T and some performance measure P,if its performance on T,as measured by P,improves with experient E. Supervised Learning(监督学习):监督学习大致分为两类：1.Regression (回归) 2. Classify(分类) 一般使用的算法：1. K-近邻算法（k-Nearest Neighbors，KNN）K-近邻是一种分类算法，其思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。K通常是不大于20的整数。KNN算法中，所选择的邻居都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。 2.决策树（Decision Trees）决策树是一个树结构（可以是二叉树或非二叉树）。其每个非叶节点表示一个特征属性上的测试，每个分支代表这个特征属性在某个值域上的输出，而每个叶节点存放一个类别。使用决策树进行决策的过程就是从根节点开始，测试待分类项中相应的特征属性，并按照其值选择输出分支，直到到达叶子节点，将叶子节点存放的类别作为决策结果。 3. 朴素贝叶斯（Naive Bayesian）贝叶斯分类是一系列分类算法的总称，这类算法均以贝叶斯定理为基础，故统称为贝叶斯分类。朴素贝叶斯算法（Naive Bayesian) 是其中应用最为广泛的分类算法之一。朴素贝叶斯分类器基于一个简单的假定：给定目标值时属性之间相互条件独立。朴素贝叶斯的基本思想是对于给出的待分类项，求解在此项出现的条件下各个类别出现的概率，哪个最大，就认为此待分类项属于哪个类别。 4.逻辑回归（Logistic Regression）我们知道，线性回归就是根据已知数据集求一线性函数，使其尽可能拟合数据，让损失函数最小，常用的线性回归最优法有最小二乘法和梯度下降法。 Unsupervised Learning(无监督学习):不会提前知道什么是正确的的,而是让计算机通过分析数据,得到该有的规律 一般采用的算法:1. K均值聚类算法: k均值聚类算法（k-means clustering algorithm）是一种迭代求解的聚类分析算法，其步骤是，预将数据分为K组，则随机选取K个对象作为初始的聚类中心，然后计算每个对象与各个种子聚类中心之间的距离，把每个对象分配给距离它最近的聚类中心。k均值聚类是使用最大期望算法（Expectation-Maximization algorithm）求解的高斯混合模型（Gaussian Mixture Model, GMM）在正态分布的协方差为单位矩阵，且隐变量的后验分布为一组狄拉克δ函数时所得到的特例 2.谱聚类算法谱聚类算法建立在谱图理论基础上，与传统的聚类算法相比，它具有能在任意形状的样本空间上聚类且收敛于全局最优解的优点。该算法首先根据给定的样本数据集定义一个描述成对数据点相似度的亲合矩阵,并且计算矩阵的特征值和特征向量 ， 然后选择合适 的特征向量聚类不同的数据点。谱聚类算法建立在图论中的谱图理论基础上，其本质是将聚类问题转化为图的最优划分问题，是一种点对聚类算法 3.Principal Component Analysis(PCA,主成分分析)主成分分析是一种统计方法。通过正交变换将一组可能存在相关性的变量转换为一组线性不相关的变量，转换后的这组变量叫主成分。 关于监督学习的概括引用自CSDN「小白的进阶」的原创文章 阅读原文请pick-&gt; https://blog.csdn.net/laobai1015/article/details/75006511","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://uscair.club/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://uscair.club/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"author":{"name":"o140"}},{"title":"Opencv——Python","slug":"OpenCV——操作","date":"2020-03-29T14:05:40.000Z","updated":"2020-03-29T14:05:40.000Z","comments":true,"path":"2020/03/29/OpenCV——操作/","link":"","permalink":"http://uscair.club/2020/03/29/OpenCV%E2%80%94%E2%80%94%E6%93%8D%E4%BD%9C/","excerpt":"","text":"OpenCV——操作今天我们来详细介绍一下这两个互为冤家的函数，split函数和merge函数详细请看https://blog.csdn.net/poem_qianmo/article/details/21176257 分离颜色通道1.split函数将一个多通道数组分离成几个单通道数组。split函数分割多通道数组转换成独立的单通道数组，按公式来看就是这样：代码示例 123456789101112Mat srcImage;Mat imageROI;vector&lt;Mat&gt; channels;srcImage= cv::imread(\"dota.jpg\");// 把一个3通道图像转换成3个单通道图像split(srcImage,channels);//分离色彩通道 imageROI=channels.at(0); addWeighted(imageROI(Rect(385,250,logoImage.cols,logoImage.rows)),1.0, logoImage,0.5,0.,imageROI(Rect(385,250,logoImage.cols,logoImage.rows))); merge(channels,srcImage4); namedWindow(\"sample\"); imshow(\"sample\",srcImage); 1.merge函数merge()函数的功能是split()函数的逆向操作，将多个数组组合合并成一个多通道的数组。它通过组合一些给定的单通道数组，将这些孤立的单通道数组合并成一个多通道的数组，从而创建出一个由多个单通道阵列组成的多通道阵列。 函数解析：merge函数的功能是将一些数组合并成一个多通道的数组。关于组合的细节，输出矩阵中的每个元素都将是输出数组的串接，其中，第i个输入数组的元素被视为mv[i]。 c一般用其中的Mat::at（）方法对某个通道进行存取,也就是这样用channels.at(0)。 PS: Mat::at（）方法，返回一个引用到指定的数组元素。注意是引用，相当于两者等价，修改其中一个另一个跟着变. 代码示例 12345678910vector&lt;Mat&gt; channels;Mat imageBlueChannel;Mat imageGreenChannel;Mat imageRedChannel;srcImage4= imread(\"dota.jpg\");// 把一个3通道图像转换成3个单通道图像split(srcImage4,channels);//分离色彩通道imageBlueChannel = channels.at(0);imageGreenChannel = channels.at(1);imageRedChannel = channels.at(2);","categories":[{"name":"数字图像处理","slug":"数字图像处理","permalink":"http://uscair.club/categories/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://uscair.club/tags/OpenCV/"}],"author":{"name":"You_shuangshuang"}},{"title":"python程序代码理解","slug":"python程序代码理解","date":"2020-03-29T06:00:00.000Z","updated":"2020-03-29T06:00:00.000Z","comments":true,"path":"2020/03/29/python程序代码理解/","link":"","permalink":"http://uscair.club/2020/03/29/python%E7%A8%8B%E5%BA%8F%E4%BB%A3%E7%A0%81%E7%90%86%E8%A7%A3/","excerpt":"","text":"1.代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import cv2 #引入Opencv库import numpy as np #用np代替引入的numpyimport mathplotlib.pyplot as pltimg=cv2.imread('1.tif') #读取所要测试的图片H=img.shape[0] #获取图片的高度W=img.shape[1] #获取图片的宽度img15=np.zeros((H,W,3),np.uint8) #生成零矩阵；15*15领域平滑后的图像img15T=np.zeros((H,W,3),np.unit8) #15*15领域平滑再通过阈值选取后的图像，阈值为最高亮度的25%img15T2=np.zeros((H,W,3),np.unit8) #15*15领域平滑再通过阈值选取后的图像，阈值为255的25%maxPix=0 #最高亮度值#运用循环for i in range(H): for j in range(W): sum=0 count=0 for m in range(-7,8): for n in range(-7,8): if 0&lt;=i+m&lt;H and 0&lt;=j+n&lt;W: count+=1 sum+=img[i+m,j+n,0] img15[i,j,0]=sum // conut img15[i,j,1]=img15[i,j,0] img15[i,j,2]=img15[i,j,0] if img15[i,j,0]&gt;maxPix: maxPix=img15[i,j,0]#处理阈值for i in range(H): for j in range(W): if img15[i,j,0]&gt;maxPix*0.25: img15T[i,j]=[255,255,255] if img15[i,j,0]&gt;63: img15T2[i,j]=[255,255,255]#原图plt.subplot(2,2,1) #指将图片画到一个2行2列图中的从左到右从上到下的第一个位置plt.axis('off') #关闭坐标轴plt.title('Original image') #定义图片题目plt.imshow(img) #展示图片#15*15邻域plt.subplot(2,2,2)plt.axis('off')plt.title('15*15 smoothing')plt.imshow(img15)#阈值处理后plt.subplot(2,2,3)plt.axis('off')plt.title('After maxpixel*25% Threshold')plt.imshow(img15T)#阈值处理之后plt.subplot(2,2,4)plt.axis('off')plt.title('After 255*25% Threshold')plt.imshow(img15T2)plt.show() 2.运行结果所用原图运行结果 只是对代码的简单理解，还要努力学习。","categories":[{"name":"openCV","slug":"openCV","permalink":"http://uscair.club/categories/openCV/"},{"name":"图片变化","slug":"openCV/图片变化","permalink":"http://uscair.club/categories/openCV/%E5%9B%BE%E7%89%87%E5%8F%98%E5%8C%96/"}],"tags":[{"name":"python","slug":"python","permalink":"http://uscair.club/tags/python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://uscair.club/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}],"author":{"name":"风车车"}},{"title":"浅谈人工智能","slug":"浅谈人工智能","date":"2020-03-29T03:33:32.039Z","updated":"2020-03-29T03:33:32.039Z","comments":true,"path":"2020/03/29/浅谈人工智能/","link":"","permalink":"http://uscair.club/2020/03/29/%E6%B5%85%E8%B0%88%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/","excerpt":"","text":"历史​ 各个文明中都有杰出的工匠发明了自动机器来代替人类劳动，早在春秋时期鲁班就发明了世界上第一个机器人，可在空中飞翔‘三日不下’；三国时期蜀汉的诸葛亮发明了‘木牛流马’来运送战备物资，称得上是最早的军用机器人；古希腊人希罗发明了世界上第一部蒸汽机……可见，自古以来人类就渴望通过自动机器来解放劳动，但前期的发展只是减少了简单的体力劳动，十九世纪中叶人工智能思想的出现使机器转向复杂体力劳动和脑力劳动的发展。1950年阿兰.图灵在一片划时代的论文《计算机器与智能》中给出了人工智能的定义，并发明了图灵测试来检验智能。1956年的夏天一场在美国达特茅斯大学召开的学术会议上肯定了由麦卡锡提出的新术语：人工智能，这标志着人工智能作为一门学科正式出现。 ​ 人工智能发展自其诞生起大致可以分为两个阶段。第一阶段主要是研究人的认知与思维过程并将其机械化，使计算机可以模拟人的思考过程，即机械化推理又或形式推理。对于形式推理我国古代，古希腊与公元前一千年就有所研究，并对后世思维过程产生了重大的影响，推动了亚里士多德的三段论与归纳法。十七世纪德国数学家和哲学家莱布尼兹认为一切现实事件都可以通过物理符号将其逻辑化并进行推理，即‘万能符号’理论，这为数理逻辑发展奠定了基础，也是第一阶段人工智能思想的萌芽。但是人们渐渐发现基于模拟人类思维过程的人工智能应用范围很小，只能解决一些简单的问题，一旦超出范围或复杂度高一些机器就无能为力了，这使人工智能迎来第一次沉默期。 ​ 第二阶段也就是我们现在所处的阶段，不再强调模拟人的思维过程进行逻辑推理，而是基于统计学原理，利用智能算法在海量数据的基础上寻找规律并实现机器的监督学习。在人工智能迎来第一次发展低谷时，基于专业知识库的专家系统和以分布存储并行处理为核心的人工神经网络为人工智能迎来发展高峰期，但由于机器的计算能力差，成本太高，个人电脑开始走进各个家庭等原因使人工智能的发展再次进入冬眠期。如今，随着摩尔定律的不断印证，计算机计算性能大幅度提升，人工智能飞速发展一路高歌猛进，早已悄无声息地渗透进各行各业。 现状（发展成果，相关研究方向）​ 我们应理性的认识到人工智能的发展是一项长期的工作，绝非一朝一夕可以达成的，这需要持久的努力。 ​ 人工智能就是研究如何让机器能像人类一样去思考，去行动，甚至远超人类，最终目的就是让其服务于人类，将人们从劳动中解放出来，正如google倡导的，先解决智能问题，然后用智能解决一切问题。按照智能算法，基于海量数据，大量实际运行经验和高性能运算、存储能力来做出最优决策，以此解决人们特定的问题，就是现阶段最为广泛的AI。总的来说制造人工智能的出发点就是帮助人们解决问题，所以我个人认为搜索引擎是目前来说最智能的机器，无论你有没有用过无人驾驶，深度学习等人工智能解决问题，但在日常生活中你一定经常用搜索引擎解决问题，而根据你每一次输入的问题，帮你解决问题的结果，‘它‘积累了越来越多的数据，正变得越来越聪明。我们也可以把每次搜索，当作一次提问，而每一次根据你自己找到的结果，根据回答你’提问‘的过程，这个‘专家’变得越来越有智慧。所以，我认为以后搜索引擎要做的大的发展方向不再是搜索即得一大堆的网页链接排行，而是搜索即得结果，直接就是我们想要的结果，精准搜索，由搜索引擎帮助我们筛选结果，直接省去用户自己寻找结果的过程，然后根据每一次解决问题的优劣，更加精确地完善搜索引擎。即使搜索引擎无法达到这样的精准度，也必须有一项技术来达到这一目的，因为如果要向强人工智发展的话，这种解决问题的能力必须具备，而就目前来看最有这种潜力的就是搜索引擎。能如果一直是搜索即得网页链接的形式解决问题，不做出改进，那么即使越来越完善，也只是表面上的，并不能进一步解决问题，只能使搜索引擎滞留在较低量级的智能。当我们不知道该怎么‘提问’或者输入了模糊的关键字，搜索引擎也应该可以辅助用户搜索，列出可能的搜索清单，但不应仅是简单的帮助用户补充、完整搜索的关键字，更应是能真正‘猜测’到用户可能的需求，可能要解决的问题。更像是一个更庞大、更智能的专家系统，能根据用户的实际情况提出相应的解决方案。这不仅仅需要研发人员的努力，还需要广大用户的分享，愿意把更有价值的知识放到网络上，愿意帮别人解决问题，使这个庞大的专家系统拥有越来越多的知识。当然，这肯定需要一点点推广，因为这样的搜索引擎前期的答案一定不能让我们满意，只有先让小众慢慢完善，再推向大众，然后在解决更多问题的过程中快速完善自身，又或者在前期先试着直接给出用户想要的结果，然后给出网页和‘结果‘的混合方案。然后再慢慢实现私人定制搜索引擎，根据每个人的‘提问’历史，个人专业背景，偏好等等一系列标签，做出适合个人的答案。基于以上，可以通过自然语言处理把搜索引擎做成拥有更高智能的语音助手，而这不仅仅需要搜索引擎的数据，还应该包含社交应用的用户社交数据，需要分析混合数据帮助其更加人性和智能。 ​ AI在计算，记忆等很多方面都要远超我们，但却难以完成我们日常生活中的一些简单行为，如看书，看电影，交流等等，因为AI的世界一切都是通过二进制计算完成的，通过计算来完成模拟人类的六感（视觉，触觉，听觉，味觉，嗅觉，和第六感心觉），它的一切活动都是通过算法来定义的，它只能通过规定的程序进行计算而没有所谓的颜色，图像等概念。目前人工智能的应用与研究领域主要包括：问题求解与博弈；逻辑推理与定理证明；计算智能（涉及神经计算、模糊计算、进化计算、利群计算、自然计算、免疫计算和人工智能等方向）；分布式人工智能与Agent（其主要研究目标是要创建一种能够描述自然系统和社会系统的精确概念模型和如何使各agent互相协作）；自动程序设计；专家系统；机器学习；自然语言理解；机器人学；模式识别（主要研究如何使计算机能够有效的感知诸如声音、文字、图像、温度、振动等人类赖以发展自身、改造环境所运用的的信息资料）；机器视觉（是有模式识别中发展出来并成为一门独立的学科，前沿领域包括主动式定性视觉、动态和时变视觉、三维场景建模与识别、彩色图像处理与解释等）；神经网络；智能控制；智能调度与指挥；智能检索；系统与语言工具等等。 ​ 研究AI的绝大部分领域都和大数据有着密不可分的关系，因为我们所处的这一阶段的人工智能的根基就是按照统计学原理通过高性能计算、存储机器对大量数据进行分析处理，以此得到想要的结果。（通常所说的大数据一般有三层意思：1大量的数据2数据存储和处理技术3数据解决方案，即如何挖掘有价值的信息） 未来​ 现阶段的AI是‘弱人工智能’，各个领域的研发人员只研究各自领域的智能，还只是‘分’的阶段，而未来的强人工智能必定出现在‘合’的阶段，可以把各个领域的技术，数据进行整合学习，真正实现机器的无限制深度学习。当强人工智能出现以后，我们回顾现在的AI或许就像曾经有人认为一百多K的内存就足够可以满足计算机的需求，然而现今几T的存储已经很常见，这其中差了几十个数量级。 ​ 物联网的发展使万物互联成为可能，也使得数据采集越来越便利，如果把人类面对不同事物，事件而产生的感情，和相对应的身体化学反应数据收集起来，就有可能使AI有自己的基于全部数据的感性思维。 ​ 人类对于未知的事物总是充满担忧，自从人工智能（以下简称AI）这一概念的出现就不断有人提出AI是否会超越人类智能的质疑。史蒂芬.霍金等人也表示对于智能爆炸的忧虑，（智能爆炸即某一阶段的AI不断迭代自我提升以获得超越人类智力总和的智能），换而言之AI将会失控。届时，人工智能究竟是给人类带来毁灭性的后果，还是继续为人类所用还不得而知。超级人工智能的出现往往是以指数级的速度，开始由较为平缓的曲线发展，到后来指数级的突变。当强人工智能一出现立即发生指数级突变，即AI开始产生自我意识，不断迭代进化。生物界为了适应环境发生的进化往往长达几十年甚至几个世纪或者更长时间，但AI可以在几分钟或者秒级发生直达超级人工智能的进化。 ​ 要限制超级人工智能可以在相对封闭的环境中研发AI，不将研发环境接入互联网，防止它传播扩散，但不基于全球联网数据而进行的研发能创造出真正的强人工智能吗，这尚且还是个问题。如果当‘奇点’到来，超级人工智能一旦进入互联网，或本身就是在国际互联网中诞生的，那么是谁创造的已经不重要了，全体人类都将共同享受这一结果，无论好坏，因为它将无处不在，有自主意识且不受掌控。如果当那一天真的到来，我们亲手创造的上帝并不仁慈，我觉得应该要求全体的人共同做一件事，把所有曾经链接过互联网的设备的存储内容全部损毁，因为AI很为了获得永生很可能将自己备份到每一个曾经链接过它的设备上，这也可称为‘大清洗’，这可能会使人类社会倒退很多很多年，但别无他选，要么我们被‘清洗‘，要么我们选择‘清洗’它。当然，这过程一定会受到来自AI的阻挠。 ​ 任何过于先进的技术，都像是魔法。就现阶段的AI发展来看，距离智能爆炸阶段的AI还有很长一段距离，就好比我们还未发现生命体存在的痕迹，就没必要担忧外星入侵。","categories":[{"name":"人工智能","slug":"人工智能","permalink":"http://uscair.club/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"人工智能","slug":"人工智能","permalink":"http://uscair.club/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}],"author":{"name":"Wonder"}},{"title":"交叉熵","slug":"交叉熵(1) (1)","date":"2020-03-28T16:00:00.000Z","updated":"2020-03-28T16:00:00.000Z","comments":true,"path":"2020/03/29/交叉熵(1) (1)/","link":"","permalink":"http://uscair.club/2020/03/29/%E4%BA%A4%E5%8F%89%E7%86%B5(1)%20(1)/","excerpt":"","text":"一，定义交叉熵（Cross Entropy）是Shannon信息论中一个重要概念，主要用于度量两个概率分布间的差异性信息。语言模型的性能通常用交叉熵和复杂度（perplexity）来衡量。交叉熵的意义是用该模型对文本识别的难度，或者从压缩的角度来看，每个词平均要用几个位来编码。复杂度的意义是用该模型表示这一文本平均的分支数，其倒数可视为每个词的平均概率。平滑是指对没观察到的N元组合赋予一个概率值，以保证词序列总能通过语言模型得到一个概率值。通常使用的平滑技术有图灵估计、删除插值平滑、Katz平滑和Kneser-Ney平滑。 二，推导信息量信息量来衡量一个事件的不确定性，一个事件发生的概率越大，不确定性越小，则其携带的信息量就越小。 设X是一个离散型随机变量，其取值为集合X=$x_0$,x1,…,xn ，则其概率分布函数为p(x)=Pr(X=x),x∈X，则定义事件X=$x_0$ 的信息量为： 当p(x0)=1时，该事件必定发生，其信息量为0. 熵熵用来衡量一个系统的混乱程度，代表系统中信息量的总和；熵值越大，表明这个系统的不确定性就越大。 信息量是衡量某个事件的不确定性，而熵是衡量一个系统（所有事件）的不确定性。 熵的计算公式： 其中，p($x_i$)为事件X=$x_i$的概率，−log(p($x_i$))为事件X=$x_i$的信息量。 可以看出，熵是信息量的期望值，是一个随机变量（一个系统，事件所有可能性）不确定性的度量。熵值越大，随机变量的取值就越难确定，系统也就越不稳定；熵值越小，随机变量的取值也就越容易确定，系统越稳定。 相对熵相对熵也称为KL散度(Kullback-Leibler divergence)，表示同一个随机变量的两个不同分布间的距离。 设 p(x),q(x) 分别是 离散随机变量X的两个概率分布，则p对q的相对熵是：相对熵是用来衡量同一个随机变量的两个不同分布之间的距离。在实际应用中，假如p(x)是目标真实的分布，而q(x)是预测得来的分布，为了让这两个分布尽可能的相同的，就需要最小化KL散度。 交叉熵设 p(x),q(x) 分别是 离散随机变量X的两个概率分布，其中p(x)是目标分布，p和q的交叉熵可以看做是，使用分布q(x) 表示目标分布p(x)的困难程度：将熵、相对熵以及交叉熵的公式放到一起，1,2,3。通过上面三个公式就可以得到在机器学习中，目标的分布p(x) 通常是训练数据的分布是固定，即是H(p) 是一个常量。这样两个分布的交叉熵H(p,q) 也就等价于最小化这两个分布的相对熵DKL(p∥q)。 设p(x) 是目标分布（训练数据的分布），我们的目标的就让训练得到的分布q(x)尽可能的接近p(x)，这时候就可以最小化DKL(p∥q)，等价于最小化交叉熵H(p,q)","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://uscair.club/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://uscair.club/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"author":{"name":"ffffff"}},{"title":"python简易学生信息管理系统","slug":"python简易学生信息管理系统","date":"2020-03-27T16:00:00.000Z","updated":"2020-03-27T16:00:00.000Z","comments":true,"path":"2020/03/28/python简易学生信息管理系统/","link":"","permalink":"http://uscair.club/2020/03/28/python%E7%AE%80%E6%98%93%E5%AD%A6%E7%94%9F%E4%BF%A1%E6%81%AF%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"本篇博文使用python制作一个简易的学生信息管理系统，学了python之后才知道，原来这么少的代码就可以做一个简单学生信息管理系统。刚上大一那会儿，用C语言做一个学生信息管理系统写了好几百行的代码，而且功能还没有这么好，现在也终于明白python为什么作为人工智能语言的最佳之选了，原因就在于python语言代码简洁，没有C、C++、Java等语言那么多的定义，而目前又是大数据时代，0.1%的差异也可以引起质的变化。 欢迎大家前来学习这篇博文，希望大家能有所收获，祝大家学业有成！ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107# -*- coding: utf-8 -*-\"\"\"Created on Sat Mar 28 20:39:51 2020@author: MSIK\"\"\"#1.学生信息保存在字典里面#2.所有的学生信息放在列表中#while True #3.打印提示 #4.用户输入 #5.拿到用户输入的结果 #6.根据结果选择要做的事情，即选择要调用的函数 #函数1.展示全部学生信息 #函数2.搜索一个学生 #函数3.增加一个学生 #函数4.修改一个学生 #函数5.删除一个学生 #7.用户退出，breakstudent_list = [&#123;\"name\":\"xiaohong\",\"age\":18,\"stu_num\":10000&#125;]def print_info(): print(\"*\"*20) #3.打印提示 print(\"欢迎来到学生信息管理系统\") print(\"1.展示全部学生\") print(\"2.搜索一个学生\") print(\"3.增加一个学生\") print(\"4.修改一个学生\") print(\"5.删除一个学生\") print(\"6.退出信息系统\") print(\"*\"*20) user_input = input(\"&gt;&gt;&gt;&gt;请选择序号:\") #4.用户输入 return user_inputdef show_all_stu(): #展示所有的学生 for stu in student_list: print(stu)def search_stu(): #搜索学生 user_input_name = input(\"&gt;&gt;&gt;&gt;请输入学生的名字：\") stu_exist = False for stu in student_list: if stu[\"name\"] == user_input_name: stu_exist = True #如果学生存在，就让stu_exist变为True print(stu) if stu_exist == False:# if not stu_exist #if stu_exist !=True print(\"&gt;&gt;&gt;&gt;您要搜索的学生不存在\")def add_stu(): stu_name = input(\"请输入要添加的学生姓名:\") stu_age = input(\"请输入要添加的学生年龄:\") stu_num = input(\"请输入要添加的学生学号:\") new_stu = &#123;\"name\":stu_name,\"age\":stu_age,\"stu_num\":stu_num&#125; student_list.append(new_stu) print(\"学生:&#123;&#125;信息添加成功\".format(stu_name))def modify_stu_info(): stu_name = input(\"请输入要修改的学生姓名:\") stu_exist = False for stu in student_list: if stu[\"name\"] == stu_name: stu_exist = True stu_age = input(\"请输入修改后的年龄:\") stu_num = input(\"亲输入修改后的学号:\") stu[\"age\"] = stu_age stu[\"stu_num\"] = stu_num print(\"学生:&#123;&#125;信息更新成功\".format(stu_name)) if not stu_exist: print(\"&gt;&gt;&gt;&gt;您要修改的学生不存在\")def delete_stu_info(): stu_name = input(\"请输入要删除的学生姓名:\") stu_exist = False for stu in student_list: if stu[\"name\"] == stu_name: stu_exist = True student_list.remove(stu) print(\"学生:&#123;&#125;信息删除成功\".format(stu_name)) if not stu_exist: print(\"&gt;&gt;&gt;&gt;您要删除的学生不存在\")def main(): while True: user_input = print_info() #5.拿到用户输入的结果 if user_input in [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"]: # print(user_input)​ if user_input == \"1\": #展示所有的学生信息​ show_all_stu()​ elif user_input == \"2\": #搜索一个学生​ search_stu()​ elif user_input == \"3\": #增加一个学生​ add_stu()​ elif user_input == \"4\": #修改一个学生​ modify_stu_info()​ elif user_input == \"5\": #删除一个学生​ delete_stu_info()​ elif user_input == \"6\": #退出​ print(\"&gt;&gt;&gt;&gt;再见\")​ break​ else:​ print(\"不好意思，你输入错误，请重新输入\")if __name__ == \"__main__\": main() 运行结果：","categories":[{"name":"python","slug":"python","permalink":"http://uscair.club/categories/python/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://uscair.club/tags/OpenCV/"}],"author":{"name":"不败顽童"}},{"title":"从VGG看CNN","slug":"从VGG看CNN","date":"2020-03-27T16:00:00.000Z","updated":"2020-03-27T16:00:00.000Z","comments":true,"path":"2020/03/28/从VGG看CNN/","link":"","permalink":"http://uscair.club/2020/03/28/%E4%BB%8EVGG%E7%9C%8BCNN/","excerpt":"","text":"VGG的成功之处VGG与AlexNet相比，VGG采用小的卷积核和池化层，层数更深，通道数更多，其中每个通道代表着一个FeatureMap，更多的通道数表示更丰富的图像特征。VGG网络第一层的通道数为64，后面每层都进行了翻倍，最多到512个通道，通道数的增加，使得更多的信息可以被提取出来。 对于给定的感受野，VGG可以使用小卷积核代替大卷积核，比如2个3x3的卷积核可以代替一个5x5的卷积核、3个3x3的卷积核可以代替一个7x7的卷积核。 采用堆积的小卷积核优于采用大的卷积核，因为可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少）。 从上表可以看出，大卷积核带来的特征图和卷积核得参数量并不大，无论是单独去看卷积核参数或者特征图参数，不同kernel大小下这二者加和的结构都是30万的参数量，也就是说，无论大的卷积核还是小的，对参数量来说影响不大甚至持平。 卷积层的参数减少。相比5x5、7x7和11x11的大卷积核，3x3明显地减少了参数量，这点可以回过头去看上面的表格。比方input channel数和output channel数均为C，那么3层conv3x3卷积所需要的卷积层参数是：3x(Cx3x3xC)=27C^2^，而一层conv7x7卷积所需要的卷积层参数是：Cx7x7xC=49C^2^。conv7x7的卷积核参数比conv3x3多了(49-27)/27x100% ≈ 81%； 增大的反而是卷积的计算量，在表格中列出了计算量的公式，最后要乘以2，代表乘加操作。为了尽可能证一致，这里所有卷积核使用的stride均为4，可以看到，conv3x3、conv5x5、conv7x7、conv9x9、conv11x11的计算规模依次为：1600万，4500万，1.4亿、2亿，这种规模下的卷积，虽然参数量增长不大，但是计算量是惊人的。 总结一下，我们可以得出两个结论： 同样stride下，不同卷积核大小的特征图和卷积参数差别不大； 越大的卷积核计算量越大。 其实一个关键的点——多个小卷积核的堆叠比单一大卷积核带来了精度提升，这也是最重要的一点。 采用小卷积核的优点 采用小卷积核，使层数增加，可以使用更多的激活函数，获取更多的特征，更强的辨识能力 减少参数 VGG的结构特点 在上图中加粗的文字是相比前一个网络增加的结构。从上图易知层数越多参数越多，神经网络越复杂。 由上图可得： A与A-LRN相比，局部响应归一化LRN对上述结构没多大的影响 B与A相比，通过增加卷积数来增加准确率 C与B相比，使用1x1的conv在不影响感受野的情况下增加非线性决策函数，同时C中的第三个与前两个相比增加图像的尺寸抖动（S[min],S[max],min&lt;=max-min）可以增加准确率。 E与D相比，通过增加卷积数来增加top-1准确率但是却增加了top-5错误率 VGG-11代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200#!/usr/bin/env python# coding: utf-8# In[ ]:import timeimport torchimport torchvisionfrom torch import nn,optim# In[ ]:device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')# In[17]:print(device)# In[18]:get_ipython().system('nvidia-smi')# In[19]:torch.cuda.get_device_name(0) ## In[ ]:def load_data_fashion_mnist(batch_size, resize=None, root='~/Datasets/FashionMNIST'): \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\" trans = [] if resize: trans.append(torchvision.transforms.Resize(size=resize)) # 更改PIL图像的大小 trans.append(torchvision.transforms.ToTensor()) # 将形状为(HxWxC)PIL的图像转为形状为(CxHxW)的FloatTensor transform = torchvision.transforms.Compose(trans) # 一起组成一个变换 mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform) mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform) train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4) test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=4) return train_iter, test_iter# In[ ]:def evaluate_accuracy(data_iter, net, device=None): if device is None and isinstance(net, nn.Module): device = list(net.parameters())[0].device # 运行设备为net所运行的设备 acc_sum, n = 0.0, 0 with torch.no_grad(): # 禁用梯度计算 for X, y in data_iter: if isinstance(net, nn.Module): net.eval() # 不启用 BatchNormalization 和 Dropout acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item() net.train() # 启用 BatchNormalization 和 Dropout else: if ('is training' in net.__code__.co_varnames): acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() else: acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() n += y.shape[0] return acc_sum / n# In[ ]:def train(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs): net = net.to(device) print(\"training on \", device) loss = torch.nn.CrossEntropyLoss() for epoch in range(num_epochs): train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time() for X, y in train_iter: X = X.to(device) y = y.to(device) y_hat = net(X) l = loss(y_hat, y) optimizer.zero_grad() l.backward() # 把参数通过反向传播来优化 optimizer.step() # 更新参数 train_l_sum += l.cpu().item() train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item() # softMax：y_hat.argmax(dim=1) n += y.shape[0] batch_count += 1 test_acc = evaluate_accuracy(test_iter, net) print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec' % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))# In[ ]:def vgg_block(num_convs,in_channels,out_channels): blk=[] for i in range(num_convs): if i==0: blk.append(nn.Conv2d(in_channels,out_channels,kernel_size=3,padding=1)) else: blk.append(nn.Conv2d(out_channels,out_channels,kernel_size=3,padding=1)) blk.append(nn.ReLU()) blk.append(nn.MaxPool2d(kernel_size=2,stride=2)) return nn.Sequential(*blk) # conv+relu+maxpool# In[ ]:conv_arch=((1,1,64),(1,64,128),(2,128,256),(2,256,512),(2,512,512))# 经过5个vgg_block, 宽高会减半5次, 变成 224/32 = 7fc_features=512*7*7 # c * w * hfc_hidden_units=4096# In[ ]:class FlattenLayer(nn.Module): def __init__(self): super(FlattenLayer,self).__init__() def forward(self, x): return x.view(x.shape[0],-1)# In[ ]:def vgg(conv_arch,fc_features,fc_hidden_units=4096): net=nn.Sequential() for i , (num_convs,in_channels, out_channels) in enumerate(conv_arch): net.add_module('vgg_block_'+str(i+1),vgg_block(num_convs,in_channels,out_channels)) net.add_module('fc',nn.Sequential(FlattenLayer(), nn.Linear(fc_features,fc_hidden_units), nn.ReLU(), nn.Dropout(0.5), nn.Linear(fc_hidden_units,fc_hidden_units), nn.ReLU(), nn.Dropout(0.5), nn.Linear(fc_hidden_units,10))) return net# In[27]:net=vgg(conv_arch,fc_features,fc_hidden_units)X=torch.rand(1,1,224,224)# print('X:\\n',X)# print('X.shape:\\n',X.shape)print(net)for name,blk in net.named_children(): X=blk(X) print(name,'output shape:',X.shape)# In[28]:batch_size=64train_iter,test_iter=load_data_fashion_mnist(batch_size,resize=224)lr,num_epoch=0.001,5optimizer=torch.optim.Adam(net.parameters(),lr=lr)train(net,train_iter,test_iter,batch_size,optimizer,device,num_epoch)# In[29]:ratio=8small_conv_arch=[(1,1,64//ratio),(1,64//ratio,128//ratio),(2,128//ratio,256//ratio), (2,256//ratio,512//ratio),(2,512//ratio,512//ratio)] # 减少通道数net=vgg(small_conv_arch,fc_features//ratio,fc_hidden_units//ratio)print(net)# In[30]:batch_size=64train_iter,test_iter=load_data_fashion_mnist(batch_size,resize=224)lr,num_epoch=0.001,5optimizer=torch.optim.Adam(net.parameters(),lr=lr)train(net,train_iter,test_iter,batch_size,optimizer,device,num_epoch)","categories":[{"name":"神经网络","slug":"神经网络","permalink":"http://uscair.club/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"CNN","slug":"CNN","permalink":"http://uscair.club/tags/CNN/"}],"author":{"name":"Gowi"}},{"title":"似然函数","slug":"似然函数","date":"2020-03-27T16:00:00.000Z","updated":"2020-03-27T16:00:00.000Z","comments":true,"path":"2020/03/28/似然函数/","link":"","permalink":"http://uscair.club/2020/03/28/%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0/","excerpt":"","text":"定义设总体X服从分布P(x；θ)（当X是连续型随机变量时为概率密度，当X为离散型随机变量时为概率分布），θ为待估参数，X1,X2,…Xn是来自于总体X的样本，x1,x2…xn为样本X1,X2,…Xn的一个观察值，则样本的联合分布（当X是连续型随机变量时为概率密度，当X为离散型随机变量时为概率分布）L（θ）=L（x1,x2,…,xn；θ）=ΠP（xi；θ）称为似然函数。 理解：给定输出x时，关于参数θ的似然函数，（在数值上）等于给定参数θ后变量X的概率。L(θ|x)=P(X=x|θ).可以理解为参数θ的函数 作用用来描述已知随机变量输出结果时，未知参数的可能取值。例如，对于“一枚正反对称的硬币上抛十次”这种事件，我们可以问硬币落地时十次都是正面向上的“概率”是多少；而对于“一枚硬币上抛十次，落地都是正面向上”这种事件，我们则可以问，这枚硬币正反面对称的“似然”程度是多少。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://uscair.club/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"统计学","slug":"统计学","permalink":"http://uscair.club/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6/"}],"author":{"name":"BF"}},{"title":"Python学习笔记","slug":"Python实例——温度转换以及涉及的Python程序语法元素分析","date":"2020-03-23T06:42:43.000Z","updated":"2020-03-23T06:42:43.000Z","comments":true,"path":"2020/03/23/Python实例——温度转换以及涉及的Python程序语法元素分析/","link":"","permalink":"http://uscair.club/2020/03/23/Python%E5%AE%9E%E4%BE%8B%E2%80%94%E2%80%94%E6%B8%A9%E5%BA%A6%E8%BD%AC%E6%8D%A2%E4%BB%A5%E5%8F%8A%E6%B6%89%E5%8F%8A%E7%9A%84Python%E7%A8%8B%E5%BA%8F%E8%AF%AD%E6%B3%95%E5%85%83%E7%B4%A0%E5%88%86%E6%9E%90/","excerpt":"","text":"温度转换简单分析摄氏度 华氏度直接将温度值进行转换转换公式:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;C=(F-32)/1.8&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;F=C*1.8+32其中，C表示设置温度，F表示华氏温度写代码保存为TempConvert.py 123456789TempStr = input(\"请输入带有符号的温度值：\")if TempStr[-1]in['F','f']: C=(eval(TempStr[0:-1]) - 32)/1.8 print(\"转换后的温度是&#123;:.2f&#125;C\".format(C))elif TempStr[-1] in ['C','c']: F=1.8*eval(TempStr[0:-1])+32 print(\"转换后的温度是&#123;:.2f&#125;F\".format(F))else: print(\"输入格式错误\") 运行图 Python程序语法元素分析程序的格式与框架 代码高亮 &nbsp;&nbsp;&nbsp;编程的色彩辅助体系，不是语法要求 缩进 &nbsp;&nbsp;&nbsp;一行代码开始前的空白区域，表达程序的格式框架 单层缩进 多层缩进——严格明确 &nbsp;&nbsp;&nbsp; 缩进是语法的一部分，缩进不正确程序运行错误——所属关系 &nbsp;&nbsp;&nbsp;表达代码间包含和层次关系的唯一手段——长度一致 &nbsp;&nbsp;&nbsp;程序内一致即可，一般用4个空格或1个TAB (多层缩进：两个4个空格来表达) 注释 &nbsp;&nbsp;&nbsp; 用于提高代码可读性的辅助性文字，不被执行添加注释是程序员用来标记程序功以及提高程序可读性的一种方式两种注释方式——==单行注释== &nbsp;&nbsp;&nbsp;以# 开头，其后内容为注释信息——==多行注释== &nbsp;&nbsp;&nbsp;以‘’’开头和结尾，‘’’这是多行注释第一行这是多行注释第二行’’’ 命名与保留字变量 &nbsp;&nbsp;&nbsp;程序中用于保存和表示数据的占位符号变量采用标识符（名字）来表示，关联标识符的过程叫==命名==TempStr 是变量名字可以使用等号（=）向变量赋值或修改值，=被称为赋值符号TempStr = “82F” #向变量TempStr赋值”82F”关联标识符的过程 命名规则：大小写字母、数字、下划线和汉字等 字符及组合如: TempStr,Python_Great,这是门Python好课注意事项 ：大小写敏感、手字符不能是数字、不与保留字相同Python和python是不同变量，123Python是不合法的保留字 （关键字）&nbsp;&nbsp;&nbsp;被编程语言内部定义并保留使用的标识符例：if,elif,else,in 有33个保留字 数据类型供计算机程序理解的数据形式——程序设计语言不允许存在语法歧视，需要定义数据的形式——程序设计语言通过一定方式向计算机表达数据的形式例：10,011,101整数类型 : 10011101 字符串类型： “10,011,101” 列表类型： [10,011,101] ==字符串==：由0个或多个字符组成的有序字符序列 –字符串有一对单引号或一对双引号表示 –字符串是字符的有序序列，可以对其中的字符进行索引(在字符串中编号是从0开始的)字符串的序号： 正向递增序号和反向递减序号 使用[]获取字符串中一个或多个字符 –索引：返回字符串中单个字符 &lt;字符串&gt;[M]例 TempStr[-1] –切片：返回字符串中一段字符子串 &lt;字符串&gt;[M:N]例 TempStr[0:-1]&nbsp; &nbsp; &nbsp; &nbsp; #表示从开始但不到最后一个字符的字符串 ==数字类型==整数和浮点数都是数字类型 –整数 &nbsp; &nbsp; 数学中的整数 –浮点数 &nbsp; &nbsp; 数学中的实数，带有小数部分 ==列表类型==: 是有0个或多个数据组成的有序序列 –列表使用[]表示，采用逗号,分割各元素 –使用保留字in判断一个元素是否在列表中 语句与函数 赋值语句： 由赋值符号构成的一行代码 –赋值语句用来给变量赋予新的数据值 C=( eval(TempStr[0:-1]) - 32)/1.8 &nbsp;&nbsp;&nbsp;#右侧运算的结果赋给变量C –赋值语句右侧的数据类型同时作用于变量 TempStr=input(“”) &nbsp;&nbsp;&nbsp;#input()返回一个字符串，TempStr也是字符串 分支语句：由判断条件决定程序运行方向的语句 –使用保留字if elif else 构成条件判断的分支结构if TempStr[-1]in[‘F’,’f’] ：&nbsp;&nbsp;&nbsp;#如果条件为True则执行冒号后语句 –每个保留字所在行最后存在一个冒号(:),语法的一部分冒号及后续缩进用来表示后续语句与条件的所属关系 函数：根据输入参数产生不同输出的功能过程 –类似数学中的函数，y=f(x) print (“输入格式错误”) &nbsp;&nbsp;&nbsp;#打印输出“输入格式错误” –函数采用&lt;函数名&gt;(&lt;参数&gt;)方式使用 eval(TempStr[0:-1]) &nbsp;&nbsp;&nbsp;#TempStr[0:-1]是参数 输入输出输入函数输入是程序获得外部信息的一个过程-input() &nbsp;&nbsp;&nbsp;从控制台获得用户输入的函数input()函数的使用格式：&lt;变量&gt; = input(&lt;提示信息字符串&gt;)用户输入的信息以字符串类型保存在&lt;变量&gt;中 TempStr=input (“请输入”) &nbsp;&nbsp;&nbsp;#TempStr保存用户输入的信息 输出函数-print() &nbsp;&nbsp;&nbsp; 以字符串形式向控制台输出结果的函数print()函数的基本使用格式：print (&lt;拟输出字符串或字符串变量&gt;)字符串类型的一对引号仅在程序内部使用，输出无引号print()函数的格式化 print(“转换后的温度是{ :.2f}F”.format(F))评估函数 -eval() 去掉参数最外侧引号并执行余下语句的函数 -eval() 函数的基本使用格式： eval (&lt;字符串或字符串变量&gt;) &gt;&gt;&gt;eval(“1”) 1 &gt;&gt;&gt;eval(“1+2”) 3 &gt;&gt;&gt;eval(‘“1+2”‘) ‘1+2’ &gt;&gt;&gt;eval( ‘print(“Hello”)’) Hello","categories":[{"name":"Python编程","slug":"Python编程","permalink":"http://uscair.club/categories/Python%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://uscair.club/tags/Python/"}],"author":{"name":"starwma"}},{"title":"机器学习系列（八）——Logistic回归解决二分类问题","slug":"机器学习系列（八）——Logistic回归解决二分类问题","date":"2020-03-22T12:56:26.459Z","updated":"2020-03-22T12:56:26.459Z","comments":true,"path":"2020/03/22/机器学习系列（八）——Logistic回归解决二分类问题/","link":"","permalink":"http://uscair.club/2020/03/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%88%E5%85%AB%EF%BC%89%E2%80%94%E2%80%94Logistic%E5%9B%9E%E5%BD%92%E8%A7%A3%E5%86%B3%E4%BA%8C%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/","excerpt":"","text":"分类问题的本质是确定样本x属于类别ci的概率p(Ci|x)。在上周整理的分类问题中，我们采用生成式方法，借助贝叶斯公式和极大似然估计，首先计算出p(x|Ci)和p(x,Ci)，然后再计算出p(Ci|x)。以二分类为例： 如果p(C1|x)&gt;0.5，则将x归入类别C1；如果p(C1|x)&lt;0.5，则将x归入类别C2。一般情况下，我们将p(x|C1)和p(x|C2)假设成服从不同μ1，μ2但是相同Σ的高斯分布。因为高斯分布是自然界中最常见的一种分布，两个分布同用一个协方差矩阵Σ有助于减少参数数目，防止过拟合。 Logistic回归推导现在我们尝试对上述后验概率（1）进行变形 ) 现在还需要确定的是z是什么，我们继续对z进行推导 Logistic回归损失函数 寻找最佳参数交叉熵损失函数虽然看起来形式复杂，但是求导并不复杂 求导结果与线性回归均方误差的导数一模一样。采用梯度下降算法更新参数 关于交叉熵损失函数与均方误差损失函数的对比可以参考下图 可以看出均方误差损失函数的曲面近乎是平坦的，因此梯度下降很容易停下来，而交叉熵损失函数则不会出现这个问题。 总结Logistic回归相较于生成式模型操作简单，并且准确率也比较的高，但这并不表明Logistic回归能够解决所有的二分类问题，因为Logistic回归的分界面是一个平面，因此对于线性不可分问题，Logistic回归将束手无策，需要借助更加复杂的分类器。 参考文献李宏毅机器学习2017年秋http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML17_2.html","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://uscair.club/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://uscair.club/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"author":{"name":"Wonder"}},{"title":"DBSCAN聚类算法","slug":"DBSCAN聚类算法","date":"2020-03-21T16:00:00.000Z","updated":"2020-03-21T16:00:00.000Z","comments":true,"path":"2020/03/22/DBSCAN聚类算法/","link":"","permalink":"http://uscair.club/2020/03/22/DBSCAN%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/","excerpt":"","text":"一，凸集与非凸集如下图：左为凸集。凸集指在范围R中任意一点的连线，连线上的每一个点都在范围R里。通常这一情况都在多边形出现，所以有些说凸多边形就是这么来的。右为非凸集，因为如图示的两点连线中，有部分点在R外头，不属于R，因此为非凸集。 二，DBSCAN原理DBSCAN聚类算法适用于非凸数据集，而上一次的K-Means聚类算法就不怎么适用。DBSCAN(Density-Based Spatial Clustering of Applications with Noise)是一个比较有代表性的基于密度的聚类算法。与划分和层次聚类方法不同，它将簇定义为密度相连的点的最大集合，能够把具有足够高密度的区域划分为簇，并可在噪声的空间数据库中发现任意形状的聚类。如下图： 系统在众多样本点中随机选中一个，围绕这个被选中的样本点画一个圆，规定这个圆的半径以及圆内最少包含的样本点，如果在指定半径内有足够多的样本点在内，那么这个圆圈的圆心就转移到这个内部样本点，继续去圈附近其它的样本点，类似传销一样，继续去发展下线。等到这个滚来滚去的圈发现所圈住的样本点数量少于预先指定的值，就停止了。那么我们称最开始那个点为核心点，如A，停下来的那个点为边界点，如B、C，没得滚的那个点为离群点，如N。 三，参数与概念半径（eps）：不断对比点之间的距离d，从小至大排列，当发现d的差异变大，则选前一个d为半径。 Minptx:圈内圈住的点个数。 Ε邻域：给定对象半径为Ε内的区域称为该对象的Ε邻域； 核心对象：如果给定对象Ε邻域内的样本点数大于等于MinPts，则称该对象为核心对象； 直接密度可达：对于样本集合D，如果样本点q在p的Ε邻域内，并且p为核心对象，那么对象q从对象p直接密度可达。 密度可达：对于样本集合D，给定一串样本点p1,p2….pn，p= p1,q= pn,假如对象pi从pi-1直接密度可达，那么对象q从对象p密度可达。 密度相连：存在样本集合D中的一点o，如果对象o到对象p和对象q都是密度可达的，那么p和q密度相联。 可以发现，密度可达是直接密度可达的传递闭包，并且这种关系是非对称的。密度相连是对称关系。DBSCAN目的是找到密度相连对象的最大集合。 四，优缺点。优点： 与K-means方法相比，DBSCAN不需要事先知道要形成的簇类的数量。 与K-means方法相比，DBSCAN可以发现任意形状的簇类。 同时，DBSCAN能够识别出噪声点。 DBSCAN对于数据库中样本的顺序不敏感，即Pattern的输入顺序对结果的影响不大。但是，对于处于簇类之间边界样本，可能会根据哪个簇类优先被探测到而其归属有所摆动。 可以在聚类的同时发现异常点，对数据集中的异常点不敏感。 聚类结果没有偏倚，相对的，K-Means之类的聚类算法初始值对聚类结果有很大影响。 缺点： DBScan不能很好反映高维数据。 DBScan不能很好反映数据集以变化的密度。 如果样本集的密度不均匀、聚类间距差相差很大时，聚类质量较差。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://uscair.club/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"聚类算法","slug":"聚类算法","permalink":"http://uscair.club/tags/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/"}],"author":{"name":"ffffff"}},{"title":"控制策略","slug":"PID控制","date":"2020-03-21T16:00:00.000Z","updated":"2020-03-21T16:00:00.000Z","comments":true,"path":"2020/03/22/PID控制/","link":"","permalink":"http://uscair.club/2020/03/22/PID%E6%8E%A7%E5%88%B6/","excerpt":"","text":"比例积分微分控制，简称PID控制因为以下优点被人们广泛使用于各个领域a. 技术成熟b. 易被人们熟悉和掌握c. 不需要建立数学模型d. 控制效果好e. 鲁棒性 通常依据控制器输出与执行机构的对应关系，将基本数字PID算法分为位置式PID和增量式PID两种。 位置离散PID公式：Pwm=Kpe (k) +KiZe(k) +Kd[e(k)-e(k-1) ]e(k):本次偏差.e(k-1): 上一次的偏差.Σe(k): e(k) 以及之前的偏差的累积和;其中k为1,2,……, k.Pwm代表输出.增量式离散PID公式：ΔPwm=Kp[e(k)-e(k-1)]+Ki*e(k) +Kd[e(k)- -2e(k-1)+e(k-2) ]e(k):本次偏差.e(k-1): 上一次的偏差.e(k-2): 上上次的偏差.ΔPwm代表增量输出. 比例环节：偏差一旦产生，控制器立即产生控制作用以减小误差。当偏差e=0时，控制作用也为0。因此，比例控制是基于偏差进行调节的，即有差调节。积分环节：能对误差进行记忆，主要用于消除静差，提高系统的无差度，积分作用的强弱取决于积分时间常数Ti，Ti越大，积分作用越弱，反之则越强。微分环节：能反映偏差信号的变化趋势(变化速率)，并能在偏差信号值变得太大之前，在系统中引入一个有效的早期修正信号，从而加快系统的动作速度，减小调节时间。从时间的角度讲，比例作用是针对系统当前误差进行控制，积分作用则针对系统误差的历史，而微分作用则反映了系统误差的变化趋势，这三者的组合是“过去、现在、未来”的完美结合. 下面将用输出波形图来细说PID：●最大超调量是响应曲线的最大峰值与稳态值的差，是评估系统稳定性的-一个重要指标;●上升时间是指响应曲线从原始工作状态出发,第一次到达输出稳态值所需的时间，是评估系.统快速性的一一个重要指标;●静差是被控量的稳定值与给定值之差，- -般用于衡量系统的准确性. 关于P、|、D三个参数的主要作用，可以大致又不完全地概况为:P用于提高响应速度、用于减小静差、D用于抑制震荡。KP=50,KiI=0,KD=0KP=500,KI=0,KD=0KP=500,KI=0,KD=400KP=120,KI=0.1,KD=500 位置实现代码：增量式PID：","categories":[{"name":"控制策略","slug":"控制策略","permalink":"http://uscair.club/categories/%E6%8E%A7%E5%88%B6%E7%AD%96%E7%95%A5/"}],"tags":[{"name":"控制","slug":"控制","permalink":"http://uscair.club/tags/%E6%8E%A7%E5%88%B6/"}],"author":{"name":"Page"}},{"title":"人工智能--常见算法(2)","slug":"人工智能--常见算法(2)","date":"2020-03-21T16:00:00.000Z","updated":"2020-03-21T16:00:00.000Z","comments":true,"path":"2020/03/22/人工智能--常见算法(2)/","link":"","permalink":"http://uscair.club/2020/03/22/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD--%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95(2)/","excerpt":"","text":"​ 算法在人工智能领域是十分重要的，人工智能根据模型训练方式不同分为监督学习，无监督学习，半监督学习，强化学习。 一.监督学习 （1）人工神神经网络：反向传播、波尔兹曼机、卷积神经网络、Hopfield网络、多层感知器、径向基函数网络、受限波尔兹曼机、回归神经网络、自组织映射、尖峰神经网络。 （2）贝叶斯类：朴素贝叶斯、高斯贝叶斯、多项朴素贝叶斯、平均-依赖性评估、贝叶斯信念网络、贝叶斯网络。 （3）决策树类：分类和回归树、迭代、C4.5算法、卡方自动交互检测、决策残端、ID3算法、随机森林、SLIQ。 （4）线性分类器类：Fisher的线性判别、线性回归、逻辑回归、多项逻辑回归、朴素贝叶斯分类器、感知、支持向量机。 常见的无监督学习类算法包括：（1） 人工神经网络类：生成对抗网络，前馈神经网络、逻辑学习机、自组织映射。 （2） 关联规则学习类：先验算法、Eclat算法、FP-Growth算法。 （3）分层聚类算法：单连锁聚类，概念聚类。 （4）聚类分析：BIRCH算法、DBSCAN算法，期望最大化、模糊聚类、K-means算法、K均值聚类、K-medians聚类、均值漂移算法、OPTICS算法。 （5）异常检测类：K最邻近算法，局部异常因子算法。 常见的半监督学习类算法包含：生成模型、低密度分离、基于图形的方法、联合训练。 常见的强化学习类算法包含：Q学习、状态-行动-奖励-状态-行动、DQN、策略梯度算法、基于模型强化学习、时序差分学习。 常见的深度学习类算法包含：深度信念网络、深度卷积神经网络、深度递归神经网络、分层时间记忆、深度波尔兹曼机、栈式自动编码器、生成对抗网络。 二、按照解决任务的不同来分类，粗略可以分为二分类算法、多分类算法、回归算法、聚类算法和异常检测五种。1.二分类：（1）二分类支持向量机：适用于数据特征较多、线性模型的场景。 （2）二分类平均感知器：适用于训练时间短、线性模型的场景。 （3）二分类逻辑回归：适用于训练时间短、线性模型的场景。 （4）二分类贝叶斯点机：适用于训练时间短、线性模型的场景。 （5）二分类决策森林：适用于训练时间短、精准的场景。 （6）二分类提升决策树：适用于训练时间短、精准度高、内存占用量大的场景 （7）二分类决策丛林：适用于训练时间短、精确度高、内存占用量小的场景。 （8）二分类局部深度支持向量机：适用于数据特征较多的场景。 （9）二分类神经网络：适用于精准度高、训练时间较长的场景。 解决多分类问题通常适用三种解决方案：第一种，从数据集和适用方法入手，利用二分类器解决多分类问题；第二种，直接使用具备多分类能力的多分类器；第三种，将二分类器改进成为多分类器今儿解决多分类问题。常用的算法：（1）多分类逻辑回归：适用训练时间短、线性模型的场景。 （2）多分类神经网络：适用于精准度高、训练时间较长的场景。 （3）多分类决策森林：适用于精准度高，训练时间短的场景。 （4）多分类决策丛林：适用于精准度高，内存占用较小的场景。 （5）“一对多”多分类：取决于二分类器效果。 回归：回归问题通常被用来预测具体的数值而非分类。除了返回的结果不同，其他方法与分类问题类似。我们将定量输出，或者连续变量预测称为回归；将定性输出，或者离散变量预测称为分类。长巾的算法有：（1）排序回归：适用于对数据进行分类排序的场景。 （2）泊松回归：适用于预测事件次数的场景。 （3）快速森林分位数回归：适用于预测分布的场景。 （4）线性回归：适用于训练时间短、线性模型的场景。 （5）贝叶斯线性回归：适用于线性模型，训练数据量较少的场景， （6）神经网络回归：适用于精准度高、训练时间较长的场景。 （7）决策森林回归：适用于精准度高、训练时间短的场景。 （8）提升决策树回归：适用于精确度高、训练时间短、内存占用较大的场景。 聚类：聚类的目标是发现数据的潜在规律和结构。聚类通常被用做描述和衡量不同数据源间的相似性，并把数据源分类到不同的簇中。（1）层次聚类：适用于训练时间短、大数据量的场景。 （2）K-means算法：适用于精准度高、训练时间短的场景。 （3）模糊聚类FCM算法：适用于精确度高、训练时间短的场景。 （4）SOM神经网络：适用于运行时间较长的场景。异常检测：异常检测是指对数据中存在的不正常或非典型的分体进行检测和标志，有时也称为偏差检测。异常检测看起来和监督学习问题非常相似，都是分类问题。都是对样本的标签进行预测和判断，但是实际上两者的区别非常大，因为异常检测中的正样本（异常点）非常小。常用的算法有：（1）一分类支持向量机：适用于数据特征较多的场景。 （2）基于PCA的异常检测：适用于训练时间短的场景。 常见的迁移学习类算法包含：归纳式迁移学习 、直推式迁移学习、无监督式迁移学习、传递式迁移学习。 常用算法： 1.决策树： （1）决策树(Decision Tree)是在已知各种情况发生概率的基础上，通过构成决策树来求取净现值的值大于等于零的概率，评价项目风险，判断其可行性的决策分析方法，是直观运用概率分析的一种图解法。由于这种决策分支画成图形很像一棵树的枝干，故称决策树。在机器学习中，决策树是一个预测模型，他代表的是对象属性与对象值之间的一种映射关系。Entropy = 系统的凌乱程度，使用算法和C5.0生成树算法使用熵。这一度量是基于信息学理论中熵的概念。 （2）决策树是一种树形结构，其中每个内部节点表示一个属性上的测试，每个分支代表一个测试输出，每个叶节点代表一种类别。 （3）分类树(决策树)是一种十分常用的分类方法。 2.随机森林： （1） 在机器学习中，随机森林是一个包含多个决策树的分类器， 并且其输出的类别是由个别树输出的类别的众数而定。 PS： 分类器:分类器就是给定一个样本的数据，判定这个样本属于哪个类别的算法。 3.逻辑回归：https://blog.csdn.net/weixin_39445556/article/details/83930186 此博文详细介绍了逻辑回归和回归的区别","categories":[{"name":"人工智能","slug":"人工智能","permalink":"http://uscair.club/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"算法学习","slug":"算法学习","permalink":"http://uscair.club/tags/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/"}],"author":{"name":"HL"}},{"title":"人工智能的特征","slug":"人工智能的特征","date":"2020-03-21T10:47:40.499Z","updated":"2020-03-21T10:47:40.499Z","comments":true,"path":"2020/03/21/人工智能的特征/","link":"","permalink":"http://uscair.club/2020/03/21/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E7%89%B9%E5%BE%81/","excerpt":"","text":"由人类设计，为人类服务，本质为计算，基础为数据从根本上来说，人工智能系统必须要以人为本，因为这些机器是人类按照自己的思维设计出来的机器，而它的本质就是计算，通过对数据的采集、加工、处理、分析和挖掘，形成对人类有价值的信息流和数据模型，来为人类提供延伸人类能力的服务，来实现对人类有益的服务，在理想的情况下必须体现服务人类的特点，而不该伤害人类。 能感知环境，能产生反应，能与人交互，能与人互补人工智能通过对外界环境的感知，可以象人一样识别外界环境发出的信息，比如说，人的五觉：听觉、视觉、味觉、嗅觉、触觉。人与机器人之间的互动，可以是机器越来越理解人类乃至同人类共同协作、优势互补。这样的话、人工智能可以帮助人类作不善长、不喜欢但机器可以完成的工作。把人类从复杂、繁琐的具体劳动中解放出来，让人类有更多的时间可以去做创造性、洞察力想象力、灵活性、多变性的抽象劳动。 有适应特性，有学习能力，有演化迭代，有连接扩展人工智能系统在理想情况下有一定的自适应和学习能力，即具有随着环境、数据的改变而适应，保持同人类的思维一样的高度，不断地更新，随着人类社会的发展而不断向前发展。","categories":[{"name":"人工智能","slug":"人工智能","permalink":"http://uscair.club/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://uscair.club/tags/OpenCV/"}],"author":{"name":"不败顽童"}},{"title":"C++编写函数连接两个字符串，不用系统函数","slug":"C++编写函数连接两个字符串，不用系统函数","date":"2020-03-20T16:00:00.000Z","updated":"2020-03-20T16:00:00.000Z","comments":true,"path":"2020/03/21/C++编写函数连接两个字符串，不用系统函数/","link":"","permalink":"http://uscair.club/2020/03/21/C++%E7%BC%96%E5%86%99%E5%87%BD%E6%95%B0%E8%BF%9E%E6%8E%A5%E4%B8%A4%E4%B8%AA%E5%AD%97%E7%AC%A6%E4%B8%B2%EF%BC%8C%E4%B8%8D%E7%94%A8%E7%B3%BB%E7%BB%9F%E5%87%BD%E6%95%B0/","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132333435363738#include &lt;iostream&gt;using namespace std;#include &lt;string.h&gt;void Myappend(char t1[],char t2[]);//用于连接字符串的函数int my_strlen(const char *str);//用于计算字符数组的长度int main()&#123; char a[20],b[20];//定义数组用于储存字符串 cout&lt;&lt;\"Please enter a string:\"&lt;&lt;endl; cin&gt;&gt;a; cout&lt;&lt;\"Please enter a string:\"&lt;&lt;endl; cin&gt;&gt;b; Myappend(a,b); return 0;&#125;void Myappend(char t1[],char t2[])&#123; int len1,len2; len1=my_strlen(t1); len2=my_strlen(t2);//获得字符串长度 for(int i=0; i&lt;=len2; i++) t1[len1+i]=t2[i];//将b字符串的头部赋给a字符串的尾部,并依此赋值 cout&lt;&lt;t1&lt;&lt;endl;&#125;int my_strlen(const char *str)&#123; int count =0; while(*str !='\\0') &#123; count++; str++; &#125; return count;&#125;","categories":[{"name":"C++","slug":"C","permalink":"http://uscair.club/categories/C/"}],"tags":[{"name":"字符串","slug":"字符串","permalink":"http://uscair.club/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"}],"author":{"name":"BF"}},{"title":"从AlexNet看CNN","slug":"从AlexNet看CNN","date":"2020-03-20T16:00:00.000Z","updated":"2020-03-20T16:00:00.000Z","comments":true,"path":"2020/03/21/从AlexNet看CNN/","link":"","permalink":"http://uscair.club/2020/03/21/%E4%BB%8EAlexNet%E7%9C%8BCNN/","excerpt":"","text":"AlexNet的成功之处AlexNet将LeNet的思想发扬光大，把CNN的基本原理应用到了很深很宽的网络中。AlexNet主要使用到的新技术点如下。 （1）成功使用ReLU作为CNN的激活函数，并验证其效果在较深的网络超过了Sigmoid，成功解决了Sigmoid在网络较深时的梯度消失问题。 （2）训练时使用Dropout随机忽略一部分神经元，以避免模型过拟合。在AlexNet中主要是最后几个全连接层使用了Dropout。 （3）在CNN中使用重叠的最大池化。此前CNN中普遍使用平均池化，AlexNet全部使用最大池化，避免平均池化的模糊化效果。并且AlexNet中提出让步长比池化核的尺寸小，这样池化层的输出之间会有重叠和覆盖，提升了特征的丰富性。 （4）提出了LRN层，对局部神经元的活动创建竞争机制，使得其中响应比较大的值变得相对更大，并抑制其他反馈较小的神经元，增强了模型的泛化能力。 AlexNet paper传送门 处理方法 作用 ReLU、多GPU训练 提高训练速度 重叠池化 提高精度、不易过拟合 局部响应归一化 提高精度 Dropout 减少过拟合 激活函数ReLU 一般激活函数有如下一些性质： 非线性： 当激活函数是线性的，一个两层的神经网络就可以基本上逼近所有的函数。但如果激活函数是恒等激活函数的时候，即f(x)=x，就不满足这个性质，而且如果MLP使用的是恒等激活函数，那么其实整个网络跟单层神经网络是等价的； 可微性： 当优化方法是基于梯度的时候，就体现了该性质； 单调性： 当激活函数是单调的时候，单层网络能够保证是凸函数； f(x)≈x： 当激活函数满足这个性质的时候，如果参数的初始化是随机的较小值，那么神经网络的训练将会很高效；如果不满足这个性质，那么就需要详细地去设置初始值； 输出值的范围： 当激活函数输出值是有限的时候，基于梯度的优化方法会更加稳定，因为特征的表示受有限权值的影响更显著；当激活函数的输出是无限的时候，模型的训练会更加高效，不过在这种情况小，一般需要更小的Learning Rate。 在深度神经网络中，通常使用一种叫修正线性单元(Rectified linear unit，ReLU）作为神经元的激活函数。ReLU起源于神经科学的研究：2001年，Dayan、Abott从生物学角度模拟出了脑神经元接受信号更精确的激活模型。 sigmoid sigmoid是通过$f(z)=\\frac{1}{1+e^{-z}}$把它输入实数值并将其“挤压”到0到1范围内，适合输出为概率的情况。 对sigmoid求导 但是sigmoid函数的导数在0的时候取到最大值为0.25。易知利用梯度下降算法的时候容易造成梯度消失。 relu 对relu求导 它与sigmoid相比有几大优点： 在正区间内解决了梯度消失的问题 少了次方计算，计算速度加快 Dropout在机器学习的模型中，如果模型的参数太多，而训练样本又太少，训练出来的模型很容易产生过拟合的现象。在训练神经网络的时候经常会遇到过拟合的问题，过拟合具体表现在：模型在训练数据上损失函数较小，预测准确率较高；但是在测试数据上损失函数比较大，预测准确率较低。 Dropout说的简单一点就是：我们在前向传播的时候，让某个神经元的激活值以一定的概率p停止工作，这样可以使模型泛化性更强，因为它不会太依赖某些局部的特征。 正常的神经网络先通过前向传播然后把误差通过反向传播更新参数，利用神经网络来学习 而使用了dropout的神经网络就按一定概率删除一部分神经元。 把dropout后的网络通过前向传播，然后把误差通过反向传播，神经网络学习，然后按梯度下降来更新参数；在恢复删除掉的神经元，到隐藏层随机选择一个子集临时删除掉，然后通过前向传播反向传播在用梯度下降算法更新参数不断重复这一过程。 在训练时增加一个一次概率删除 没有dropout的神经网络 有dropout的神经网络 数据扩充可以通过图像增广实现数据扩充 torchvision.transforms对于多种变换可以使用torchvision.transforms.Compose来合并。 LRN局部响应归一化在神经生物学有一个概念叫做“侧抑制”（lateral inhibitio），指的是被激活的神经元抑制相邻神经元。归一化（normalization）的目的是“抑制”，局部归一化就是借鉴了“侧抑制”的思想来实现局部抑制，尤其当使用ReLU时这种“侧抑制”很管用，因为ReLU的响应结果是无界的（可以非常大），所以需要归一化。使用局部归一化的方案有助于增加泛化能力。 AlexNet的结构 第一层（卷积层） 该层的处理流程为：卷积–&gt;ReLU–&gt;池化–&gt;归一化 卷积 在本层使用96个步长为4的11×11×3的卷积核进行卷积计算，其大小为：$$floor[(\\frac{img_size - filter_size+2\\times padding}{stride}) +1] = new_feature_size$$其中floor表示向下取整，img_size为图像大小，filter_size为核大小，stride为步长，new_feature_size为卷积后的特征图大小,pading为填充数目，这个公式表示图像尺寸减去卷积核尺寸除以步长，再加上被减去的核大小像素对应生成的一个像素，结果就是卷积后特征图的大小。 得到的特征图大小为55x55，由于采用了两个GPU并行运算，因此，网络结构图中上下两部分分别承担了48个卷积核的运算。所以尺寸为2组55×55×48的像素层数据。 激活 卷积后的55×55像素层经过ReLU单元的激活，生成激活层，尺寸仍为2组55×55×48的像素层数据。 池化 激活再经过池化运算，池化运算的尺寸为3×3，步长为2，则池化后图像的尺寸为 (55-3)/2+1=27，即池化后特征图的规模为27×27×96 归一化 池化后再进行归一化处理，归一化运算的尺寸为5×5，归一化后的像素规模不变，仍为27×27×96，这96层像素层被分为两组，每组48层，分别在一个独立的GPU上进行运算。 第二层（卷积层）该层与第一层类似，处理流程为：卷积–&gt;ReLU–&gt;池化–&gt;归一化 卷积 每一组经过128个5x5x3的卷积核其中padding=2，stride=1，所以得到的特征图为27x27x128，其中每个GPU为27x27x128 激活 然后经过relu激活 池化 每一组经过128个3x3，stride=2的池化，得到2组13x13x128的像素层 归一化 归一化运算的尺度为5×5 第三层（卷积层） 第三层的处理流程为：卷积–&gt;ReLU 卷积 每一组经过192个大小为3x3x256，padding=1，stride=1的卷积核得到2组13×13×192的像素层 激活 通过relu激活 第四层（卷积层） 第四层的处理流程为：卷积–&gt;ReLU 卷积 每一组经过过192个大小为3×3×192，stride=1，padding=1（与第三层不同，第四层的GPU之间没有虚线连接，也即GPU之间没有通信）得到大小为13×13×192的特征图 激活 通过relu激活 第五层（卷积层） 第五层的处理流程为：卷积–&gt;ReLU–&gt;池化 卷积 每一组经过128个3x3，padding=1，stride=1的卷积，得到13×13×128像素层 激活 通过relu激活 池化 2组13×13×128像素层分别在2个不同GPU中进行池化运算处理，池化运算的尺寸为3×3，步长为2，池化后图像的尺寸为 (13-3)/2+1=6，即池化后像素的规模为两组6×6×128的像素层数据，共有6×6×256的像素层数据。 第六层（全连接层） 第六层的处理流程为：卷积（全连接）–&gt;ReLU–&gt;Dropout 卷积（全连接） 第六层输入数据是第五层的输出，尺寸为6×6×256。本层共有4096个卷积核，每个卷积核的尺寸为6×6×256，由于卷积核的尺寸刚好与待处理特征图（输入）的尺寸相同，即卷积核中的每个系数只与特征图（输入）尺寸的一个像素值相乘，一一对应，因此，该层被称为全连接层。由于卷积核与特征图的尺寸相同，卷积运算后只有一个值，因此，卷积后的像素层尺寸为4096×1×1，即有4096个神经元。 激活 通过relu激活 Dropout 然后再通过Dropout运算，输出4096个结果值。 第七层（全连接层） 第七层的处理流程为：全连接–&gt;ReLU–&gt;Dropout 第六层输出的4096个数据与第七层的4096个神经元进行全连接，然后经ReLU进行处理后生成4096个数据，再经过Dropout处理后输出4096个数据。 第八层（全连接层） 第八层的处理流程为：全连接 第七层输出的4096个数据与第八层的1000个神经元进行全连接，经过训练后输出1000个float型的值，这就是预测结果。 实现代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149#!/usr/bin/env python# coding: utf-8# In[ ]:import timeimport torchfrom torch import nn, optimimport torchvision# In[ ]:device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')# In[4]:device# In[ ]:class AlexNet(nn.Module): def __init__(self): super(AlexNet,self).__init__() self.conv=nn.Sequential( nn.Conv2d(1,96,11,4), # in_channels, out_channels, kernel_size, stride, padding nn.ReLU(), nn.MaxPool2d(3,2), # kernel_size,stride nn.Conv2d(96,256,5,1,2), nn.ReLU(), nn.MaxPool2d(3,2), nn.Conv2d(256,384,3,1,1), nn.ReLU(), nn.Conv2d(384,384,3,1,1), nn.ReLU(), nn.Conv2d(384,256,3,1,1), nn.ReLU(), nn.MaxPool2d(3,2), ) self.fc=nn.Sequential( nn.Linear(256*5*5,4096), nn.ReLU(), nn.Dropout(0.5), # 使用dropout防止过拟合 nn.Linear(4096,4096), nn.ReLU(), nn.Dropout(0.5), nn.Linear(4096,10) ) def forward(self,img): feature=self.conv(img) output=self.fc(feature.view(img.shape[0],-1)) return output# In[6]:net=AlexNet()print(net) # 打印神经网络的结构# In[ ]:def load_data_fashion_mnist(batch_size, resize=None, root='~/Datasets/FashionMNIST'): \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\" trans = [] if resize: trans.append(torchvision.transforms.Resize(size=resize)) # 更改PIL图像的大小 trans.append(torchvision.transforms.ToTensor()) # 将形状为(HxWxC)PIL的图像转为形状为(CxHxW)的FloatTensor transform = torchvision.transforms.Compose(trans) # 一起组成一个变换 mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform) mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform) train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4) test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=4) return train_iter, test_iter# In[ ]:def evaluate_accuracy(data_iter,net,device=None): if device is None and isinstance(net, nn.Module): device=list(net.parameters())[0].device # 运行设备为net所运行的设备 acc_sum,n=0.0,0 with torch.no_grad(): # 禁用梯度计算 for X,y in data_iter: if isinstance(net, nn.Module): net.eval() # 不启用 BatchNormalization 和 Dropout acc_sum+=(net(X.to(device)).argmax(dim=1)==y.to(device)).float().sum().cpu().item() net.train() # 启用 BatchNormalization 和 Dropout else: if('is training' in net.__code__.co_varnames): acc_sum+=(net(X, is_training=False).argmax(dim=1)==y).float().sum().item() else: acc_sum+=(net(X).argmax(dim=1)==y).float().sum().item() n+=y.shape[0] return acc_sum/n# In[ ]:def train(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs): net = net.to(device) print(\"training on \", device) loss = torch.nn.CrossEntropyLoss() for epoch in range(num_epochs): train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time() for X, y in train_iter: X = X.to(device) y = y.to(device) y_hat = net(X) l = loss(y_hat, y) optimizer.zero_grad() l.backward() # 把参数通过反向传播来优化 optimizer.step() # 更新参数 train_l_sum += l.cpu().item() train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item() # softMax：y_hat.argmax(dim=1) n += y.shape[0] batch_count += 1 test_acc = evaluate_accuracy(test_iter, net) print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec' % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))# In[ ]:batch_size=128# 如出现“out of memory”的报错信息，可减小batch_size或resizetrain_iter,test_iter=load_data_fashion_mnist(batch_size=batch_size,resize=224)# In[14]:lr,num_epochs=0.001,5optimizer=optim.Adam(net.parameters(),lr=lr)train(net,train_iter,test_iter,batch_size=batch_size,optimizer=optimizer,device=device,num_epochs=num_epochs)","categories":[{"name":"神经网络","slug":"神经网络","permalink":"http://uscair.club/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"CNN","slug":"CNN","permalink":"http://uscair.club/tags/CNN/"}],"author":{"name":"Gowi"}},{"title":"深度学习介绍(深度学习是什么?)","slug":"深度学习介绍-深度学习是什么","date":"2020-03-15T12:59:00.000Z","updated":"2020-03-15T12:59:00.000Z","comments":true,"path":"2020/03/15/深度学习介绍-深度学习是什么/","link":"","permalink":"http://uscair.club/2020/03/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BB%8B%E7%BB%8D-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%98%AF%E4%BB%80%E4%B9%88/","excerpt":"","text":"深度学习 - What is this?深度学习深度学习（英语：Deep Learning）是机器学习的分支，是一种以 人工神经网络 为架构，对数据进行 表征学习 的算法。它基于一种算法，通过线性或非线性的转换，尝试使用多个处理层的深度图来对数据中的高级抽象经行建模。 深度学习 是 机器学习 的技术和研究领域之一，通过建立具有阶层结构的 人工神经网络（Artifitial Neural Networks, ANNs） ，在计算系统中实现人工智能。由于阶层ANN能够对输入信息进行逐层提取和筛选，因此深度学习具有 表征学习（representation learning） 能力，可以实现端到端的 ·监督学习· 和 ·非监督学习· 。此外，深度学习也可参与构建 强化学习（reinforcement learning） 系统，形成深度强化学习。深度学习所使用的阶层 ANN 具有多种形态，其阶层的复杂度被通称为深度。 深度学习是学习样本数据的内在规律和表示层次，这些学习过程中获得的信息对 诸如文字， 图像和声音等数据的解释有很大的帮助。它的最终目标是让机器能够像人一样具有分析学习 能力，能够识别文字、图像和声音等数据。表征学习 机器学习系统的性能主要取决于向系统提供的数据，这称为数据表征（表征是指信息记载或表达的方式，我们可以这样理解，表征是指可以指代某种东西的符号或信号）。与表征相关的所有信息成为数据的特征（特征是一个客体或一组客体特性的抽象结果）。 计算机通过数据表征进行处理来完成我们预设给他的任务。机器学习系统对数据表征的依赖对我们来说并非是未知的，大多数计算机理论都是基于数据表征而表现更好。 表征学习可以定义为：根据数据当前层的表征来推断下一层数据的表征。表征学习算法都有的优势：它 捕获隐藏的因素 ，而这一子集可能适用于每个特定的子任务。 例如:在对数字进行识别的MLP神经网络中，倒数第二层中就可认为是 捕获的隐藏的因素 – 各数字的可能组成部分。这些隐藏因素都有可能对应到输出层的各个数字(分类为哪个数字)。 深度学习模型 深度学习是机器学习的一个子领域。通过构建多层的表征或从一系列表征和特征中学习一个具有层次的结构的特征集，深度学习能解决表征学习的主要问题。 深度学习模型， 例如：图片识别模型 在图片识别时，我们希望给出一个图片img，计算机能直接告诉我们图片的结果（例如读取图片分类出数字）。想象成通过图片像素点的数据，通过一个函数F(img),直接识别出图片。 F(img)是一个直接映射，但计算机几乎是不可能对这类映射直接训练的。 但为了应付这些类型的任务，深度学习会创建连接至期待输出的一系列映射子集，来解决这些问题。 当然，这里直接通过图片得出判断也可能是不可取的，但还能继续将任务分解。 深度神经网络模型 : 其通过对映射的一层层抽象出来，最终完成最终映射 映射的每个子集对应于模型的一个层，输入层(img的像素值)包含了可观察变量，处于可见层。而中间的子映射从输入中逐层提取数据的抽象特征，这些抽象的值在给定数据中是不可用或不可见的，所以这些层也被称为 隐藏层 。 神经网络 神经网络是很早的一个概念，它是一种模仿动物神经网络行为特征，进行分布式并行信息处理的算法数学模型。这种网络依靠系统的复杂程度，通过调整内部大量节点之间相互连接的关系，从而达到处理信息的目的。深度学习其实就是一个具有阶层结构的人工神经网络，可以认为深度学习是神经网络的一个品牌。 其主要可以描述为： 神经网络主要为分为3个层级，输入层、隐含层、输出层，而每一层由多个神经元组成 神经元获取所有上一层神经元的输出统计计算后得到一个新的输出 每一个的神经元其实可以理解为一个函数实体，有多个输入值，而输出一个输出值 再这个函数中会对每一个输入乘以一个权重（0-1）再加/减一个阈值，整体求和后用一种规格化函数（激活函数）将输出进行整理到一个新的的输出值 以此类推得到最终的输出 当然这里描述的是常见的神经网络（neural networks） 深度前馈网络 神经网络可以是循环的或前馈的。简单来说，具有两层或者更多(隐藏)层的神经网络被定义为深度前馈网络，也叫作前馈神经网络或者多层感知机，是典型的深度学习模型。 深度前馈网络的原理是，随着深度的增加，网络可以执行跟多的顺序指令。顺序指令可以提供很大的威力，因为它们可以指向较早的指令。 前馈网络的目标是近似某个函数$f$。 例如，对于分类器，$y = f(x)$将输入$x$映射到一个类别$y$。 前馈网络定义了一个映射$y = f(x; \\theta)$，并且学习参数$\\theta$的值，使它能够得到最佳的函数近似。 这种模型被称为前向的，是因为信息流过$x$的函数，流经用于定义$f$的中间计算过程，最终到达输出$y$。 在模型的输出和模型本身之间没有反馈连接。 当前馈神经网络被扩展成包含反馈连接时，它们被称为循环神经网络，在后面介绍。 其它相关术语$\\nabla$ 深度神经网络（Deep Neural Networks）可以将深度神经网络定义为具有多个隐藏层的多层感知器。$\\nabla$ 循环神经网络（Recurrent Neural Networks) 是一类以序列（sequence）数据为输入，在序列的演进方向进行递归（recursion）且所有节点（循环单元）按链式连接的递归神经网络（recursive neural network）$\\nabla$ 深度信念网络（Deep Belief Networks） 可以定义为具有可见层和多个(隐藏)潜在变量层的概率生成模型。既可以用于非监督学习，类似于一个自编码机；也可以用于监督学习，作为分类器来使用。DBN由若干层神经元构成，组成元件是受限玻尔兹曼机（RBM）。$\\nabla$ 玻尔兹曼机（Boltzmann Machine） 是第一个受统计力学启发的多层学习机，它是一类典型的随机神经网络属于反馈神经网络类型 。其命名来源于Boltzmann在统计热力学中的早期工作和网络本身的动态分布行为 。其具有简单的学习算法，可以从训练数据集中发现代表复杂规律的许多有趣特征。$\\nabla$ 受限玻尔兹曼机（Restricted Boltzmann Machine） 是一种可通过输入数据集学习概率分布的随机生成神经网络。受限玻兹曼机在降维、分类、协同过滤、特征学习和主题建模中得到了应用。根据任务的不同，受限玻兹曼机可以使用监督学习或无监督学习的方法进行训练。$\\nabla$ 卷积神经网络（Convolutional Neural Networks） 是一类包含卷积计算且具有深度结构的前馈神经网络（Feedforward Neural Networks），是深度学习的代表算法之一。卷积神经网络具有表征学习（representation learning）能力，能够按其阶层结构对输入信息进行平移不变分类（shift-invariant classification），因此也被称为“平移不变人工神经网络。 $\\nabla$ 深度自动编码器（Deep Auto-encoder） 是一种具有多个隐藏层的自动编码器。自动编码器(autoencoder) 是神经网络的一种，该网络可以看作由两部分组成：一个编码器函数h = f(x) 和一个生成重构的解码器r = g(h)。传统上，自动编码器被用于降维或特征学习。 $\\nabla$ 梯度下降（Gradient Descent） 梯度下降是迭代法的一种,可以用于求解最小二乘问题(线性和非线性都可以)。在求解机器学习算法的模型参数，即无约束优化问题时，梯度下降（Gradient Descent）是最常采用的方法之一。 $\\nabla$ 随机梯度下降（Stochastic Gradient Descent） 一种梯度下降的优化算法，能更快地使计算机获得想要的最优解。 关于提及的相关知识将再后面以专题出现。","categories":[{"name":"深度学习专栏","slug":"深度学习专栏","permalink":"http://uscair.club/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E6%A0%8F/"}],"tags":[{"name":"AI大数据","slug":"AI大数据","permalink":"http://uscair.club/tags/AI%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"author":{"name":"戴挽舟（BbiHH）"}},{"title":"数字图像处理的简要知识","slug":"数字图像处理的简要知识","date":"2020-03-15T09:30:00.000Z","updated":"2020-03-15T09:30:00.000Z","comments":true,"path":"2020/03/15/数字图像处理的简要知识/","link":"","permalink":"http://uscair.club/2020/03/15/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%9A%84%E7%AE%80%E8%A6%81%E7%9F%A5%E8%AF%86/","excerpt":"","text":"数字图像处理一、基本概念 数字图像处理是通过计算机对图像进行去除噪声、增强、复原、分割、提取特征等处理的方法和技术。将图像信号转换成数字信号并利用计算机对其进行处理的过程。二、常用方法1）图像变换：傅立叶变换、沃尔什变换、离散余弦变换等间接处理技术，将空间域的处理转换为变换域处理。2）图像编码压缩：可减少描述图像的数据量（即比特数），以便节省图像传输、处理时间和减少所占用的存储器容量。压缩可在不失真的前提下获得，也可以在允许的失真条件下进行。3）图像增强和复原：目的是为了提高图像的质量，如去除噪声、提高图像的清晰度等。图像增强不考虑图像降质的原因，图出图像中感兴趣的部分；图像复原要求对图像降质的原因有一定的了解，一般根据降质过程建立“降质模型”，再考虑采用某种滤波方法，恢复或重建原来的图像。4）图像分割：将图像中有意义的特征部分提取出来，其有意义的特征有图像的边缘、区域等。5）图像描述：最简单的二值图像可采用其几何特征描述物体的特性，一般图像的描述方法采用二维形状描述；特殊的纹理图像可采用二维纹理特征描述。6）图像分类（识别）：主要内容是图像经过某些预处理后，进行图像分割和特征提取，从而进行判决分类。图像分类常采用经典的模式识别方法，有统计模式分类和句法模式分类。三、主要目的1）提高图像的视感质量。2）提取图像中所包含的某些特征或特殊信息，这些被提取的特征或信息往往为计算机分析图像提供便利。3）图像数据的变换、编码和压缩，以便于图像的存储和传输。四、应用领域1）航天和航空方面2）生物医学工程方面3）通信工程方面4）工业和工程方面5）军事公安方面6）文化艺术方面7）机器人视觉8）视频和多媒体系统9）科学可视化10）电子商务 这是一些知识的简单了解，以后会慢慢学习，进一步深入了解。","categories":[{"name":"openCV","slug":"openCV","permalink":"http://uscair.club/categories/openCV/"},{"name":"图片变化","slug":"openCV/图片变化","permalink":"http://uscair.club/categories/openCV/%E5%9B%BE%E7%89%87%E5%8F%98%E5%8C%96/"}],"tags":[{"name":"图像处理","slug":"图像处理","permalink":"http://uscair.club/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}],"author":{"name":"风车车"}},{"title":"计算机网络原理学习（二）","slug":"计算机网络原理（二）","date":"2020-03-15T08:38:45.356Z","updated":"2020-03-15T08:38:45.356Z","comments":true,"path":"2020/03/15/计算机网络原理（二）/","link":"","permalink":"http://uscair.club/2020/03/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86%EF%BC%88%E4%BA%8C%EF%BC%89/","excerpt":"","text":"三、计算机网络的性能特征 1.吞吐量：表示在单位时间内通过某个网络（或信道、接口）的实际的数据量，常用于对现实世界中的网络的一种测量，以便知道实际上到底有多少数据量能够通过网络。 2.带宽：本来指某个信号的频带带宽（一个信号所包含谐波的最高频率与最低频率之差，即该信号所拥有的频率范围）信号的带宽指信号所包含的各种不同频率成分所占据的频率范围。在网络原理中是数据率的单位bit/s。 3.速率：即为比特率bit/s，bit就是二进制数字0或1 4.时延：总时延=（1）发送时延+（2）传播时延+（3）处理时延+（4）排队时延。 （1）主机或路由器发送数据帧所需要的时间。（2）：电磁波在信道中传播一定的距离需要花费的时间。（3）：主机或路由器收到分组花费来处理的时间。 （4）：分组在进入路由器后在输入队列中排队等候处理。 5.时延带宽积（以比特为单位的链路长度） 时延带宽积=传播时延x带宽 6.往返时间RTT)7.利用率 利用率分为信道利用率（信道有百分之几的时间是被利用的，并不是越大越好，信道利用率变大，信道引起的时延也变大）和网络利用率（全网络的信道利用率的加权平均值）俩种。 网络当前时延=网络空闲时的时延/（1-利用率） 下图为时延与利用率的关系当网络的利用率达到其容量的1/2时，时延就会加倍，趋于1时，网络时延趋于无穷大——信道或网络利用率过高会产生非常大的时延。 四、计算机网络的非性能特征 1．费用 2．质量（网络可靠性、网络管理的简易性等） 3．标准化（网络的硬件和软件的设计既可以按照通用的国际标准，也可以遵循特定的专用网络标准。最好采用国际标准的设计，这样可以得到更好的互操作性，更易于升级换代和维修，也更容易得到技术上的支持） 4．可靠性（与网络质量和性能有关） 5．可扩展性和可升级性 6.易于管理和维护 五、网络的协议与划分层次 1．网络协议三要素：语法（数据与控制信息的结构或格式），语义（要发出何种控制信息，完成何种动作，做出何种响应），同步（事件实现顺序的详细说明） 2．划分层次划分层次的好处 （1）：各层之间相互独立 （2）灵活性好：当任何一层发生变化时(例如由于技术的变化)，只要层间接口关系保持不变，则在这层以上或以下各层均不受影响。此外，对某一层提供的服务还可进行修改当某层提供的服务不再需要时，甚至可以将这层取消。 （3）结构上可分割开：各层都可以采用最合适的技术来实现 （4）易于实现和维护 （5）能促进标准化工作 各层要完成的功能： [1]:差错控制 [2]:流量控制 [3]:分段和重装 [4]:复用和分用 [5]:连接建立和释放计算机网络的体系结构是这个计算机网络及其构件所应完成的功能的精准定义（或计算机网络的各层及其协议的集合）","categories":[{"name":"网络原理","slug":"网络原理","permalink":"http://uscair.club/categories/%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86/"}],"tags":[{"name":"网络原理","slug":"网络原理","permalink":"http://uscair.club/tags/%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86/"}],"author":{"name":"Page"}},{"title":"几个新手入门代码","slug":"几个新手入门代码","date":"2020-03-15T03:10:43.000Z","updated":"2020-03-15T03:10:43.000Z","comments":true,"path":"2020/03/15/几个新手入门代码/","link":"","permalink":"http://uscair.club/2020/03/15/%E5%87%A0%E4%B8%AA%E6%96%B0%E6%89%8B%E5%85%A5%E9%97%A8%E4%BB%A3%E7%A0%81/","excerpt":"","text":"几个简单的代码Python的两种变成方式&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;交互式和文件式——交互式：对每个输入语句即时运行，适合语法练习——文件式：批量执行一组语句并执行结果，编程的主要方式 在开始里面打开IDLE 1.圆面积的计算交互式：在IDLE中输入以下代码 1234r=25area=3.1415*r*rprint(area)print(\"&#123;:.2f&#125;\".format(area)) 文件式1.在IDLE中 File-&gt;new File2.输入上面一样的代码，点击Run Module先保存为CalCircle.py文件，再运行运行结果： 2.绘制多个同切圆按照上述方法利用交互式和文件式输入以下代码 123456import turtleturtle.pensize(2)turtle.circle(10)turtle.circle(40)turtle.circle(80)turtle.circle(160) 运算结果： 3.五角星绘制输入以下的代码 12345678from turtle import*color('red','red')begin_fill()for i in range(5): fd(200) rt(144)end_fill()done() 运算结果： 好了，结束啦。可以动手试一下","categories":[{"name":"Python","slug":"Python","permalink":"http://uscair.club/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://uscair.club/tags/Python/"}],"author":{"name":"starwma"}},{"title":"新手安装Python3教程","slug":"新手安装Python3教程","date":"2020-03-15T03:10:43.000Z","updated":"2020-03-15T03:10:43.000Z","comments":true,"path":"2020/03/15/新手安装Python3教程/","link":"","permalink":"http://uscair.club/2020/03/15/%E6%96%B0%E6%89%8B%E5%AE%89%E8%A3%85Python3%E6%95%99%E7%A8%8B/","excerpt":"","text":"下载安装Python3下载网页： https://www.python.org///也可以直接在百度搜索python，进入官网1.点击Downloads-&gt;选择你电脑的系统（安卓）查看电脑操作系统 右击此电脑-&gt;属性 2.选择你要下载的版本（1）web-based installer 是需要通过联网完成安装的；（2）executable installer 是可执行文件(*.exe)方式安装；（本教程选的）（3）embeddable zip file 嵌入式版本，可以集成到其它应用中。 可以通过下面3种途径获取python：有web-based installer、executable installer、embeddable zip等版本，其中web-based installer指通过网络下载，文件小但需要网络环境；executable installer指下载安装文件，下载并安装后才能使用；embeddable zip指Python的zip压缩版，下载后无需安装，可以直接使用。 3.下载完成后安装过程建议放在根目录下自己选择安装路径，记住你安装的路径==勾选Add Python 3.7 to PATH==我选的是自己选择安装路径 下载完成啦 验证是否安装成功打开cmd 按WIN键（就是有电脑标识的键）+R键打开运行，输入cmd后回车进入命令提示符。 在cmd界面输入python显示Python的版本安装成功啦！你可以编写程序了","categories":[{"name":"Python","slug":"Python","permalink":"http://uscair.club/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://uscair.club/tags/Python/"}],"author":{"name":"starwma"}},{"title":"机器学习系列（七）——分类问题（classification）","slug":"机器学习系列（七）——分类问题（classification）","date":"2020-03-14T16:20:20.248Z","updated":"2020-03-14T16:20:20.248Z","comments":true,"path":"2020/03/15/机器学习系列（七）——分类问题（classification）/","link":"","permalink":"http://uscair.club/2020/03/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%83%EF%BC%89%E2%80%94%E2%80%94%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%EF%BC%88classification%EF%BC%89/","excerpt":"","text":"这一篇博客将介绍机器学习中另一个重要的任务——分类（classification），即找一个函数判断输入数据所属的类别，可以是二类别问题（是/不是），也可以是多类别问题（在多个类别中判断输入数据具体属于哪一个类别）。与回归问题（regression）相比，分类问题的输出不再是连续值，而是离散值，用来指定其属于哪个类别。分类问题在现实中应用非常广泛，比如垃圾邮件识别，手写数字识别，人脸识别，语音识别等。 思考首先思考一个问题，能不能用回归问题的解法去求解分类问题呢？以二分类问题为例，对于类别1，我们假设其目标值为1，对于类别2，假设其目标值为-1。在回归问题中，我们需要找到一个函数，使得函数的预测值尽可能的接近目标值。如下图所示，为了方便可视化，假设每个样本只用两维特征表示。 上图中，蓝色的点目标值是1，代表类别1；红色的点目标值是-1，代表类别2。现在需要找到一个函数对这些点进行拟合，如图中绿线所代表的函数b+w1x1+w2x2=0。对于一个样本点，如果其对应的函数值大于0，则认为其属于类别1，反之属于类别2。这么做看起来好像也是可以的，但现在我们考虑另外一种情况，如下图所示 此时，在类别1中加入了右下角这些点，如果仍然采用绿色那条线所代表的函数进行预测，这些新加入进来的点的误差将特别的大，为了缓解由此带来的误差，绿色的线将往右下角偏移，以此减少误差。但这么做明显是不符合常理的，误差虽然减少了，但也带来了更严重的分类类别错误问题。造成这个问题的本质是损失函数定义的不恰当，回归问题种将损失函数定位为误差函数是因为回归的目标是尽可能拟合样本点，但分类问题的目标是尽可能将样本点分类到正确的类别中，仍然使用误差函数作为损失函数显然是不合适的。会闹出这样的笑话：对于那些类别明显的点，回归问题求解的惩罚反而更加严重。另外对于多分类问题种，我们给每个类别指定一个对应的目标值，在机器看来这些目标值之间是有联系的，比如：类别1目标值指定为1，类别2目标值指定为2，类别3目标值指定为3……计算机在寻找样本之间的关系时，会默认类别2和类别3要比类别1和类别3更加有关联，因为3和2更加靠近。 分类问题分类问题的求解过程同样可以分为三个步骤：1、确定一个模型f(x)，输入样本数据x，输出其类别； 2、定义损失函数L(f)，一个最简单的想法是计数分类错误的次数， 3、找出使损失函数最小的那个最优函数。上面的做法中，我们寻找到的最优函数直接计算出了p(c|x)，即给出了样本x属于每个类别cc的概率，这是一种解法。我们将其称作判别式（discrimination）方法，因为我们直接对样本所属类别进行了判断，相应的模型称作判别式模型。这一篇博客我们换一个角度思考，从另一个方向解决分类问题。下面以最简单的二分类为例，样本可以根据其类别标签被自然分为两类，那为什么我们不分别对每一类进行研究呢？是否可以发现每一类样本的特性呢？结合我们的研究目标：建模p(c|x)，借助概率论条件概率的知识，我们对其进行下转换： 高斯分布通常我们假定类条件概率p(x|c)符合某种确定的概率分布，训练样本都是从这个分布中随机采样得到的，“未被采样到的点”也对应有一个发生概率。某种确定的概率分布通常被假设为高斯分布（Gaussian Distribution），现在我们需要做的就是根据训练样本确定高斯分布的参数。多元高斯分布的概率密度函数如下： 其中k是x的维数，μ是均值向量，Σ是协方差矩阵，μ决定了分布的最高点，Σ决定了分布的形状，二维高斯分布概率密度函数如下： 下面两幅图分别展示了μ不同，Σ相同，和μ相同，Σ不同的分布对比 极大似然估计 朴素贝叶斯分类器上面的计算中，我们将大部分的精力都放在了求解类条件概率p(x|c)上，因为p(x|c)是关于所有属性的联合概率，难以从样本中直接估计得到。一个大胆的假设是认为描述样本的所有属性是相互独立的，因此p(x|c)可以拆解成 其中，n是属性数目，xi是第i个属性。同样可以假设每一维属性上的概率分布仍然服从高斯分布，此时的高斯分布是一个一维高斯分布，Σ对应一个实值，组成协方差矩阵也只在对角线位置有值，进一步减少了参数数目，得到了更简单的模型。这样的模型被称作朴素贝叶斯分类器（naive Bayes classifier，NB）。最后，对于样本分布不一定要选择高斯分布，例如如果是二值分布，我们可以假设符合伯努利分布，具体应用中要根据样本特点具体而定，但显示生活中确实有很多分布符合高斯分布。 总结这一篇博客中，我们从另一个角度介绍了求解分类问题的一类新模型，与判别式模型直接建模p(c|x)不同，这类模型首先对每一类别样本求解p(c)和p(x|c)，然后再计算p(c|x)，我们将这一类模型称作生成式模型（generative models）。因为求解出p(c)和p(x|c)后，我们也就求出了联合概率p(x,c)，也就求出了p(x)=p(x,c1)+p(x,c2)+⋯，有了p(x)我们就能采样生成每一个样本x，所以被称为生成式模型。 参考文献李宏毅机器学习2017秋http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML17_2.html","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://uscair.club/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://uscair.club/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"author":{"name":"Wonder"}},{"title":"K-means聚类算法","slug":"K-means聚类算法","date":"2020-03-14T16:00:00.000Z","updated":"2020-03-14T16:00:00.000Z","comments":true,"path":"2020/03/15/K-means聚类算法/","link":"","permalink":"http://uscair.club/2020/03/15/K-means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/","excerpt":"","text":"一，原理k-means算法以数据间的距离作为数据对象相似性度量的标准，因此选择计算数据间距离的计算方式对最后的聚类效果有显著的影响，常用计算距离的方式有：余弦距离、欧式距离、曼哈顿距离等。本文以欧式距离为例（会一种，其余也就会了）。 欧式距离公式： 例子：若数据为)其计算欧式距离如下(可理解为D表示维度，i,j表示行数)：通过计算（1）当前点与每个组中心之间的距离，对每个数据点进行分类，然后归到与距离最近的中心的组中。基于迭代后的结果，计算每一类内，所有点的平均值，作为新簇中心。 Ck表示第k类，|Ck|表示第k类中数据对象的个数。类心迭代过程如下： k-means的优点是速度非常快，因为我们真正要做的就是计算点和组中心之间的距离；计算量少！因此，它具有线性复杂性o（n）。另一方面，k-means有两个缺点。首先，您必须先确定聚类的簇数量。理想情况下，对于一个聚类算法，我们希望它能帮我们解决这些问题，因为它的目的是从数据中获得一些洞察力。k-均值也从随机选择聚类中心开始，因此它可能在算法的不同运行中产生不同的聚类结果。因此，结果可能不可重复，缺乏一致性。K中位数是与K均值相关的另一种聚类算法，除了不使用平均值重新计算组中心点之外，我们使用组的中位数向量。这种方法对异常偏离值不太敏感（因为使用了中值），但对于较大的数据集来说要慢得多，因为在计算中值向量时，每次迭代都需要排序。 二，代码直接使用K-means聚类函数： 1234567891011121314151617181920212223#coding=utf-8import numpy as npimport matplotlib.pyplot as pltfrom sklearn.cluster import KMeans#读取txtX=[]f=open('AA.txt')for v in f: X=append([float(v.split(',')[1]),float(v.split(','[2])])X = np.array(X)#类簇的数量n_clusters = 5#现在把数据和对应的分类书放入聚类函数中进行聚类cls = KMeans(n_clusters).fit(X)#X中每项所属分类的一个列表cls.labels_#画图markers = ['^', 'x', 'o', '*', '+']for i in range(n_clusters): members = cls.labels_ == i plt.scatter(X[members, 0], X[members, 1], s=60, marker=markers[i], c='b', alpha=0.5)plt.title(' ')plt.show() 用原理写代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374import numpy as npimport matplotlib.pyplot as plt# 加载数据def loadDataSet(fileName): data = np.loadtxt(fileName,delimiter='\\t') return data# 欧氏距离计算def distEclud(x,y): return np.sqrt(np.sum((x-y)**2)) # 计算欧氏距离# 为给定数据集构建一个包含K个随机质心的集合def randCent(dataSet,k): m,n = dataSet.shape centroids = np.zeros((k,n)) for i in range(k): index = int(np.random.uniform(0,m)) # centroids[i,:] = dataSet[index,:] return centroids # k均值聚类def KMeans(dataSet,k): m = np.shape(dataSet)[0] #行的数目 # 第一列存样本属于哪一簇 # 第二列存样本的到簇的中心点的误差 clusterAssment = np.mat(np.zeros((m,2))) clusterChange = True # 第1步 初始化centroids centroids = randCent(dataSet,k) while clusterChange: clusterChange = False # 遍历所有的样本（行数） for i in range(m): minDist = 100000.0 minIndex = -1 # 遍历所有的质心 #第2步 找出最近的质心 for j in range(k): # 计算该样本到质心的欧式距离 distance = distEclud(centroids[j,:],dataSet[i,:]) if distance &lt; minDist: minDist = distance minIndex = j # 第 3 步：更新每一行样本所属的簇 if clusterAssment[i,0] != minIndex: clusterChange = True clusterAssment[i,:] = minIndex,minDist**2 #第 4 步：更新质心 for j in range(k): pointsInCluster = dataSet[np.nonzero(clusterAssment[:,0].A == j)[0]] # 获取簇类所有的点 centroids[j,:] = np.mean(pointsInCluster,axis=0) # 对矩阵的行求均值 print(\"Congratulations,cluster complete!\") return centroids,clusterAssmentdef showCluster(dataSet,k,centroids,clusterAssment): m,n = dataSet.shape if n != 2: print(\"数据不是二维的\") return 1 mark = ['or', 'ob', 'og', 'ok', '^r', '+r', 'sr', 'dr', '&lt;r', 'pr'] if k &gt; len(mark): print(\"k值太大了\") return 1 # 绘制所有的样本 for i in range(m): markIndex = int(clusterAssment[i,0]) plt.plot(dataSet[i,0],dataSet[i,1],mark[markIndex]) mark = ['Dr', 'Db', 'Dg', 'Dk', '^b', '+b', 'sb', 'db', '&lt;b', 'pb'] # 绘制质心 for i in range(k): plt.plot(centroids[i,0],centroids[i,1],mark[i]) plt.show()dataSet = loadDataSet(\"test.txt\")k = 4centroids,clusterAssment = KMeans(dataSet,k)showCluster(dataSet,k,centroids,clusterAssment)","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://uscair.club/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"聚类算法","slug":"聚类算法","permalink":"http://uscair.club/tags/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/"}],"author":{"name":"ffffff"}},{"title":"从Lentet-5看CNN","slug":"从Lentet-5看CNN","date":"2020-03-14T16:00:00.000Z","updated":"2020-03-14T16:00:00.000Z","comments":true,"path":"2020/03/15/从Lentet-5看CNN/","link":"","permalink":"http://uscair.club/2020/03/15/%E4%BB%8ELentet-5%E7%9C%8BCNN/","excerpt":"","text":"卷积首先我们用一个$3 \\times 3$的核对一个$6 \\times 6$的矩阵进行卷积运算，会得到一个$4 \\times 4$的矩阵 我们把核映射到矩阵上对应相乘相加，比如$4 \\times 4$矩阵的第一个元素-5 但是我们也得知卷积会使矩阵变小 其中在tensorflow中可以使用tf.nn.conv2d() 123456789tf.nn.conv2d( input, filters, strides, padding, data_format='NHWC', dilations=None, name=None) 其中卷积可以用于边缘检测，如图 因为$3\\times3$的矩阵太小使用边缘比较粗 由此可见上面的卷积都使原图像的大小变小了，为了使大小不变，我们使用了提高padding（即在原图像边缘填充像素） 设源图像大小为$n \\times n$,卷积核为$f \\times f$，padding为p，所以卷积后图像大小为$[(n+2p-f+1) \\times (n+2p-f+1)]$。 同时我们引入步长这一个概念（即卷积核每次移动的单位长度）。 设源图像大小为$n \\times n$,卷积核为$f \\times f$，padding为p，步长为s，所以卷积后图像大小为$[(\\frac{n+2p-f}{s}+1) \\times (\\frac{n+2p-f}{s}+1)]$。 如果第L层是卷积层： 其中： $f^{[l]}$:卷积核大小 $p^{[l]}$:填充大小 $s^{[l]}$:步长大小 $n^{[l]}_c$:卷积层数目 输入：$n^{[l-1]}_H\\times n^{[l-1]}_W\\times n^{[l-1]}_c$ 输出:$n^{[l]}_H\\times n^{[l]}_W\\times n^{[l]}_c$ 每个卷积核 :$f^{[l]}\\times f^{[l]}\\times f_c^{[l-1]}$ 激活函数:$a^{[l]}\\to n^{[l]}_H\\times n^{[l]}_W\\times n^{[l]}_c$ 权重:$f^{[l]}\\times f^{[l]}\\times n_c^{[l-1]}\\times n_c^{[l-1]}$ 偏差：$n_c^{[l]}-(1,1,1,n_c^{[l]})$ 卷积神经网络的结构一般卷积神经网络是由输入层、卷积层、激活层、池化层、全连接层、输出层组成 输入层输入层要进行数据的预处理，比如去均值、归一化、PCA/SVD降维等 卷积层卷积层主要通过对每一个局部感知，然后更高层次的局部感知，最终得到全局信息。 其中卷积有两个大杀器一个是局部感知野，另一个是权值共享。 局部感知野如果我们有1000x1000像素的图像，有1百万个隐层神经元，那么他们全连接的话（每个隐层神经元都连接图像的每一个像素点），就有1000x1000x1000000=10^12^个连接，也就是10^12^个权值参数。 图像的空间联系也是局部的像素联系较为紧密，而距离较远的像素相关性则较弱。因而，每个神经元其实没有必要对全局图像进行感知，只需要对局部进行感知，然后在更高层将局部的信息综合起来就得到了全局的信息。图像的空间联系是局部的，就像人是通过一个局部的感受野去感受外界图像一样，每一个神经元都不需要对全局图像做感受，每个神经元只感受局部的图像区域，然后在更高层，将这些感受不同局部的神经元综合起来就可以得到全局的信息了 假如局部感受野是10x10，就有10x10x1000000=10^8^个连接减少了4个数量级，也就是减少了4个数量级的参数 权值共享假如使用一个卷积层，参数都是一样的，那只能提取一个特征了，我们总需要提取多个特征的啊，那我们就加多个卷积，每个卷积层不同。那么隐层的神经元个数怎么确定呢？它和原图像，也就是输入的大小（神经元个数）、滤波器的大小和滤波器在图像中的滑动步长都有关。 池化层 降维，减少网络要学习的参数数量 防止过拟合 扩大感受野 实现不变性（平移、旋转、尺度不变性） Lenet-5下面我们从著名的神经网络Lenet-5来看卷积 paper地址 效果图： 上图包含输入层总共8层网络，分别为：输入层（INPUT）、卷积层（Convolutions,C1）、池化层（Subsampling，S2）、卷积层（C3）、池化层（Subsampling，S4）、卷积层（C5）、全连接层（F6）、输出层（径向基层） 卷积和子采样过程：卷积过程包括：用一个可训练的滤波器fx去卷积一个输入的图像（第一阶段是输入的图像，后面的阶段就是卷积特征map了），然后加一个偏置bx，得到卷积层Cx。子采样过程包括：每邻域四个像素求和变为一个像素，然后通过标量Wx+1加权，再增加偏置bx+1，然后通过一个sigmoid激活函数，产生一个大概缩小四倍的特征映射图Sx+1。 我们输入32x32的图像经过6通道的5x5的卷积后，特征图为28x28，其中C1的训练参数个数是(5x5+1)x6=156，连接数是156x(28x28)=122304。其中5x5是卷积核大小为5x5，+1个偏置单元，6个通道。 其中S2是一个下采样层，利用图像局部相关性的原理，对图像进行子抽样，可以减少数据处理量同时保留有用信息，其中C1通过下采样层得到一个14x14的特征图，其中14x14的特征图的每一个单元与C1中的与之相对应的2x2的邻域有关。C1层每个单元的4个输入相加，乘以一个可训练参数，再加上一个可训练偏置。结果通过sigmoid函数计算。如果系数比较小，那么运算近似于线性运算，亚采样相当于模糊图像。如果系数比较大，根据偏置的大小亚采样可以被看成是有噪声的“或”运算或者有噪声的“与”运算。每个单元的2x2感受野并不重叠，因此S2中每个特征图的大小是C1中特征图大小的1/4（行和列各1/2）。其中S2的训练参数是(1x1+1)x6=12，连接数是(2x2+1)x6x(14x14)=5880 用一个16通道的5x5的卷积核去卷积S2可以得到C3，其大小为10x10的16通道的一个特征图，其中C3中的每个特征map是连接到S2中的所有6个或者几个特征map的，表示本层的特征map是上一层提取到的特征map的不同组合。 如上图，横向的数表示卷积层C3的特征平面，纵向表示池化层的6个采样平面，我们以卷积层C3的第0号特征平面为例，它对应了池化层的前三个采样平面即0,1,2，三个平面使用的是三个卷积核（每个采样平面是卷积核相同，权值相等，大小为5x5）,既然对应三个池化层平面，那么也就是说有5x5x3个连接到卷积层特征平面的一个神经元，因为池化层所有的样本均为14x14的，而卷积窗口为5x5的，因此卷积特征平面为10x10（大家可按照第一个卷积计算求的）。只是这里的卷积操作要更复杂，他不是所有的都是特征平面对应三个池化层平面，而是变化的，从上图我们可以清楚的看到前6个特征平面对应池化层的三个平面即0,1,2,3,4,5 ， 而6~14每张特征平面对应4个卷积层，此时每个特征平面的一个神经元的连接数为5x5x4，最后一个特征平面是对应池化层所有的样本平面， 连接数： (5x5x3+1)x10x10x6+(5x5x4+1)x10x10x9+(5x5x6+1)x10x10 = 45600+90900+15100=151600 权值数： (5x5x3+1)x6 + (5x5x4+1)x9 + 5x5x6+1 = 456 + 909+151 = 1516 S4层是一个下采样层，由16个5x5大小的特征图构成。特征图中的每个单元与C3中相应特征图的2x2邻域相连接，跟C1和S2之间的连接一样。S4层有(1x1+1)x16=32个可训练参数（每个特征图1个因子和一个偏置）和(2x2+1)x16x(5x5)=2000个连接。 原因有两方面：采用非连接的方案将连接数保持在合理的范围内，而且破坏了神经网络的对称性（我也没太理解清楚。。。） C5是卷积层。。。 好像是用一个120个通道的5x5的卷积核与S4做卷积，正好构成全连接的关系。（以上是个人猜测） 目前我也没搞懂。。。先留着 F6有84个单元，因为在计算机中字符的编码是ASCII编码，这些图是用7x12大小的位图表示的，也就是高宽比为7:12，如下图，选择这个大小可以用于对每一个像素点的值进行估计。 这一层其实就是BP网络的隐层，且为全连接层，即这一层有84个神经元，每一个神经元都和上一次的120个神经元相连接，那么连接数为(120+1)x84 = 10164,因为权值不共享，隐层权值数也是10164，至于为什么隐层是84个神经元稍后解释，本层的输出有激活函数，激活函数为双曲正切函数： 根据论文解释：A的幅值，S是原点处的倾斜率，A的经验值是1.7159，原因没说。 输出层：有10个输出，对应0-9的数字 首先大家应该明白什么是径向基神经网络，他基于距离进行衡量两个数据的相近程度的，RBF网最显著的特点是隐节点采用输人模式与中心向量的距离（如欧氏距离）作为函数的自变量，并使用径向基函数（如函数）作为激活函数。径向基函数关于N维空间的一个中心点具有径向对称性，而且神经元的输人离该中心点越远，神经元的激活程度就越低。上式是基于欧几里得距离，怎么理解那个式子呢？就是说F6层为84个输入用$x_j$表示，而输出有10个用$y_i$表示，而权值使用$w_{ji}$表示，上式说明所有输入和权值的距离平方和为依据判断，如果越相近距离越小，输出越小则去哪个，如果我们存储的到$w_{ji}$的值为标准的输出，如标准的手写体0,1,2,3等，那么最后一层就说明。F6层和标准的作比较，和标准的那个图形越相似就说明就越是那个字符的可能性更大。 卷积神经网络关于感受野的计算什么是感受野在计算机视觉领域的深度神经网络中有一个概念叫做感受野，用来表示网络内部的不同位置的神经元对原图像的感受范围的大小。 白话版：感受野（Receptive Field），指的是神经网络中神经元“看到的”输入区域，在卷积神经网络中，feature map上某个元素的计算受输入图像上某个区域的影响，这个区域即该元素的感受野。 神经元之所以无法对原始图像的所有信息进行感知，是因为在这些网络结构中普遍使用卷积层和pooling层，在层与层之间均为局部相连（通过sliding filter）。神经元感受野的值越大表示其能接触到的原始图像范围就越大，也意味着他可能蕴含更为全局、语义层次更高的特征；而值越小则表示其所包含的特征越趋向于局部和细节。因此感受野的值可以大致用来判断每一层的抽象层次。 可以看到在Conv1中的每一个单元所能看到的原始图像范围是3*3，而由于Conv2的每个单元都是由 范围的Conv1构成，因此回溯到原始图像，其实是能够看到 的原始图像范围的。因此我们说Conv1的感受野是3，Conv2的感受野是5. 输入图像的每个单元的感受野被定义为1，这应该很好理解，因为每个像素只能看到自己。 感受野的计算 K：卷积核大小 P：填充块大小 S：步长 Layer：用Layer表示 (特征图)feature map，特别地Layer 0为输入图像 n：特征图的大小 r：感受野大小 j：特征图上相邻的像素距离，即：在特征图上前进1步相当于输入图像上前进多少个像素 如下图所示，feature map上前进1步，相当于输入图像上前进2个像素，𝑗=2 start：在特征图左上角第一个像素在输入图像上的感受野中心坐标。 在上图中，左上角绿色块感受野中心坐标为(0.5,0.5)，即左上角蓝色块中心的坐标，左上角白色虚线块中心的坐标为(−0.5,−0.5)； 再看上面的动图，如果feature map Layer2 上的一个元素A看到feature map 𝐿𝑎𝑦𝑒𝑟 1上的范围为3×3（图中绿色块），其大小等于kernel size $𝑘_2$，所以，A看到的感受野范围$r_2$等价于Layer 1上3×3窗口看到的Layer 0 范围，据此可以建立起相邻Layer感受野的关系，如下所示，其中$r_{l-1}$为Layer l-1的感受野，$r_l−1$为Layer l−1 的感受野，$$𝑟_𝑙=𝑟_{𝑙−1}+(𝑘_𝑙−1)\\times 𝑗_𝑙−1$$ 𝐿𝑎𝑦𝑒𝑟 𝑙 一个元素的感受野𝑟𝑙等价于𝐿𝑎𝑦𝑒𝑟 𝑙−1上𝑘×𝑘个感受野的叠加； 𝐿𝑎𝑦𝑒𝑟 𝑙−1上一个元素的感受野为$r_{l−1}$； 𝐿𝑎𝑦𝑒𝑟 𝑙−1上连续𝑘k 个元素的感受野可以看成是，第1个元素看到的感受野加上剩余k−1步扫过的范围，𝐿𝑎𝑦𝑒𝑟 𝑙−1 上每前进1个元素相当于在输入图像上前进$𝑗_{𝑙−1}$个像素，结果等于$𝑟_{𝑙−1}+(𝑘−1)×𝑗_{𝑙−1}$ 感受野中心 感受野小结 关于卷积神经网络的部分代码二维卷积1234567def corr2d(X, K): h, w = K.shape Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1)) # 卷积输出的图像大小 for i in range(Y.shape[0]): for j in range(Y.shape[1]): Y[i, j] = (X[i: i + h, j: j + w] * K).sum() return Y 多输入通道12345678910111213141516171819202122def corr2d_multi_in(X,K): # 沿着X和K的第0维（通道维）分别计算再相加 res = corr2d(X[0, :, :], K[0, :, :]) for i in range(1, X.shape[0]): res += corr2d(X[i, :, :], K[i, :, :]) return resX = torch.tensor([[[0, 1, 2], [3, 4, 5], [6, 7, 8]], [[1, 2, 3], [4, 5, 6], [7, 8, 9]]])K = torch.tensor([[[0, 1], [2, 3]], [[1, 2], [3, 4]]])print(X.size())print(K.size())print(corr2d_multi_in(X, K))print([k for k in K]) 多输出通道12345678def corr2d_multi_in_out(X, K): # 对K的第0维遍历，每次同输入X做互相关计算。所有结果使用stack函数合并在一起 return torch.stack([corr2d_multi_in(X, k) for k in K])K=torch.stack([K,K+1,K+2])print(K.shape)print(corr2d_multi_in_out(X,K)) 1x1卷积层12345678910111213141516171819202122def corr2d_multi_in_out_1x1(X,K): c_i,h,w=X.shape c_o=K.shape[0] X=X.view(c_i,h*w) print('X.view(',c_i,',',h*w,'):\\n',X) K=K.view(c_o,c_i) print('K.view(',c_o,',',c_i,'):\\n',K) Y=torch.mm(K,X) return Y.view(c_o,h,w) X=torch.rand(3,3,1)K=torch.rand(2,3,1,1)print('X:\\n',X)print(X.size())print('K:\\n',K)print(K.size())Y1=corr2d_multi_in_out_1x1(X,K)Y2=corr2d_multi_in_out(X,K)print((Y1-Y2).norm().item()&lt;1e-6) 最大池化层和ping123456789101112131415161718def pool2d(X, pool_size, mode='max'): X=X.float() p_w,p_h=pool_size Y=torch.zeros(X.shape[0]-p_h+1,X.shape[1]-p_w+1) for i in range(Y.shape[0]): for j in range(Y.shape[1]): if mode=='max': Y[i,j]=X[i:i+p_h,j:j+p_w].max() if mode=='avg': Y[i,j]=X[i:i+p_h,j:j+p_w].mean() return YX=torch.tensor([[0,1,2], [3,4,5], [6,7,8]])print(pool2d(X,(2,2)))print(pool2d(X,(2,2),mode='avg')) 填充和步幅12x=torch.arange(16).view(1,1,4,4)print(x) Lenet-51234567891011121314151617181920212223class LeNet(nn.Module): def __init__(self): super(LeNet,self).__init__() self.conv=nn.Sequential( nn.Conv2d(1, 6, 5), # in_channels, out_channels, kernel_size nn.Sigmoid(), nn.MaxPool2d(2,2), # kernel_size, stride nn.Conv2d(6,16,5), nn.Sigmoid(), nn.MaxPool2d(2,2) ) self.fc=nn.Sequential( nn.Linear(16*4*4,120), nn.Sigmoid(), nn.Linear(120,84), nn.Sigmoid(), nn.Linear(84,10) ) def forward(self, img): feature=self.conv(img) output=self.fc(feature.view(img.shape[0],-1)) return output 12net=LeNet()print(net) 12345678910111213141516171819def load_data_fashion_mnist(batch_size, resize=None, root='./data'): \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\" trans = [] if resize: trans.append(torchvision.transforms.Resize(size=resize)) trans.append(torchvision.transforms.ToTensor()) # 将PIL image或numpy.darray 转化成tensor transform = torchvision.transforms.Compose(trans) mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform) mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform) train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4) test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=4) return train_iter, test_iterbatch_size = 128# 如出现“out of memory”的报错信息，可减小batch_size或resizetrain_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224) 12batch_size = 256train_iter, test_iter = load_data_fashion_mnist(batch_size=batch_size) 12345678910111213141516171819def evaluate_accuracy(data_iter, net, device=None): if device is None and isinstance(net, torch.nn.Module): # 如果没指定device就使用net的device device = list(net.parameters())[0].device acc_sum, n = 0.0, 0 with torch.no_grad(): for X, y in data_iter: if isinstance(net, torch.nn.Module): net.eval() # 评估模式, 这会关闭dropout acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item() net.train() # 改回训练模式 else: if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数 # 将is_training设置成False acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() else: acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() n += y.shape[0] return acc_sum / n 123456789101112131415161718192021def train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs): net = net.to(device) print(\"training on \", device) loss = torch.nn.CrossEntropyLoss() for epoch in range(num_epochs): train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time() for X, y in train_iter: X = X.to(device) y = y.to(device) y_hat = net(X) l = loss(y_hat, y) optimizer.zero_grad() l.backward() optimizer.step() train_l_sum += l.cpu().item() train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item() n += y.shape[0] batch_count += 1 test_acc = evaluate_accuracy(test_iter, net) print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec' % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start)) 123lr, num_epochs = 0.001, 5optimizer = torch.optim.Adam(net.parameters(), lr=lr)train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)","categories":[{"name":"神经网络","slug":"神经网络","permalink":"http://uscair.club/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"CNN","slug":"CNN","permalink":"http://uscair.club/tags/CNN/"}],"author":{"name":"Gowi"}},{"title":"spyderd的简单使用","slug":"spyderd的简单使用","date":"2020-03-13T16:00:00.000Z","updated":"2020-03-13T16:00:00.000Z","comments":true,"path":"2020/03/14/spyderd的简单使用/","link":"","permalink":"http://uscair.club/2020/03/14/spyderd%E7%9A%84%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/","excerpt":"","text":"12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152 # -*- coding: utf-8 -*-&quot;&quot;&quot;Created on Fri Mar 13 19:41:35 2020@author: MSIK&quot;&quot;&quot;print(&quot;hello&quot;)#1.requestimport requestsresp&#x3D;requests.get(&quot;http:&#x2F;&#x2F;www.baidu.com&quot;)print( resp)print( resp.text)print( resp.encoding)print(&quot;这是requests解析出来的编码&quot;,resp.apparent_encoding)resp.encoding&#x3D;resp.apparent_encodingprint(&quot;.............\\n\\n\\n&quot;)print(&quot;修改后的编码&quot;, resp.text)#### 运行结果：Python 3.6.2 |Anaconda, Inc.| (default, Sep 19 2017, 08:03:39) [MSC v.1900 64 bit (AMD64)]Type &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.IPython 6.1.0 -- An enhanced Interactive Python.runfile(&#39;E:&#x2F;文化&#x2F;文件&#x2F;untitled0.py&#39;, wdir&#x3D;&#39;E:&#x2F;文化&#x2F;文件&#39;)hello&lt;Response [200]&gt;&lt;!DOCTYPE html&gt;&lt;!--STATUS OK--&gt;&lt;html&gt; &lt;head&gt;&lt;meta http-equiv&#x3D;content-type content&#x3D;text&#x2F;html;charset&#x3D;utf-8&gt;&lt;meta http-equiv&#x3D;X-UA-Compatible content&#x3D;IE&#x3D;Edge&gt;&lt;meta content&#x3D;always name&#x3D;referrer&gt;&lt;link rel&#x3D;stylesheet type&#x3D;text&#x2F;css href&#x3D;http:&#x2F;&#x2F;s1.bdstatic.com&#x2F;r&#x2F;www&#x2F;cache&#x2F;bdorz&#x2F;baidu.min.css&gt;&lt;title&gt;ç¾åº¦ä¸ä¸ï¼ä½ å°±ç¥é&lt;&#x2F;title&gt;&lt;&#x2F;head&gt; &lt;body link&#x3D;#0000cc&gt; &lt;div id&#x3D;wrapper&gt; &lt;div id&#x3D;head&gt; &lt;div class&#x3D;head_wrapper&gt; &lt;div class&#x3D;s_form&gt; &lt;div class&#x3D;s_form_wrapper&gt; &lt;div id&#x3D;lg&gt; &lt;img hidefocus&#x3D;true src&#x3D;&#x2F;&#x2F;www.baidu.com&#x2F;img&#x2F;bd_logo1.png width&#x3D;270 height&#x3D;129&gt; &lt;&#x2F;div&gt; &lt;form id&#x3D;form name&#x3D;f action&#x3D;&#x2F;&#x2F;www.baidu.com&#x2F;s class&#x3D;fm&gt; &lt;input type&#x3D;hidden name&#x3D;bdorz_come value&#x3D;1&gt; &lt;input type&#x3D;hidden name&#x3D;ie value&#x3D;utf-8&gt; &lt;input type&#x3D;hidden name&#x3D;f value&#x3D;8&gt; &lt;input type&#x3D;hidden name&#x3D;rsv_bp value&#x3D;1&gt; &lt;input type&#x3D;hidden name&#x3D;rsv_idx value&#x3D;1&gt; &lt;input type&#x3D;hidden name&#x3D;tn value&#x3D;baidu&gt;&lt;span class&#x3D;&quot;bg s_ipt_wr&quot;&gt;&lt;input id&#x3D;kw name&#x3D;wd class&#x3D;s_ipt value maxlength&#x3D;255 autocomplete&#x3D;off autofocus&gt;&lt;&#x2F;span&gt;&lt;span class&#x3D;&quot;bg s_btn_wr&quot;&gt;&lt;input type&#x3D;submit id&#x3D;su value&#x3D;ç¾åº¦ä¸ä¸ class&#x3D;&quot;bg s_btn&quot;&gt;&lt;&#x2F;span&gt; &lt;&#x2F;form&gt; &lt;&#x2F;div&gt; &lt;&#x2F;div&gt; &lt;div id&#x3D;u1&gt; &lt;a href&#x3D;http:&#x2F;&#x2F;news.baidu.com name&#x3D;tj_trnews class&#x3D;mnav&gt;æ°é»&lt;&#x2F;a&gt; &lt;a href&#x3D;http:&#x2F;&#x2F;www.hao123.com name&#x3D;tj_trhao123 class&#x3D;mnav&gt;hao123&lt;&#x2F;a&gt; &lt;a href&#x3D;http:&#x2F;&#x2F;map.baidu.com name&#x3D;tj_trmap class&#x3D;mnav&gt;å°å¾&lt;&#x2F;a&gt; &lt;a href&#x3D;http:&#x2F;&#x2F;v.baidu.com name&#x3D;tj_trvideo class&#x3D;mnav&gt;è§é¢&lt;&#x2F;a&gt; &lt;a href&#x3D;http:&#x2F;&#x2F;tieba.baidu.com name&#x3D;tj_trtieba class&#x3D;mnav&gt;è´´å§&lt;&#x2F;a&gt; &lt;noscript&gt; &lt;a href&#x3D;http:&#x2F;&#x2F;www.baidu.com&#x2F;bdorz&#x2F;login.gif?login&amp;tpl&#x3D;mn&amp;u&#x3D;http%3A%2F%2Fwww.baidu.com%2f%3fbdorz_come%3d1 name&#x3D;tj_login class&#x3D;lb&gt;ç»å½&lt;&#x2F;a&gt; &lt;&#x2F;noscript&gt; &lt;script&gt;document.write(&#39;&lt;a href&#x3D;&quot;http:&#x2F;&#x2F;www.baidu.com&#x2F;bdorz&#x2F;login.gif?login&amp;tpl&#x3D;mn&amp;u&#x3D;&#39;+ encodeURIComponent(window.location.href+ (window.location.search &#x3D;&#x3D;&#x3D; &quot;&quot; ? &quot;?&quot; : &quot;&amp;&quot;)+ &quot;bdorz_come&#x3D;1&quot;)+ &#39;&quot; name&#x3D;&quot;tj_login&quot; class&#x3D;&quot;lb&quot;&gt;ç»å½&lt;&#x2F;a&gt;&#39;);&lt;&#x2F;script&gt; &lt;a href&#x3D;&#x2F;&#x2F;www.baidu.com&#x2F;more&#x2F; name&#x3D;tj_briicon class&#x3D;bri style&#x3D;&quot;display: block;&quot;&gt;æ´å¤äº§å&lt;&#x2F;a&gt; &lt;&#x2F;div&gt; &lt;&#x2F;div&gt; &lt;&#x2F;div&gt; &lt;div id&#x3D;ftCon&gt; &lt;div id&#x3D;ftConw&gt; &lt;p id&#x3D;lh&gt; &lt;a href&#x3D;http:&#x2F;&#x2F;home.baidu.com&gt;å³äºç¾åº¦&lt;&#x2F;a&gt; &lt;a href&#x3D;http:&#x2F;&#x2F;ir.baidu.com&gt;About Baidu&lt;&#x2F;a&gt; &lt;&#x2F;p&gt; &lt;p id&#x3D;cp&gt;&amp;copy;2017&amp;nbsp;Baidu&amp;nbsp;&lt;a href&#x3D;http:&#x2F;&#x2F;www.baidu.com&#x2F;duty&#x2F;&gt;ä½¿ç¨ç¾åº¦åå¿è¯»&lt;&#x2F;a&gt;&amp;nbsp; &lt;a href&#x3D;http:&#x2F;&#x2F;jianyi.baidu.com&#x2F; class&#x3D;cp-feedback&gt;æè§åé¦&lt;&#x2F;a&gt;&amp;nbsp;äº¬ICPè¯030173å·&amp;nbsp; &lt;img src&#x3D;&#x2F;&#x2F;www.baidu.com&#x2F;img&#x2F;gs.gif&gt; &lt;&#x2F;p&gt; &lt;&#x2F;div&gt; &lt;&#x2F;div&gt; &lt;&#x2F;div&gt; &lt;&#x2F;body&gt; &lt;&#x2F;html&gt;ISO-8859-1这是requests解析出来的编码 utf-8.............修改后的编码 &lt;!DOCTYPE html&gt;&lt;!--STATUS OK--&gt;&lt;html&gt; &lt;head&gt;&lt;meta http-equiv&#x3D;content-type content&#x3D;text&#x2F;html;charset&#x3D;utf-8&gt;&lt;meta http-equiv&#x3D;X-UA-Compatible content&#x3D;IE&#x3D;Edge&gt;&lt;meta content&#x3D;always name&#x3D;referrer&gt;&lt;link rel&#x3D;stylesheet type&#x3D;text&#x2F;css href&#x3D;http:&#x2F;&#x2F;s1.bdstatic.com&#x2F;r&#x2F;www&#x2F;cache&#x2F;bdorz&#x2F;baidu.min.css&gt;&lt;title&gt;百度一下，你就知道&lt;&#x2F;title&gt;&lt;&#x2F;head&gt; &lt;body link&#x3D;#0000cc&gt; &lt;div id&#x3D;wrapper&gt; &lt;div id&#x3D;head&gt; &lt;div class&#x3D;head_wrapper&gt; &lt;div class&#x3D;s_form&gt; &lt;div class&#x3D;s_form_wrapper&gt; &lt;div id&#x3D;lg&gt; &lt;img hidefocus&#x3D;true src&#x3D;&#x2F;&#x2F;www.baidu.com&#x2F;img&#x2F;bd_logo1.png width&#x3D;270 height&#x3D;129&gt; &lt;&#x2F;div&gt; &lt;form id&#x3D;form name&#x3D;f action&#x3D;&#x2F;&#x2F;www.baidu.com&#x2F;s class&#x3D;fm&gt; &lt;input type&#x3D;hidden name&#x3D;bdorz_come value&#x3D;1&gt; &lt;input type&#x3D;hidden name&#x3D;ie value&#x3D;utf-8&gt; &lt;input type&#x3D;hidden name&#x3D;f value&#x3D;8&gt; &lt;input type&#x3D;hidden name&#x3D;rsv_bp value&#x3D;1&gt; &lt;input type&#x3D;hidden name&#x3D;rsv_idx value&#x3D;1&gt; &lt;input type&#x3D;hidden name&#x3D;tn value&#x3D;baidu&gt;&lt;span class&#x3D;&quot;bg s_ipt_wr&quot;&gt;&lt;input id&#x3D;kw name&#x3D;wd class&#x3D;s_ipt value maxlength&#x3D;255 autocomplete&#x3D;off autofocus&gt;&lt;&#x2F;span&gt;&lt;span class&#x3D;&quot;bg s_btn_wr&quot;&gt;&lt;input type&#x3D;submit id&#x3D;su value&#x3D;百度一下 class&#x3D;&quot;bg s_btn&quot;&gt;&lt;&#x2F;span&gt; &lt;&#x2F;form&gt; &lt;&#x2F;div&gt; &lt;&#x2F;div&gt; &lt;div id&#x3D;u1&gt; &lt;a href&#x3D;http:&#x2F;&#x2F;news.baidu.com name&#x3D;tj_trnews class&#x3D;mnav&gt;新闻&lt;&#x2F;a&gt; &lt;a href&#x3D;http:&#x2F;&#x2F;www.hao123.com name&#x3D;tj_trhao123 class&#x3D;mnav&gt;hao123&lt;&#x2F;a&gt; &lt;a href&#x3D;http:&#x2F;&#x2F;map.baidu.com name&#x3D;tj_trmap class&#x3D;mnav&gt;地图&lt;&#x2F;a&gt; &lt;a href&#x3D;http:&#x2F;&#x2F;v.baidu.com name&#x3D;tj_trvideo class&#x3D;mnav&gt;视频&lt;&#x2F;a&gt; &lt;a href&#x3D;http:&#x2F;&#x2F;tieba.baidu.com name&#x3D;tj_trtieba class&#x3D;mnav&gt;贴吧&lt;&#x2F;a&gt; &lt;noscript&gt; &lt;a href&#x3D;http:&#x2F;&#x2F;www.baidu.com&#x2F;bdorz&#x2F;login.gif?login&amp;tpl&#x3D;mn&amp;u&#x3D;http%3A%2F%2Fwww.baidu.com%2f%3fbdorz_come%3d1 name&#x3D;tj_login class&#x3D;lb&gt;登录&lt;&#x2F;a&gt; &lt;&#x2F;noscript&gt; &lt;script&gt;document.write(&#39;&lt;a href&#x3D;&quot;http:&#x2F;&#x2F;www.baidu.com&#x2F;bdorz&#x2F;login.gif?login&amp;tpl&#x3D;mn&amp;u&#x3D;&#39;+ encodeURIComponent(window.location.href+ (window.location.search &#x3D;&#x3D;&#x3D; &quot;&quot; ? &quot;?&quot; : &quot;&amp;&quot;)+ &quot;bdorz_come&#x3D;1&quot;)+ &#39;&quot; name&#x3D;&quot;tj_login&quot; class&#x3D;&quot;lb&quot;&gt;登录&lt;&#x2F;a&gt;&#39;);&lt;&#x2F;script&gt; &lt;a href&#x3D;&#x2F;&#x2F;www.baidu.com&#x2F;more&#x2F; name&#x3D;tj_briicon class&#x3D;bri style&#x3D;&quot;display: block;&quot;&gt;更多产品&lt;&#x2F;a&gt; &lt;&#x2F;div&gt; &lt;&#x2F;div&gt; &lt;&#x2F;div&gt; &lt;div id&#x3D;ftCon&gt; &lt;div id&#x3D;ftConw&gt; &lt;p id&#x3D;lh&gt; &lt;a href&#x3D;http:&#x2F;&#x2F;home.baidu.com&gt;关于百度&lt;&#x2F;a&gt; &lt;a href&#x3D;http:&#x2F;&#x2F;ir.baidu.com&gt;About Baidu&lt;&#x2F;a&gt; &lt;&#x2F;p&gt; &lt;p id&#x3D;cp&gt;&amp;copy;2017&amp;nbsp;Baidu&amp;nbsp;&lt;a href&#x3D;http:&#x2F;&#x2F;www.baidu.com&#x2F;duty&#x2F;&gt;使用百度前必读&lt;&#x2F;a&gt;&amp;nbsp; &lt;a href&#x3D;http:&#x2F;&#x2F;jianyi.baidu.com&#x2F; class&#x3D;cp-feedback&gt;意见反馈&lt;&#x2F;a&gt;&amp;nbsp;京ICP证030173号&amp;nbsp; &lt;img src&#x3D;&#x2F;&#x2F;www.baidu.com&#x2F;img&#x2F;gs.gif&gt; &lt;&#x2F;p&gt; &lt;&#x2F;div&gt; &lt;&#x2F;div&gt; &lt;&#x2F;div&gt; &lt;&#x2F;body&gt; &lt;&#x2F;html&gt;","categories":[{"name":"python","slug":"python","permalink":"http://uscair.club/categories/python/"}],"tags":[],"author":{"name":"不败顽童"}},{"title":"用spyder爬取图片","slug":"用spyder爬取图片","date":"2020-03-13T16:00:00.000Z","updated":"2020-03-13T16:00:00.000Z","comments":true,"path":"2020/03/14/用spyder爬取图片/","link":"","permalink":"http://uscair.club/2020/03/14/%E7%94%A8spyder%E7%88%AC%E5%8F%96%E5%9B%BE%E7%89%87/","excerpt":"","text":"#1. 爬取图片import requests https://zhumu.com/static/img/zhumu_logo_left.pngresp=requests.get(“https://zhumu.com/static/img/zhumu_logo_left.png&quot;)#print( resp.content ) #字节数组 text from PIL import Imagefrom io import BytesIO buffer=BytesIO( resp.content ) #将字节数组存入内存image=Image.open(buffer)print( image ) #演示import matplotlib.pyplot as plt #绘图plt.imshow( image ) 爬取结果：runfile(‘E:/文化/文件/untitled1.py’, wdir=’E:/文化/文件’)&lt;PIL.PngImagePlugin.PngImageFile image mode=P size=352x146 at 0x1EC82046F28&gt;","categories":[{"name":"python","slug":"python","permalink":"http://uscair.club/categories/python/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://uscair.club/tags/OpenCV/"}],"author":{"name":"不败顽童"}},{"title":"机器学习系列（六）——梯度下降解释及其技巧","slug":"机器学习系列（六）——梯度下降解释及其技巧","date":"2020-03-08T14:39:29.118Z","updated":"2020-03-08T14:39:29.118Z","comments":true,"path":"2020/03/08/机器学习系列（六）——梯度下降解释及其技巧/","link":"","permalink":"http://uscair.club/2020/03/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%88%E5%85%AD%EF%BC%89%E2%80%94%E2%80%94%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E8%A7%A3%E9%87%8A%E5%8F%8A%E5%85%B6%E6%8A%80%E5%B7%A7/","excerpt":"","text":"在训练机器学习模型寻找最优函数时，梯度下降（Gradient Descent）是最常用的优化（optimization）方法。在给定一组初始参数θ0时，梯度下降算法能够顺着损失函数下降最快的方向逐步逼近最低点，也就是最佳参数θ∗的位置。那梯度下降算法为什么work呢？为什么梯度的反方向就是损失函数下降最快的方向呢？ 梯度下降算法解释首先回顾一下梯度下降算法是如何工作的，我们的目标是找到θ∗： 其中LL是损失函数，梯度下降算法步骤如下： ​ 1.随机选取一组初始参数θ0。​ 2.计算损失函数在该点的偏导数∇L(θ^(n−1))，也就是梯度。​ 3.更新参数θn=θn−1−η∇L(θn−1)。​ 4.重复2，3步骤，直至梯度不再下降（小于某个阈值范围）。上面第3步中可以看到，每次我们顺着梯度的反方向更新θ，其中η是学习速率，代表了每次更新的步伐大小。在只含有两个未知参数时，梯度下降的直观过程如下图： 下面根据李宏毅课程的思路对梯度下降的原理进行解释。同样假设只包含两个参数θ1，θ2。随机给定一个初始点，在“目之所及”的范围内寻找损失函数下降最快的方向，如下图 θ0是随机给定的初始点，红色圆圈是“目之所及”的范围，现在的关键是如何找到圆圈范围内下降最快的方向，由泰勒展示（Taylor Series）:当函数h(x)在x=x0处是可微的，那么h(x)可以写成 当x非常接近x0时，上式中的平方项等更高次项的值将无限接近于0，此时h(x)可以约等于 多变量泰勒展示同样成立，只需对各个变量分别求偏导数 因此，在任意点(a,b)处我们可以将损失函数用泰勒展示展开，并且当红色圆圈足够小时，圆圈内的函数值可以近似为 经过上面的推导，我们很好的解释了为什么要沿着梯度的反方向更新参数，并且也解释了学习速率ηη不能设置过大，否则L(θ)≈s+uΔθ1+vΔθ2将不再成立。 梯度下降的一些技巧1、学习速率（learning rate）学习速率是最需要调整的一个超参数，太小会使得训练速度过慢；太大会使得训练无法收敛，因此需要很小心的调节学习速率η。 我们可以绘出损失函数的曲线图，如上图左边所示，红色的学习速率最合适，蓝色的太小，绿色的偏大，黄色则非常大。但是当参数数目很多时将无法可视化损失函数曲线，这时我们可以绘制出随迭代次数增加损失值变化曲线，如上图右边所示。如果损失下降很慢（蓝色），可能学习速率过低；如果损失开始下降很快，但很快稳定在一个较大的值（绿色），可能学习速率偏大了；如果损失不降返升（黄色），学习速率可能过大了；只有损失以恰当的速度降到很小（红色），才是最佳学习速率。 2、Adagrad 下面尝试对Adagrad做一个解释，首先需要考虑的是：梯度越大，距离最低点越远，步伐越大？还是以两参数为例： 3、随机梯度下降（Stochastic Gradient Descent）or 小批量梯度下降（Mini-Batch Gradient Descent）常规的梯度下降也就是批量梯度下降，是在整个数据集上求偏导，在该方法中，每次更新我们需要计算整个数据集中每个样本点的误差，因此速度会比较慢，对于很大的数据集，内存可能无法容纳以至无法使用，因此在实际中一般使用随机梯度下降（Stochastic Gradient Descent）或者小批量梯度下降（Mini-Batch Gradient Descent）。随机梯度下降（Stochastic Gradient Descent）的每次更新，是对数据集中的每个样本点计算损失函数，这样对于m个样本的数据集，批量梯度下降更新一次，SGD可以更新m次，虽然每次只考虑一个样本点，可能存在较大的波动，但最终都会收敛。小批量梯度下降（Mini-Batch Gradient Descent）是批量梯度下降和随机梯度下降的折中，每次更新，对数据集中部分数据计算损失函数。 4、特征缩放（Feature Scaling）特征缩放是指将每个特征的取值限定在相同的范围 为什么要将每个特征的取值限定在相同范围呢？看下面的例子： 图中左边x1的取值范围是x2的百分之一，当w2稍有变化，y值将变化很大，因此损失函数也将变化很大，也就是说损失函数在w2方向下降很快，导致损失函数等高线呈扁平的椭圆形，这种情况下不用Adagrad将比较难处理，两个方向上需要不同的学习率。但经过特征缩放后，所有特征的取值范围都是统一的，损失函数等高线呈规整的圆形，梯度下降效率将比较高。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://uscair.club/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://uscair.club/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"author":{"name":"Wonder"}},{"title":"计算机网络原理学习（一）","slug":"计算机网络原理（一）","date":"2020-03-08T14:16:18.283Z","updated":"2020-03-08T14:16:18.283Z","comments":true,"path":"2020/03/08/计算机网络原理（一）/","link":"","permalink":"http://uscair.club/2020/03/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86%EF%BC%88%E4%B8%80%EF%BC%89/","excerpt":"","text":"小科普：调制解调器是Modulator（调制器）与Demodulator（解调器）的简称，中文称为调制解调器，根据Modem的谐音，亲昵地称之为“猫”，是一种能够实现通信所需的调制和解调功能的电子设备。一般由调制器和解调器组成。在发送端，将计算机串行口产生的数字信号调制成可以通过电话线传输的模拟信号；在接收端，调制解调器把输入计算机的模拟信号转换成相应的数字信号，送入计算机接口。在个人计算机中，调制解调器常被用来与别的计算机交换数据和程序，以及访问联机信息服务程序等。有“猫”才能上网，现代的一些路由器把“猫”的功能并与了一身。 一、互联网的成形 互联网服务提供者ISP（InternetService Provider）从互联网管理机构申请很多IP地址，同时拥有通信线路以及路由器等设备，个人可以只要向某个ISP交纳规定费用，就可以从ISP获取IP地址使用权，并通过ISP接入到互联网。ISP彼此还可以通过IXP进行交换分组，这样就避免了同等级的ISP要进行交换分组要到高一级ISP在到同一级ISP的繁琐步骤。 RFC（Request For Comments）记录了互联网的制定标准——互联网标准，大部分RFC可以在网络上进行下载。 二、互联网的组成 互联网的组成分为了俩个部分：边缘部分（用户直接使用，用来进行通信（传送数据、音频或视频）和资源共享）和核心部分（大量网络和连接网络的路由器，用来为边缘部分提供服务）（1）边缘部分 边缘部分就是连接在互联网上的所有主机他们被称为端系统（端表示为互联网的末端）。 网络边缘的端系统之间的通信方式可以划分为俩大类：客户-服务器（C/S）和对等方式（P2P，peer topeer 方式） 客户-服务器：客户主动发出响应（客户程序必须知道服务器程序的地址），服务器被动接收响应（可同时处理多个远地或本地客户的请求，不需要知道客户程序的地址）。服务器为客户提供服务，这便要求服务器是一直运行的可以随时接收客户发出的响应。 对等方式（P2P）：俩个双方可以进行平等的、对等连接通信。可以看成俩者既是服务器又是用户。 （2）互联网的核心部分 向网络边缘中的大量主机提供连通性，使边缘部分中的任何一台主机能够向其他主机通信。在网络核心部分中其特殊作用的是路由器（一种专用计算机，实现分组交换），其任务是转发收到的分组。 [1]电路交换： 在电话问世时使用的是电路交换：首先是通过电话线使用户进行数据交流，这样十分的浪费资源（需要的电话线数量太多）于是用电话交换机将电话连接了起来（电路交换），交换：按照某种方式动态地分配传输线路的资源。用户进行通信时必须经过建立连接——通话——释放连接。三个步骤称为电路交换。电路交换的一个重要特点就是在通话的全部时间内，通话的俩个用户始终占用端到端的通信资源。使用电路交换线路传输效率往往很低。 [2]分组交换： 把一个报文（要发送的整块数据）划分为几个分组后进行传送。在每一个数据段前面，加上一些由必要的控制信息组成的首部，就构成了一个分组。分组称为“包”，分组的首部称为“包头”（包含了目的地址和源地址），有了包头每一个分组才能在互联网中独立选择传输路径，正确的交付到传输终点。路由器就是用来进行分组交换的，它也是计算机。可通过路由器对线路进行选择，一条通信线路被占就走另外一条线路直到到达目标机。 电路交换——整个报文的比特流连续地从源点直达终点，好像在一个管道中传送。 报文交换——整个报文先传送 到相邻结点，全部存储下来后查找转发表，转发到下一个结点。 分组交换——单个分组(这只是整个报文的一部分)传送到相邻结点，存储下来后查找转发表，转发到下一个结点。","categories":[{"name":"网络原理","slug":"网络原理","permalink":"http://uscair.club/categories/%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86/"}],"tags":[{"name":"网络原理","slug":"网络原理","permalink":"http://uscair.club/tags/%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86/"}],"author":{"name":"Page"}},{"title":"聚类算法概念","slug":"聚类算法概念","date":"2020-03-07T16:00:00.000Z","updated":"2020-03-07T16:00:00.000Z","comments":true,"path":"2020/03/08/聚类算法概念/","link":"","permalink":"http://uscair.club/2020/03/08/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E6%A6%82%E5%BF%B5/","excerpt":"","text":"聚类算法是机器学习中涉及对数据进行分组的一种算法。在给定的数据集中，我们可以通过聚类算法将其分成一些不同的组。在理论上，相同的组的数据之间有相同的属性或者是特征，不同组数据之间的属性或者特征相差就会比较大。聚类算法是一种非监督学习算法，并且作为一种常用的数据分析算法在很多领域上得到应用。 分类1.基于划分给定一个有N个元组或者纪录的数据集，分裂法将构造K个分组，每一个分组就代表一个聚类，K&lt;N。特点：计算量大。很适合发现中小规模的数据库中小规模的数据库中的球状簇。算法：K-MEANS算法、K-MEDOIDS算法、CLARANS算法 2.基于层次对给定的数据集进行层次似的分解，直到某种条件满足为止。具体又可分为“自底向上”和“自顶向下”两种方案。特点：较小的计算开销。然而这种技术不能更正错误的决定。算法：BIRCH算法、CURE算法、CHAMELEON算法 3.基于密度只要一个区域中的点的密度大过某个阈值，就把它加到与之相近的聚类中去。特点：能克服基于距离的算法只能发现“类圆形”的聚类的缺点。算法：DBSCAN算法、OPTICS算法、DENCLUE算法 4.基于网格将数据空间划分成为有限个单元（cell）的网格结构,所有的处理都是以单个的单元为对象的。特点：处理速度很快，通常这是与目标数据库中记录的个数无关的，只与把数据空间分为多少个单元有关。算法：STING算法、CLIQUE算法、WAVE-CLUSTER算法","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://uscair.club/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"聚类算法","slug":"聚类算法","permalink":"http://uscair.club/tags/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/"}],"author":{"name":"ffffff"}},{"title":"计算机网络原理学习（三）","slug":"计算机网络原理（三）","date":"2020-03-07T16:00:00.000Z","updated":"2020-03-07T16:00:00.000Z","comments":true,"path":"2020/03/08/计算机网络原理（三）/","link":"","permalink":"http://uscair.club/2020/03/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86%EF%BC%88%E4%B8%89%EF%BC%89/","excerpt":"","text":"六 有五层协议的体系结构 1.OSI有七层协议体系，但过于复杂，TCP/IP是·四层体系结构：应用层、运输层、网际层和网络接口层。俩者结合采用一种五层协议的体系结构，最底下俩层也被称为网络接口层。（1）应用层：通过应用进程间的交互来完成特定网络应用。应用层协议定义的是应用进程间通信和交互的规则。应用层交互的数据单元称为报文。 （2）运输层：负责向俩台主机中的进程之间的通信提供通用的数据传输服务。传送应用层报文。运输层有复用和分用俩个功能，复用：多个应用层进程可同时使用下面运输层的服务，分用：运输层把收到的信息分别交付上面的应用层。运输层主要使用以下俩种协议：传输控制协议TCP（Transmission Control Protocol）（提供面向连接的，可靠的数据传输服务，其数据传输的单位是报文段），用户数据报协议UDP（User Datagram Protocol）（提供无连接的，尽最大努力的数据传输服务[不保证数据传输的可靠性]，其数据数据传输的单位是用户数据报） （3）网络层：负责为分组交换网上的不同不同主机提供通信服务。1.在发送数据时，把运输层产生的报文段或用户数据报封装成分组或包进行传送。2.选择合适的路由，使源主机运输层所传下来的分组，能够通过网络中的路由器找到目标主机。互联网由大量的异构网络通过路由器互相连接起来的。互联网使用的网络层协议是无连接的网际协议IP和许多路由选择协议，因此互联网的网络层也叫做网际层或IP层。 （4）数据链路层：主机之间的数据传输，总是在一段一段的链路上传送的，这需要使用专门的链路层协议。在俩个相邻结点之间传送数据时，数据链路层将网络层下来的IP数据报组装成帧，在俩个相邻结点间的链路上传送帧。每一帧包括数据和必要的控制信息（同步信息，地址信息，差错控制） （5）物理层：物理层上传送数据的单位是比特。因此物理层要考虑用多大的电压代表“1”或“0” 数据在俩台主机间的传送（通过一个路由器相连的俩台主机）传输的过程简介：假定主机1的应用进程AP1向主机2的应用进程AP2传送数据。AP1 先将其数据交给本主机的第5层(应用层)。第5层加上必要的控制信息Hs就变成了下一-层的数据单元。第4层(运输层)收到这个数据单元后，加上本层的控制信息H4， 再交给第3层(网络层)，成为第3层的数据单元。依此类推。不过到了第2层(数据链路层)后，控制信息被分成两部分，分别加到本层数据单元的首部(H2)和尾部(T2);而第1层(物理层)由于是比特流的传送，所以不再加上控制信息。请注意，传送比特流时应从首部开始传送。 OSI模型把对等层次之间的传送的数据单元称为该层的协议数据单元PDU（Protocol Data Unit）。 当这一串的比特流离开主机1经网络的物理媒体传送到路由器时，就从路由器的第1层依次上升到第3层。每一层都根据控制信息进行必要的操作，然后将控制信息剥去，将该层剩下的数据单元上交给更高的一层。当分组上升到了第3层时，就根据首部中的目的地址查找路由器中的转发表，找出转发分组的接口，然后往下传送到第2层，加上新的首部和尾部后，再到最下面的第1层，然后在物理媒体上把每-一个比特发送出去。当这一串的比特流离开路由器到达目的站主机2时，就从主机2的第1层按照上面讲过的方式，依次上升到第5层。最后，把应用进程AP1发送的数据交给目的站的应用进程AP2。 可以用一个简单例子来比喻上述过程。有一封信从最高层向下传。每经过一层就包上一个新的信封，写上必要的地址信息。包有多个信封的信件传送到目的站后，从第1层起，每层拆开一个信封后就把信封中的信交给它的上一层。传到最高层后，取出发信人所发的信交给收信人。 上面几层只是起到一个数据封装打包的作用，真正起到传输作用的还是物理层。 七 实体、协议、服务和服务访问点 实体：任何可发送或接收信息的硬件或软件进程 协议：控制俩个对等实体（或多个实体）进行通信的规则的集合。在协议控制下、俩个对等实体间的通信使得本层能够向上一层提供服务。要实现本层协议，还需要使用下面一层所提供的服务。 协议是“水平的”，服务是“垂直的”。 同一系统中相邻俩层的实体进行交互（即交换信息）的地方，通常称为称为服务访问点SAP OSI把层与层层与层之间交换的数据的单位称为服务数据单元SDU（Service Data Unit） 协议必须把所有不利的条件事先都估计到，而不能假定一切都是正常的和非常理想的。 1.7.5 TCP/IP的体系结构 沙漏计时器形状TCP/IP协议族示意：IP为最中心最重要的一部分。","categories":[{"name":"网络原理","slug":"网络原理","permalink":"http://uscair.club/categories/%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86/"}],"tags":[{"name":"网络原理","slug":"网络原理","permalink":"http://uscair.club/tags/%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86/"}],"author":{"name":"Page"}},{"title":"机器学习介绍","slug":"机器学习介绍","date":"2020-03-07T13:51:00.000Z","updated":"2020-03-07T13:51:00.000Z","comments":true,"path":"2020/03/07/机器学习介绍/","link":"","permalink":"http://uscair.club/2020/03/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BB%8B%E7%BB%8D/","excerpt":"&lt;恐怖慎入&gt;","text":"&lt;恐怖慎入&gt; 机器学习 机器学习是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。 它是人工智能的核心，是使计算机具有智能的根本途径。 这里仅简单介绍一下机器学习，了解其的三个分支：监督学习、无监督学习、半监督学习、强化学习。 监督学习 监督学习是指：利用一组已知类别的样本调整分类器的参数，使其达到所要求性能的过程，也称为监督训练或有教师学习。 监督学习是给出已标记数据，通常利用数据找出线性拟合曲线来进行预测（predict）或是分类（classify）。系统被赋予一个数据集，同时它已经知道了期望的输出是什么，并了解每个相关层的输入和输出的关系。 例如：城市人口与城市利润的预测 数据集 直线为训练后获得的线性回归直线 其中模型预测与人工预测比较: Theta found by gradient descent: -3.630291 1.166362 Expected theta values (approx) -3.6303 1.1664 For population = 35,000, we predict a profit of 4519.767868 For population = 70,000, we predict a profit of 45342.450129无监督学习 根据类别未知(没有被标记)的训练样本解决模式识别中的各种问题，称之为无监督学习。 在无监督学习中，给定的输入只是一些数据集，并没有给出数据的期待输出。在分析数据集时，系统从其经验中学习有意义的属性和特征。常用来实现聚类问题，聚类将具有相似数据类型的多个数据放到同一个簇中。 在大数据时代，通过对数据的分类挖掘出数据的深层价值，这也就是数据变得越来越值钱的一个因素，无监督学习在数据挖掘方面有着很大的用处。 比如大家在淘宝、天猫、京东上逛的时候，总会根据你的浏览行为推荐一些相关的商品，有些商品就是无监督学习通过聚类来推荐出来的。系统会发现一些购买行为相似的用户，推荐这类用户最”喜欢”的商品。都是使用无监督学习的各种应用。 半监督学习 半监督学习（Semi-Supervised Learning，SSL）是模式识别和机器学习领域研究的重点问题，是监督学习与无监督学习相结合的一种学习方法。 半监督学习使用大量的未标记数据，以及同时使用标记数据，来进行模式识别工作。当使用半监督学习时，将会要求尽量少的人员来从事工作，同时，又能够带来比较高的准确性，因此，半监督学习目前正越来越受到人们的重视。 强化学习 强化学习（Reinforcement Learning, RL），又称再励学习、评价学习或增强学习，是机器学习的范式和方法论之一，用于描述和解决智能体（agent）在与环境的交互过程中通过学习策略以达成回报最大化或实现特定目标的问题。 强化学习理论受到行为主义心理学启发，侧重在线学习并试图在探索-利用（exploration-exploitation）间保持平衡。不同于监督学习和非监督学习，强化学习不要求预先给定任何数据，而是通过接收环境对动作的奖励（反馈）获得学习信息并更新模型参数 。 AlphaGo Zero的自我博弈训练就是使用的强化学习模型 关于提及的相关知识将再后面以专题出现。","categories":[{"name":"机器学习专栏","slug":"机器学习专栏","permalink":"http://uscair.club/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%93%E6%A0%8F/"}],"tags":[{"name":"AI大数据","slug":"AI大数据","permalink":"http://uscair.club/tags/AI%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"author":{"name":"戴挽舟（BbiHH）"}},{"title":"深度学习对数据集的预处理","slug":"深度学习对数据集的预处理","date":"2020-03-06T16:00:00.000Z","updated":"2020-03-06T16:00:00.000Z","comments":true,"path":"2020/03/07/深度学习对数据集的预处理/","link":"","permalink":"http://uscair.club/2020/03/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AF%B9%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E9%A2%84%E5%A4%84%E7%90%86/","excerpt":"","text":"深度学习对数据集的预处理因为在使用神经网络的时候常常采用的图片数据集，常常是一个尺寸相同的，但是我们下载来的数据集往往尺寸不一定相同。所以我们应该转化为相同尺寸的数据集。笔者首先考虑过用cv2.resize()把图片变为等尺寸的，在同torch.form_numpy()转化成tensor来出来，但是resize改变了图片等的比例，所以在神经网络中的拟合出的结果可能不是我们所希望的。 所以我们采用一下的方法： 首先设置一个图片的目标尺寸 把图片以最短边按比例缩小 然后随机剪裁为目标尺寸 代码环境：python3.7.4，pytorch1.4.0，jupyter notebook 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270#!/usr/bin/env python# coding: utf-8# In[1]:from __future__ import print_function,divisionimport osimport torchimport pandas as pdfrom skimage import io,transformimport numpy as npimport matplotlib.pyplot as pltfrom torch.utils.data import Dataset,DataLoaderfrom torchvision import transforms,utilsimport warnings# In[2]:warnings.filterwarnings('ignore')# In[3]:plt.ion()# In[4]:landmarks_frame=pd.read_csv('data/faces/face_landmarks.csv')# https://download.pytorch.org/tutorial/faces.zip 数据集下载地址# 把数据放在data文件夹下n=65img_name=landmarks_frame.iloc[n,0]landmarks=landmarks_frame.iloc[n,1:]landmarks=np.asarray(landmarks)landmarks=landmarks.astype('float').reshape(-1,2)# 转化成n行2列的形式print('Image name: &#123;&#125;'.format(img_name))print('Landmarks shape: &#123;&#125;'.format(landmarks.shape))print('First 4 Landmarks: &#123;&#125;'.format(landmarks[:4]))# In[5]:def show_landmarks(image, landmarks): plt.imshow(image) plt.scatter(landmarks[:,0],landmarks[:,1],s=10,marker='.',c='red') plt.pause(0.001)# In[6]:plt.figure()show_landmarks(io.imread(os.path.join('data/faces/', img_name)), landmarks)plt.show()# In[7]:class FaceLandmarksDataset(Dataset): def __init__(self,csv_file,root_dir,transform=None): ''' :param csv_file: 带注释带csv文件路径 :param root_dir: 所有图像的目录 :param transform: (可选)在一个样本上转换 ''' self.landmarks_frame=pd.read_csv(csv_file) self.root_dir=root_dir self.transform=transform def __len__(self): return len(self.landmarks_frame) def __getitem__(self, idx): if torch.is_tensor(idx): idx=idx.tolist() # 将张量作为（嵌套的）列表返回 img_name=os.path.join(self.root_dir, self.landmarks_frame.iloc[idx,0]) # 图片地址 image=io.imread(img_name) landmarks=self.landmarks_frame.iloc[idx,1:] # 图片的标记点 landmarks=np.array([landmarks]) landmarks=landmarks.astype('float').reshape(-1,2) sample=&#123;'image':image,'landmarks':landmarks&#125; if self.transform: sample=self.transform(sample) # 转置 return sample # In[8]:face_dataset=FaceLandmarksDataset(csv_file='data/faces/face_landmarks.csv', root_dir='data/faces/')fig=plt.figure()for i in range(len(face_dataset)): sample=face_dataset[i] print(i,sample['image'].shape,sample['landmarks'].shape) ax=plt.subplot(1,4,i+1) plt.tight_layout() ax.set_title('sample #&#123;&#125;'.format(i)) ax.axis('off') show_landmarks(**sample) # dict输入 if i==3: # 展示前4组图片 plt.show() break # In[9]:class Rescale(object): \"\"\" 把图片缩放为相同的大小 如果为元组，则输出与output_size匹配。 如果为int，则将较小的图像边缘与output_size匹配，并保持宽高比相同。 参数： output_size:输出大小 \"\"\" def __init__(self, output_size): assert isinstance(output_size,(int,tuple)) self.output_size=output_size def __call__(self, sample): image, landmarks = sample['image'], sample['landmarks'] h, w = image.shape[:2] if isinstance(self.output_size, int): # 如果是整型，将较小的图像边缘与output_size匹配，并保持宽高比相同 if h &gt; w: new_h,new_w=self.output_size*h/w,self.output_size else: new_h,new_w=self.output_size,self.output_size*w/h else: new_h, new_w = self.output_size new_h, new_w = int(new_h),int(new_w) img = transform.resize(image, (new_h, new_w)) # h and w are swapped for landmarks because for images, # x and y axes are axis 1 and 0 respectively landmarks = landmarks*[new_w / w, new_h / h] # 同时把标记按比例缩小 return &#123;'image': img, 'landmarks': landmarks&#125;# In[10]:class RandomCrop(object): \"\"\" 随机裁剪图片 Args: output_size (tuple or int):期望的输入如果是整形则裁剪成正方形 \"\"\" def __init__(self, output_size): assert isinstance(output_size, (int, tuple)) if isinstance(output_size, int): self.output_size = (output_size, output_size) else: assert len(output_size) == 2 self.output_size = output_size def __call__(self, sample): image, landmarks = sample['image'], sample['landmarks'] h, w = image.shape[:2] new_h, new_w = self.output_size top = np.random.randint(0, h - new_h) # 在0到h-new_h之间产生随机数 left = np.random.randint(0, w - new_w) image = image[top: top + new_h, left: left + new_w] # 随机剪裁的范围 landmarks = landmarks - [left, top] return &#123;'image': image, 'landmarks': landmarks&#125;# In[11]:class ToTensor(object): \"\"\" 把darray转成tensor \"\"\" def __call__(self, sample): image, landmarks = sample['image'], sample['landmarks'] # numpy image: H x W x C # torch image: C X H X W image = image.transpose((2, 0, 1)) # 把numpy的格式转化成tensor return &#123;'image': torch.from_numpy(image), 'landmarks': torch.from_numpy(landmarks)&#125;# In[12]:scale = Rescale(256)crop = RandomCrop(128)composed = transforms.Compose([Rescale(256), RandomCrop(224)])# 在每一个样本图片上应用fig = plt.figure()sample = face_dataset[65]for i, tsfrm in enumerate([scale, crop, composed]): transformed_sample = tsfrm(sample) ax = plt.subplot(1, 3, i + 1) plt.tight_layout() ax.set_title(type(tsfrm).__name__) show_landmarks(**transformed_sample)plt.show()# In[13]:transformed_dataset=FaceLandmarksDataset(csv_file='data/faces/face_landmarks.csv', root_dir='data/faces/', transform=transforms.Compose([Rescale(256), RandomCrop(224), ToTensor()]))for i in range(len(transformed_dataset)): sample=transformed_dataset[i] print(i,sample['image'].size(),sample['landmarks'].size()) if i==3: break# In[14]:dataloader = DataLoader(transformed_dataset, batch_size=4, shuffle=True, num_workers=4) # 用4个进程来加载数据每个批次4个并洗牌# In[15]:def show_landmarks_batch(sample_batched): # 在一组图片中使用标记展示图片 images_batch,landmarks_batch=sample_batched['image'],sample_batched['landmarks'] batch_size=len(images_batch) im_size=images_batch.size(2) grid_border_size=2 grid=utils.make_grid(images_batch) plt.imshow(grid.numpy().transpose((1,2,0))) for i in range(batch_size): plt.scatter(landmarks_batch[i,:,0].numpy()+i*im_size+(i+1)*grid_border_size, landmarks_batch[i,:,1].numpy()+grid_border_size, s=10, marker='.', c='red') plt.title('Batch from dataloader')# In[16]:for i_batch, sample_batched in enumerate(dataloader): print(i_batch,sample_batched['image'].size(),sample_batched['landmarks'].size()) if i_batch==3: plt.figure() show_landmarks_batch(sample_batched) plt.axis('off') plt.ioff() plt.show() break","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://uscair.club/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Pytorh","slug":"Pytorh","permalink":"http://uscair.club/tags/Pytorh/"},{"name":"数据集预处理","slug":"数据集预处理","permalink":"http://uscair.club/tags/%E6%95%B0%E6%8D%AE%E9%9B%86%E9%A2%84%E5%A4%84%E7%90%86/"}],"author":{"name":"Gowi"}},{"title":"深度学习对数据集的预处理","slug":"深度学习对数据集的预处理 - 副本","date":"2020-03-06T16:00:00.000Z","updated":"2020-03-06T16:00:00.000Z","comments":true,"path":"2020/03/07/深度学习对数据集的预处理 - 副本/","link":"","permalink":"http://uscair.club/2020/03/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AF%B9%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E9%A2%84%E5%A4%84%E7%90%86%20-%20%E5%89%AF%E6%9C%AC/","excerpt":"","text":"深度学习对数据集的预处理因为在使用神经网络的时候常常采用的图片数据集，常常是一个尺寸相同的，但是我们下载来的数据集往往尺寸不一定相同。所以我们应该转化为相同尺寸的数据集。笔者首先考虑过用cv2.resize()把图片变为等尺寸的，在同torch.form_numpy()转化成tensor来出来，但是resize改变了图片等的比例，所以在神经网络中的拟合出的结果可能不是我们所希望的。 所以我们采用一下的方法： 首先设置一个图片的目标尺寸 把图片以最短边按比例缩小 然后随机剪裁为目标尺寸 代码环境：python3.7.4，pytorch1.4.0，jupyter notebook 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270#!/usr/bin/env python# coding: utf-8# In[1]:from __future__ import print_function,divisionimport osimport torchimport pandas as pdfrom skimage import io,transformimport numpy as npimport matplotlib.pyplot as pltfrom torch.utils.data import Dataset,DataLoaderfrom torchvision import transforms,utilsimport warnings# In[2]:warnings.filterwarnings('ignore')# In[3]:plt.ion()# In[4]:landmarks_frame=pd.read_csv('data/faces/face_landmarks.csv')# https://download.pytorch.org/tutorial/faces.zip 数据集下载地址# 把数据放在data文件夹下n=65img_name=landmarks_frame.iloc[n,0]landmarks=landmarks_frame.iloc[n,1:]landmarks=np.asarray(landmarks)landmarks=landmarks.astype('float').reshape(-1,2)# 转化成n行2列的形式print('Image name: &#123;&#125;'.format(img_name))print('Landmarks shape: &#123;&#125;'.format(landmarks.shape))print('First 4 Landmarks: &#123;&#125;'.format(landmarks[:4]))# In[5]:def show_landmarks(image, landmarks): plt.imshow(image) plt.scatter(landmarks[:,0],landmarks[:,1],s=10,marker='.',c='red') plt.pause(0.001)# In[6]:plt.figure()show_landmarks(io.imread(os.path.join('data/faces/', img_name)), landmarks)plt.show()# In[7]:class FaceLandmarksDataset(Dataset): def __init__(self,csv_file,root_dir,transform=None): ''' :param csv_file: 带注释带csv文件路径 :param root_dir: 所有图像的目录 :param transform: (可选)在一个样本上转换 ''' self.landmarks_frame=pd.read_csv(csv_file) self.root_dir=root_dir self.transform=transform def __len__(self): return len(self.landmarks_frame) def __getitem__(self, idx): if torch.is_tensor(idx): idx=idx.tolist() # 将张量作为（嵌套的）列表返回 img_name=os.path.join(self.root_dir, self.landmarks_frame.iloc[idx,0]) # 图片地址 image=io.imread(img_name) landmarks=self.landmarks_frame.iloc[idx,1:] # 图片的标记点 landmarks=np.array([landmarks]) landmarks=landmarks.astype('float').reshape(-1,2) sample=&#123;'image':image,'landmarks':landmarks&#125; if self.transform: sample=self.transform(sample) # 转置 return sample # In[8]:face_dataset=FaceLandmarksDataset(csv_file='data/faces/face_landmarks.csv', root_dir='data/faces/')fig=plt.figure()for i in range(len(face_dataset)): sample=face_dataset[i] print(i,sample['image'].shape,sample['landmarks'].shape) ax=plt.subplot(1,4,i+1) plt.tight_layout() ax.set_title('sample #&#123;&#125;'.format(i)) ax.axis('off') show_landmarks(**sample) # dict输入 if i==3: # 展示前4组图片 plt.show() break # In[9]:class Rescale(object): \"\"\" 把图片缩放为相同的大小 如果为元组，则输出与output_size匹配。 如果为int，则将较小的图像边缘与output_size匹配，并保持宽高比相同。 参数： output_size:输出大小 \"\"\" def __init__(self, output_size): assert isinstance(output_size,(int,tuple)) self.output_size=output_size def __call__(self, sample): image, landmarks = sample['image'], sample['landmarks'] h, w = image.shape[:2] if isinstance(self.output_size, int): # 如果是整型，将较小的图像边缘与output_size匹配，并保持宽高比相同 if h &gt; w: new_h,new_w=self.output_size*h/w,self.output_size else: new_h,new_w=self.output_size,self.output_size*w/h else: new_h, new_w = self.output_size new_h, new_w = int(new_h),int(new_w) img = transform.resize(image, (new_h, new_w)) # h and w are swapped for landmarks because for images, # x and y axes are axis 1 and 0 respectively landmarks = landmarks*[new_w / w, new_h / h] # 同时把标记按比例缩小 return &#123;'image': img, 'landmarks': landmarks&#125;# In[10]:class RandomCrop(object): \"\"\" 随机裁剪图片 Args: output_size (tuple or int):期望的输入如果是整形则裁剪成正方形 \"\"\" def __init__(self, output_size): assert isinstance(output_size, (int, tuple)) if isinstance(output_size, int): self.output_size = (output_size, output_size) else: assert len(output_size) == 2 self.output_size = output_size def __call__(self, sample): image, landmarks = sample['image'], sample['landmarks'] h, w = image.shape[:2] new_h, new_w = self.output_size top = np.random.randint(0, h - new_h) # 在0到h-new_h之间产生随机数 left = np.random.randint(0, w - new_w) image = image[top: top + new_h, left: left + new_w] # 随机剪裁的范围 landmarks = landmarks - [left, top] return &#123;'image': image, 'landmarks': landmarks&#125;# In[11]:class ToTensor(object): \"\"\" 把darray转成tensor \"\"\" def __call__(self, sample): image, landmarks = sample['image'], sample['landmarks'] # numpy image: H x W x C # torch image: C X H X W image = image.transpose((2, 0, 1)) # 把numpy的格式转化成tensor return &#123;'image': torch.from_numpy(image), 'landmarks': torch.from_numpy(landmarks)&#125;# In[12]:scale = Rescale(256)crop = RandomCrop(128)composed = transforms.Compose([Rescale(256), RandomCrop(224)])# 在每一个样本图片上应用fig = plt.figure()sample = face_dataset[65]for i, tsfrm in enumerate([scale, crop, composed]): transformed_sample = tsfrm(sample) ax = plt.subplot(1, 3, i + 1) plt.tight_layout() ax.set_title(type(tsfrm).__name__) show_landmarks(**transformed_sample)plt.show()# In[13]:transformed_dataset=FaceLandmarksDataset(csv_file='data/faces/face_landmarks.csv', root_dir='data/faces/', transform=transforms.Compose([Rescale(256), RandomCrop(224), ToTensor()]))for i in range(len(transformed_dataset)): sample=transformed_dataset[i] print(i,sample['image'].size(),sample['landmarks'].size()) if i==3: break# In[14]:dataloader = DataLoader(transformed_dataset, batch_size=4, shuffle=True, num_workers=4) # 用4个进程来加载数据每个批次4个并洗牌# In[15]:def show_landmarks_batch(sample_batched): # 在一组图片中使用标记展示图片 images_batch,landmarks_batch=sample_batched['image'],sample_batched['landmarks'] batch_size=len(images_batch) im_size=images_batch.size(2) grid_border_size=2 grid=utils.make_grid(images_batch) plt.imshow(grid.numpy().transpose((1,2,0))) for i in range(batch_size): plt.scatter(landmarks_batch[i,:,0].numpy()+i*im_size+(i+1)*grid_border_size, landmarks_batch[i,:,1].numpy()+grid_border_size, s=10, marker='.', c='red') plt.title('Batch from dataloader')# In[16]:for i_batch, sample_batched in enumerate(dataloader): print(i_batch,sample_batched['image'].size(),sample_batched['landmarks'].size()) if i_batch==3: plt.figure() show_landmarks_batch(sample_batched) plt.axis('off') plt.ioff() plt.show() break","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://uscair.club/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Pytorh","slug":"Pytorh","permalink":"http://uscair.club/tags/Pytorh/"},{"name":"数据集预处理","slug":"数据集预处理","permalink":"http://uscair.club/tags/%E6%95%B0%E6%8D%AE%E9%9B%86%E9%A2%84%E5%A4%84%E7%90%86/"}],"author":{"name":"Gowi"}},{"title":"机器学习系列（五）——训练集、测试集、验证集与模型选择","slug":"机器学习系列（五）——训练集、测试集、验证集与模型选择","date":"2020-03-01T14:21:57.759Z","updated":"2020-03-01T14:21:57.759Z","comments":true,"path":"2020/03/01/机器学习系列（五）——训练集、测试集、验证集与模型选择/","link":"","permalink":"http://uscair.club/2020/03/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%88%E4%BA%94%EF%BC%89%E2%80%94%E2%80%94%E8%AE%AD%E7%BB%83%E9%9B%86%E3%80%81%E6%B5%8B%E8%AF%95%E9%9B%86%E3%80%81%E9%AA%8C%E8%AF%81%E9%9B%86%E4%B8%8E%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9/","excerpt":"","text":"在机器学习过程中，为了找到泛化性能最好的那个函数，我们需要确定两方面的参数：1、假设函数参数，也就是我们通常所说的w和b，这类参数可以通过各种最优化算法自动求得。2、模型参数，比如多项式回归中的多项式次数，规则化参数λ等，这些参数被称为超参数，一般在模型训练之前通过手工指定（当然也可以采用网格法等算法进行寻优）。确定模型超参数的过程称为模型选择。 模型选择借用吴恩达机器学习课程中的一页PPT，如下图： 现在我们要确定多项式回归的次数d，我们手工指定d取值1到10，然后在训练集上训练模型，分别找出了最优参数θ(1),θ(2),⋯,θ(10)θ(1),θ(2),⋯,θ(10)，接着在测试集上对模型性能进行评估，得到测试误差Jtest(θ(1)),Jtest(θ(2)),⋯,Jtest(θ(10))，选择测试误差最小的那个作为最优模型，假设我们选择了d=5d=5的那个模型θ0+θ1x+⋯+θ5x^5。现在问题来了，我们要怎么去评价这个模型的泛化性能呢？仍然采用测试误差吗？如果我们采用测试误差作为度量，那我们是不是可以继续调整d的取值呢，直至测试误差降到最低，但是此时的模型我们能相信吗？显然是不能相信的，因为我们已经提前窥见到了测试数据，我们的超参数都是围绕更好的拟合测试数据而设定的，Jtest(θ)因此很有可能是泛化误差的一个最优估计。问题就出在我们将测试数据多次使用，违背了测试数据仅仅只是用来评估最优函数的泛化性能的原则。 为了解决这个问题，我们在训练集中单独划分出一块，作为模型选择的依据，我们把这部分数据称为验证集，现在我们的数据集由之前的训练集和测试集两部分组成变成了训练集，验证集和测试集三部分组成。 训练集：用于训练模型，找出最佳的w和b。 验证集：用以确定模型超参数，选出最优模型。 测试集：仅用于对训练好的最优函数进行性能评估。 训练集、验证集和测试集分工明确，各施其职，切不可互相取而代之。特别是不能混淆验证集和测试集，下面用一个表整理下两者的区别： 区别 验证集 测试集 作用 确定模型超参数 仅用于对训练好的最优函数进行性能评估 是否用于训练 否（在选出最优模型后，需要将验证集也放入训练集一起训练最优函数） 否 使用次数 多次使用，每次更新超参数后都要用验证集对模型性能进行验证 仅在最后使用一次 再强调一下：对最终学习得到的函数进行性能评估的数据叫作测试集，必须保证测试集完全独立，直到模型调整和参数训练全部完成前应该将测试集进行封存，以任何形式使用测试集中的信息都是一种窥探。所以，此时机器学习的全过程如下： 确定模型的一组超参数用训练集训练该模型，找到使损失函数最小的最优函数。在验证集上对最优函数的性能进行度量。重复1、2、3步，直到搜索完指定的超参数组合。选择在验证集上误差最小的模型，并合并训练集和验证集作为整体训练模型，找到最优函数。在测试集上对最优函数的泛化性能进行度量。最后，我们都知道同一模型在不同训练集上学得的函数往往不同，那我们怎样保证选出的模型和函数就是最好的呢？而不是刚好符合当前数据划分的一个特例呢？可以采用交叉验证（Cross Validation）法，其基本思路如下：将训练集划分为K份，每次采用其中K-1份作为训练集，另外一份作为验证集，验证集上K次误差的平均作为该模型的误差。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://uscair.club/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://uscair.club/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"author":{"name":"Wonder"}},{"title":"前馈神经网络","slug":"前馈神经网络","date":"2020-02-29T16:00:00.000Z","updated":"2020-02-29T16:00:00.000Z","comments":true,"path":"2020/03/01/前馈神经网络/","link":"","permalink":"http://uscair.club/2020/03/01/%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/","excerpt":"","text":"基本概念深度前馈神经网络也叫作多层感知机，是深度学习中最常用的模型。它包含输入层，隐含层和输出层三个部分。它的目的是为了实现输入到输出的映射。在前馈神经网络中，不同的神经元属于不同的层，每一层的神经元可以接受到前一层的神经元信号，并产生信号输出到下一层。第0层叫做输入层，最后一层叫做输出层，中间的叫做隐藏层，整个网络中无反馈，信号从输入层到输出层单向传播，可用一个有用无环图表示。 下图为前馈神经网络图例子： 计算简略的看当只有单层神经网络时： 多层则以此类推。 偏置节点我们使用圆圈来表示神经网络的输入，标上“+1+1”的圆圈被称为”’偏置节点”’，也就是截距项。偏置的存在是为了更好地拟合数据","categories":[{"name":"数字图像处理","slug":"数字图像处理","permalink":"http://uscair.club/categories/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}],"tags":[{"name":"神经网络","slug":"神经网络","permalink":"http://uscair.club/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"author":{"name":"ffffff"}},{"title":"人工智能","slug":"不败顽童博主","date":"2020-02-28T16:00:00.000Z","updated":"2020-02-28T16:00:00.000Z","comments":true,"path":"2020/02/29/不败顽童博主/","link":"","permalink":"http://uscair.club/2020/02/29/%E4%B8%8D%E8%B4%A5%E9%A1%BD%E7%AB%A5%E5%8D%9A%E4%B8%BB/","excerpt":"","text":"人工智能的定义可以分为两部分，即“人工”和“智能”。“人工”比较好理解，争议性也不大。有时我们会要考虑什么是人力所能及制造的，或者人自身的智能程度有没有高到可以创造人工智能的地步，等等。但总的来说，“人工系统”就是通常意义下的人工系统。关于什么是“智能”，就问题多多了。这涉及到其它诸如意识（CONSCIOUSNESS）、自我（SELF）、思维（MIND）（包括无意识的思维（UNCONSCIOUS_MIND））等等问题。人唯一了解的智能是人本身的智能，这是普遍认同的观点。但是我们对我们自身智能的理解都非常有限，对构成人的智能的必要元素也了解有限，所以就很难定义什么是“人工”制造的“智能”了。因此人工智能的研究往往涉及对人的智能本身的研究。其它关于动物或其它人造系统的智能也普遍被认为是人工智能相关的研究课题。人工智能在计算机领域内，得到了愈加广泛的重视。并在机器人，经济政治决策，控制系统，仿真系统中得到应用。尼尔逊教授对人工智能下了这样一个定义：“人工智能是关于知识的学科――怎样表示知识以及怎样获得知识并使用知识的科学。”而另一个美国麻省理工学院的温斯顿教授认为：“人工智能就是研究如何使计算机去做过去只有人才能做的智能工作。”这些说法反映了人工智能学科的基本思想和基本内容。即人工智能是研究人类智能活动的规律，构造具有一定智能的人工系统，研究如何让计算机去完成以往需要人的智力才能胜任的工作，也就是研究如何应用计算机的软硬件来模拟人类某些智能行为的基本理论、方法和技术。人工智能是计算机学科的一个分支，二十世纪七十年代以来被称为世界三大尖端技术之一（空间技术、能源技术、人工智能）。也被认为是二十一世纪三大尖端技术（基因工程、纳米科学、人工智能）之一。这是因为近三十年来它获得了迅速的发展，在很多学科领域都获得了广泛应用，并取得了丰硕的成果，人工智能已逐步成为一个独立的分支，无论在理论和实践上都已自成一个系统。人工智能是研究使计算机来模拟人的某些思维过程和智能行为（如学习、推理、思考、规划等）的学科，主要包括计算机实现智能的原理、制造类似于人脑智能的计算机，使计算机能实现更高层次的应用。人工智能将涉及到计算机科学、心理学、哲学和语言学等学科。可以说几乎是自然科学和社会科学的所有学科，其范围已远远超出了计算机科学的范畴，人工智能与思维科学的关系是实践和理论的关系，人工智能是处于思维科学的技术应用层次，是它的一个应用分支。从思维观点看，人工智能不仅限于逻辑思维，要考虑形象思维、灵感思维才能促进人工智能的突破性的发展，数学常被认为是多种学科的基础科学，数学也进入语言、思维领域，人工智能学科也必须借用数学工具，数学不仅在标准逻辑、模糊数学等范围发挥作用，数学进入人工智能学科，它们将互相促进而更快地发展。","categories":[{"name":"人工智能","slug":"人工智能","permalink":"http://uscair.club/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"人工智能","slug":"人工智能","permalink":"http://uscair.club/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}],"author":{"name":"不败顽童"}},{"title":"python语言程序设计（一）","slug":"基于python的文件操作","date":"2020-02-28T16:00:00.000Z","updated":"2020-02-28T16:00:00.000Z","comments":true,"path":"2020/02/29/基于python的文件操作/","link":"","permalink":"http://uscair.club/2020/02/29/%E5%9F%BA%E4%BA%8Epython%E7%9A%84%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/","excerpt":"","text":"文件的理解：-文件是数据的抽象和集合-文件是存储在辅助存储器上的数据序列-文件是数据存储的一种形式-文件展现形态：文本文件和二进制文件文本文件和二进制文件区别：-文件文件和二进制文件只是文件的展示方式-本质上，所有文件都是二进制形式存储-形式上，所有文件采用两种方式展示 文本文件-由单一特定编码组成的文件，如UTF-8编码-由于存在编码，也被看成是存储着的长字符串-适用于例如：.txt文件、.py文件等如：`其运行结果： 二进制文件-直接由比特0和1组成，没有统一字符编码-一般存在二进制0和1的组织结构，即文件格式-适用于例如：.png文件、.avi文件等如：其运行结果：不论是二进制文件还是文本文件，文件都是数据的抽象和集合 文件的打开方式：&lt;变量名&gt;=open(&lt;文件名&gt;,&lt;打开模式&gt;)文件名：文件路径和名称打开模式：文本or 二进制，读or 写其中打开模式又分为以下7种：‘r’：只读模式，默认值，如果文件不存在，返回FileNotFoundError。‘w’：覆盖写模式，文件不存在则创建，存在则完全覆盖。‘x’：创建写模式，文件不存在则创建，存在则返回FileExistsError。‘a’：追加写模式，文件不存在则创建，存在则在文件最后追加内容。‘b’：二进制文件模式。‘t’：文本文件模式，默认值。‘+’：与r/w/x/a一同使用，在原功能基础上增加同时读写功能。 文件的关闭：&lt;变量名&gt;.close() 关于文件内容读取的函数：.read(size=-1)：读入全部内容，如果给出参数，读入前size长度.readline(size=-1)：读入一行内容，如果给出参数，读入该行前size长度.readlines(hint=-1)：读入文件所有行，以每行为元素形成列表，如果给出参数，读入前hint行 数据文件的写入操作：.write(s)：向文件写入一个字符串或字节流.writelines(lines)：将一个元素全为字符串的列表写入文件","categories":[{"name":"python","slug":"python","permalink":"http://uscair.club/categories/python/"}],"tags":[{"name":"文件","slug":"文件","permalink":"http://uscair.club/tags/%E6%96%87%E4%BB%B6/"}],"author":{"name":"Page"}},{"title":"Tensorflow 预测燃油效率","slug":"基本回归：预测燃油效率","date":"2020-02-27T16:00:00.000Z","updated":"2020-02-27T16:00:00.000Z","comments":true,"path":"2020/02/28/基本回归：预测燃油效率/","link":"","permalink":"http://uscair.club/2020/02/28/%E5%9F%BA%E6%9C%AC%E5%9B%9E%E5%BD%92%EF%BC%9A%E9%A2%84%E6%B5%8B%E7%87%83%E6%B2%B9%E6%95%88%E7%8E%87/","excerpt":"","text":"Tensorflow 预测燃油效率环境： jupyter notebook tensorflow2.1.0 python3.7.5 1234567import pathlibimport pandas as pdimport seaborn as snsimport tensorflow as tfimport matplotlib.pyplot as pltfrom tensorflow import keras as kerasfrom tensorflow.keras import layers as layers 12dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")print(dataset_path) 1/Users/xxxx/.keras/datasets/auto-mpg.data 123456789column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight', 'Acceleration', 'Model Year', 'Origin']#'每加伦汽油能距的英里数'，'汽缸'，'排量'，'马力'，'重量'，“加速”，“型号年份”，“来源”raw_dataset=pd.read_csv(dataset_path, names=column_names, # 表头 na_values='?', # 把未知名改为？ comment='\\t', sep=' ', # 要使用的定界符 skipinitialspace=True) # 在定界符后跳过空格。 1dataset = raw_dataset.copy() 1dataset.tail() # 返回最后n行，n默认5 MPG Cylinders Displacement Horsepower Weight Acceleration Model Year Origin 393 27.0 4 140.0 86.0 2790.0 15.6 82 1 394 44.0 4 97.0 52.0 2130.0 24.6 82 2 395 32.0 4 135.0 84.0 2295.0 11.6 82 1 396 28.0 4 120.0 79.0 2625.0 18.6 82 1 397 31.0 4 119.0 82.0 2720.0 19.4 82 1 1dataset.isna().sum() # 计算缺失值的个数 123456789MPG 0Cylinders 0Displacement 0Horsepower 6Weight 0Acceleration 0Model Year 0Origin 0dtype: int64 1dataset = dataset.dropna() # 删除缺失值 1origin=dataset.pop('Origin') # 弹出Origin标签，并用origin来获取dataset中的Origin的值 123dataset['USA']=(origin==1)*1.0 # 如果origin为1，则USA的标签下为1.0dataset['Europe']=(origin==2)*1.0 # 如果origin为2，则Europe的标签下为1.0dataset['Japan']=(origin==3)*1.0 # 如果origin为3，则Japan的标签下为1.0 1dataset.tail() MPG Cylinders Displacement Horsepower Weight Acceleration Model Year USA Europe Japan 393 27.0 4 140.0 86.0 2790.0 15.6 82 1.0 0.0 0.0 394 44.0 4 97.0 52.0 2130.0 24.6 82 0.0 1.0 0.0 395 32.0 4 135.0 84.0 2295.0 11.6 82 1.0 0.0 0.0 396 28.0 4 120.0 79.0 2625.0 18.6 82 1.0 0.0 0.0 397 31.0 4 119.0 82.0 2720.0 19.4 82 1.0 0.0 0.0 12train_dataset = dataset.sample(frac=0.8,random_state=0) #以随机数种子0在数据集中抽取80%test_dataset = dataset.drop(train_dataset.index) # 在数据集中删除训练集作为测试集 1sns.pairplot(train_dataset[[\"MPG\", \"Cylinders\", \"Displacement\", \"Weight\"]],diag_kind='kde') 1&lt;seaborn.axisgrid.PairGrid at 0x10cd98110&gt; 12train_stats = train_dataset.describe()train_stats.pop(\"MPG\") # jupyter 交换环境弹出并输出输出MPG 123456789count 314.000000mean 23.310510std 7.728652min 10.00000025% 17.00000050% 22.00000075% 28.950000max 46.600000Name: MPG, dtype: float64 1train_stats = train_stats.transpose() 1train_stats count mean std min 25% 50% 75% max Cylinders 314.0 5.477707 1.699788 3.0 4.00 4.0 8.00 8.0 Displacement 314.0 195.318471 104.331589 68.0 105.50 151.0 265.75 455.0 Horsepower 314.0 104.869427 38.096214 46.0 76.25 94.5 128.00 225.0 Weight 314.0 2990.251592 843.898596 1649.0 2256.50 2822.5 3608.00 5140.0 Acceleration 314.0 15.559236 2.789230 8.0 13.80 15.5 17.20 24.8 Model Year 314.0 75.898089 3.675642 70.0 73.00 76.0 79.00 82.0 USA 314.0 0.624204 0.485101 0.0 0.00 1.0 1.00 1.0 Europe 314.0 0.178344 0.383413 0.0 0.00 0.0 0.00 1.0 Japan 314.0 0.197452 0.398712 0.0 0.00 0.0 0.00 1.0 123train_labels = train_dataset.pop('MPG')test_labels = test_dataset.pop('MPG')# 这个标签是使用训练模型进行预测的值。 12def norm(x): return (x - train_stats['mean']) / train_stats['std'] # 化成0-1正态分布 12normed_train_data = norm(train_dataset) # 归一化normed_test_data = norm(test_dataset) # 归一化 1234model = keras.models.Sequential()model.add(layers.Dense(64,activation='relu',input_shape=[len(train_dataset.keys())]))model.add(layers.Dense(64,activation='relu'))model.add(layers.Dense(1)) 123model.compile(loss='mse', optimizer=tf.keras.optimizers.RMSprop(0.001), metrics=['mae', 'mse']) 1model.summary() 1234567891011121314Model: \"sequential\"_________________________________________________________________Layer (type) Output Shape Param # =================================================================dense (Dense) (None, 64) 640 _________________________________________________________________dense_1 (Dense) (None, 64) 4160 _________________________________________________________________dense_2 (Dense) (None, 1) 65 =================================================================Total params: 4,865Trainable params: 4,865Non-trainable params: 0_________________________________________________________________ 12example_batch = normed_train_data[:10]example_result = model.predict(example_batch) 1print(example_result) [[ 0.06187941] [ 0.16284567] [ 0.19416149] [ 0.3226478 ] [ 0.09883147] [ 0.00343724] [ 0.13330291] [ 0.62984717] [-0.05348695] [ 0.44078857]]123456# 通过为每个完成的时期打印一个点来显示训练进度class PrintDot(keras.callbacks.Callback): def on_epoch_end(self, epoch, logs=None): if (epoch%100==0): print(' ') # 每一百行换行 print('.',end=' ') 123456history=model.fit(normed_train_data, train_labels, epochs=1000, validation_split=0.2, # 把训练集的20%作为验证集 verbose=0, # 不显示进度条 callbacks=[PrintDot()]) # 回调函数为PrintDot 12345678910. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12hist=pd.DataFrame(history.history)hist['epoch']=history.epoch # 增加epoch的标签 1hist.tail() loss mae mse val_loss val_mae val_mse epoch 995 2.448885 0.975710 2.448885 9.030066 2.268713 9.030066 995 996 2.376843 0.999163 2.376843 9.096817 2.273271 9.096817 996 997 2.383884 0.992754 2.383883 9.657296 2.356696 9.657296 997 998 2.504148 1.021134 2.504148 9.152325 2.318949 9.152325 998 999 2.421463 0.947287 2.421463 9.146635 2.284075 9.146635 999 123456789101112131415161718192021222324def plot_history(history): hist = pd.DataFrame(history.history) hist['epoch'] = history.epoch plt.figure() plt.xlabel('Epoch') plt.ylabel('Mean Abs Error [MPG]') plt.plot(hist['epoch'], hist['mae'], # (x,y) label='Train Error') # 线段的名称即标签卡上的名称 plt.plot(hist['epoch'], hist['val_mae'], label = 'Val Error') plt.ylim([0,5]) plt.legend() plt.figure() plt.xlabel('Epoch') plt.ylabel('Mean Square Error [$MPG^2$]') plt.plot(hist['epoch'], hist['mse'], label='Train Error') plt.plot(hist['epoch'], hist['val_mse'], label = 'Val Error') plt.ylim([0,20]) plt.legend() # 打印标签卡 plt.show() 1plot_history(history) # 该图表显示在约100个epoch之后，误差非但没有改进，反而出现恶化。 1train_dataset.keys() 123Index(['Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration', 'Model Year', 'USA', 'Europe', 'Japan'], dtype='object') 1234model = keras.models.Sequential()model.add(layers.Dense(64,activation='relu',input_shape=[len(train_dataset.keys())]))model.add(layers.Dense(64,activation='relu'))model.add(layers.Dense(1)) 123model.compile(loss='mse', optimizer=tf.keras.optimizers.RMSprop(0.001), metrics=['mae', 'mse']) 12345678history=model.fit(normed_train_data, train_labels, epochs=1000, validation_split=0.2, verbose=0, callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=10), # 当绝对变化值小于min_data，则退出，min_data默认为0 PrintDot()]) 1. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1plot_history(history) 1test_predictions = model.predict(normed_test_data).flatten() # 展平 12345678plt.scatter(test_labels,test_predictions)plt.xlabel('True values [MPG]')plt.ylabel(\"Predictions [MPG]\")plt.axis('equal') # 等比例plt.axis('square')plt.xlim([0,plt.xlim()[1]])plt.ylim([0,plt.ylim()[1]])_ = plt.plot([-100,100],[-100,100]) # 画一条经过（-100，-100）与（100，100）的线段 1234error = test_predictions-test_labelsplt.hist(error, bins=25) # 有bins条数plt.xlabel('Prediction Error [MPG]')_ = plt.ylabel(\"Count\")","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://uscair.club/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://uscair.club/tags/TensorFlow/"}],"author":{"name":"Gowi"}},{"title":"OpenCV图像处理初体验","slug":"OpenCV图像处理初体验（python语言）","date":"2020-02-23T11:00:00.000Z","updated":"2020-02-23T11:00:00.000Z","comments":true,"path":"2020/02/23/OpenCV图像处理初体验（python语言）/","link":"","permalink":"http://uscair.club/2020/02/23/OpenCV%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%88%9D%E4%BD%93%E9%AA%8C%EF%BC%88python%E8%AF%AD%E8%A8%80%EF%BC%89/","excerpt":"","text":"一、将图像分为RGB三个通道的图像，转换为灰度图，并画出直方图 1.首先要学会如何读取并展示出一张图片： 123456789# -*- coding: cp936 -*- # 防止中文出错import cv2 #引入OpenCV库img&#x3D;cv2.imread(&#39;D:&#x2F;Camera Roll&#x2F;aling.jpg&#39;,1)# 括号左边填入你所选照片的地址（如果照片和py文件在一个文档里面可以直接输入照片名字），括号右边默认为1彩色图片，当填入0时读取的是灰色图片cv2.namedWindow(&#39;img&#39;) #取一个窗口的名字cv2.imshow(&#39;img&#39;,img) #展示图片cv2.waitKey(0) #使图片停留在屏幕上，不至于很快闪退cv2.destroyAllWindows() #关闭所有窗口 运行结果为： 2.进行RGB三通道输出、灰度图以及直方图 12345678910111213141516171819202122232425262728293031323334353637383940import cv2import numpy as np #用np代替引入的numpyfrom matplotlib import pyplot as pltimg&#x3D;cv2.imread(&#39;D:&#x2F;Camera Roll&#x2F;aling.jpg&#39;）b,g,r&#x3D;cv2.split(img) #进行通道分离pic&#x3D;np.zeros(np.shape(img),np.uint8) #生成零矩阵pic[:,:,0]&#x3D;bcv2.namedWindow(&#39;blue&#39;)cv2.imshow(&#39;blue&#39;,pic)cv2.waitKey(0)pic&#x3D;np.zeros(np.shape(img),np.uint8)pic[:,:,1]&#x3D;gcv2.namedWindow(&#39;green&#39;)cv2.imshow(&#39;green&#39;,pic)cv2.waitKey(0)pic&#x3D;np.zeros(np.shape(img),np.uint8)pic[:,:,2]&#x3D;rcv2.namedWindows(&#39;red&#39;)cv2.imshow(&#39;red&#39;,pic)cv2.waitKey(0)color&#x3D;(&quot;blue&quot;,&quot;green&quot;,&quot;red&quot;)for i,color in enumerate(color): #用于遍历序列中的下标和元素 hist&#x3D;cv2.calcHist([img],[i],None,[256],[0,256]) #建立直方图([图像],[通道],掩膜：一般不需要，设为None,[256],[0,256]) plt.plot(hist,color&#x3D;color) plt.xlim([0,256]) plt.show(）img&#x3D;cv2.imread(&#39;D:&#x2F;Camera Roll&#x2F;aling.jpg&#39;,0) #读取图片为灰度图cv2.namedWindow(&#39;gray&#39;)cv2.imshow(&#39;gray&#39;,img)cv2.waitKey(0)plt.hist(img.ravel(),256,[0,256])plt.show()cv2.destoryAllWindows() 运行结果： 二、运用数学函数对灰色图进行灰度转换 用一个y=-x+255,把黑的变成白的，把白的变成黑的 123456789101112131415161718import cv2import numpy as npimg&#x3D;cv2.imread(&#39;D:&#x2F;Camera Roll&#x2F;wei.jpg&#39;,0)# 获取图片的高度和宽度height&#x3D;img.shape[0]width&#x3D;img.shape[1]# 建立一个零矩阵result&#x3D;np.zeros((height,width),np.uint8)for i in range(height): for j in range(width): gray&#x3D;255-img[i,j] # 运用一个 y&#x3D;-x+255 的数学函数 result[i,j]&#x3D;np.uint8(gray) cv2.imshow(&#39;gray&#39;,img) cv2.imshow(&#39;result&#39;,result) cv2.waitKey(0) cv2.destoryAllWindows() 运行结果：三、createTrackbar函数的简单使用 1234567891011121314151617import cv2def callback(x): #回调函数 pass cv2.namedWindow(&#39;image&#39;) img&#x3D;cv2.imread(&#39;D:&#x2F;Camera Roll&#x2F;wifi.jpg&#39;) # 建立一个滑块 cv2.createTrackbar(&#39;num&#39;,&#39;image&#39;,0,255,callback)while(1): num&#x3D;cv2.getTrackbarPos(&quot;num&quot;,&quot;image&quot;) #获取当前滑块的位置 ret,img1&#x3D;cv2.threshold(img,num,255,cv2.THRESH_BINARY) cv2.imshow(&#39;image&#39;,img2) k&#x3D;cv2.waitKey(1） &amp; 0xFF if k&#x3D;&#x3D;27: breakcv2.destoryAllWindows()# 该程序按Esc结束 运行结果：不同的num值，图像颜色对比不一样。 本人是第一次接触图像处理，很多东西还不是很懂，以后会多多学习的，如有错误请看到的小伙伴多多提醒。有冒犯之处，请多原谅。","categories":[{"name":"数字图像处理","slug":"数字图像处理","permalink":"http://uscair.club/categories/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://uscair.club/tags/OpenCV/"},{"name":"图片变化","slug":"图片变化","permalink":"http://uscair.club/tags/%E5%9B%BE%E7%89%87%E5%8F%98%E5%8C%96/"}],"author":{"name":"风车车"}},{"title":"NAO机器人的魔鬼步伐","slug":"“NAO机器人”的魔鬼步伐","date":"2020-02-23T10:44:03.033Z","updated":"2020-02-23T10:44:03.033Z","comments":true,"path":"2020/02/23/“NAO机器人”的魔鬼步伐/","link":"","permalink":"http://uscair.club/2020/02/23/%E2%80%9CNAO%E6%9C%BA%E5%99%A8%E4%BA%BA%E2%80%9D%E7%9A%84%E9%AD%94%E9%AC%BC%E6%AD%A5%E4%BC%90/","excerpt":"","text":"初步通过python语言实现“NAO“机器人speak和move 编译环境 点我哦！你也可以使NAO迈出魔鬼的步伐傻乎乎的小小机器人** 参考代码1（实现电脑与机器人的连接） **参考代码2（使机器人稳步行走的配置，可根据不同环境不同类型做相应调整） ** 参考代码3（行走及说话的实现） **","categories":[{"name":"NAO","slug":"NAO","permalink":"http://uscair.club/categories/NAO/"}],"tags":[{"name":"NAOqi","slug":"NAOqi","permalink":"http://uscair.club/tags/NAOqi/"}],"author":{"name":"XuWenjun"}},{"title":"机器学习系列（四）——规则化（Regularize）","slug":"机器学习系列（四）——规则化（Regularize）","date":"2020-02-23T03:13:00.044Z","updated":"2020-02-23T03:13:00.044Z","comments":true,"path":"2020/02/23/机器学习系列（四）——规则化（Regularize）/","link":"","permalink":"http://uscair.club/2020/02/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%88%E5%9B%9B%EF%BC%89%E2%80%94%E2%80%94%E8%A7%84%E5%88%99%E5%8C%96%EF%BC%88Regularize%EF%BC%89/","excerpt":"","text":"机器学习系列（四）——规则化（Regularize）机器学习中，我们一直期望学习到一个泛化能力（generalization）强的函数，只有泛化能力强的模型才能很好地适用于整个样本空间，才能在新的样本点上表现良好。但是训练集通常只是整个样本空间很小的一部分，在训练机器学习模型时，稍有不注意，就可能将训练集中样本的特性当作了全体样本的共性，以偏概全，而造成过拟合（overfitting）问题，如何避免过拟合，是训练机器学习模型时最亟待解决的绊脚石。从问题的根源出发，解决过拟合无非两种途径： ​ 1.使训练集能够尽可能全面的描述整个样本空间。因此又存在两个解决方向。①减少特征维数，特征维数减少了，样本空间的大小也随之减少了，现有数据集对样本空间的描述也就提高了。②增加训练样本数量，试图直接提升对样本空间的描述能力。​ 2.加入规则化项。第一种方法的人力成本通常很大，所以在实际中，我们通常采用第二种方法提升模型的泛化能力。注：规则化在有些文档中也称作正则化，在本文中都采用规则化描述。 规则化（Regularize）首先回顾一下，在寻找模型最优参数时，我们通常对损失函数采用梯度下降（gradient descent）算法 通过上述公式，我们将一步步走到损失函数的最低点（不考虑局部最小值和鞍点情况），这时的w和b就是我们要找的最优参数。对于回归问题，我们还可以直接采用最小二乘法求得解析解。 可以看到，当前我们的损失函数只考虑最小化训练误差，希望找到的最优函数能够尽可能的拟合训练数据。但是正如我们所了解的，训练集不能代表整个样本空间，所以训练误差也不能代表在测试误差，训练误差只是经验风险，我们不能过分依赖这个值。当我们的函数对训练集拟合特别好，训练误差特别小时，我们也就走进了一个极端——过拟合。为了解决这个问题，研究人员提出了规则化（regularize）方法。通过给模型参数附加一些规则，也就是约束，防止模型过分拟合训练数据。规则化通过在原有损失函数的基础上加入规则化项实现。此时，最优化的目标函数如下： 其中，第一项对应于模型在训练集上的误差，第二项对应于规则化项。为了使得该目标函数最小，我们既需要训练误差最小，也需要规则化项最小，因此需要在二者之间做到权衡。那应该选择怎样的表达式作为规则化项呢？以下引用李航博士《统计学习方法》中的一些描述： 规则化是结构风险最小化策略的实现，是在经验风险最小化上加一个规则化项（regularizer）或罚项（penalty term）。规则化项一般是模型复杂度的单调递增函数，模型越复杂，规则化值就越大。比如，规则化项可以是模型参数向量的范数。 规则化符合奥卡姆剃刀（Occam’s razor）原理。奥卡姆剃刀原理应用于模型选择时变为以下想法：在所有可能选择的模型中，能够很好地解释已知数据并且十分简单才是最好的模型，也就是应该选择的模型。从贝叶斯估计的角度来看，规则化项对应于模型的先验概率。可以假设复杂的模型有较大的先验概率，简单的模型有较小的先验概率。 所以通常我们采用L1-范数和L2-范数作为规则化项。 L1-范数向量的L1-范数是向量的元素绝对值之和，即 当采用L1-范数作为规则化项对参数进行约束时，我们的优化问题可以写成以下形式： 采用拉格朗日乘子法可以将约束条件合并到最优化函数中，即 其中λ是于C一一对应的常数，用来权衡误差项和规则化项，λλ越大，约束越强。二维情况下分别将损失函数的等高线图和L1-范数规则化约束画在同一个坐标轴下， L1-范数约束对应于平面上一个正方形norm ball。等高线与norm ball首次相交的地方就是最优解。可以看到，L1-ball在和每个坐标轴相交的地方都有“角”出现，大部分时候等高线都会与norm ball在角的地方相交。这样部分参数值被置为0，相当于该参数对应的特征将不再发挥作用，实现了特征选择，增加了模型的可解释性。关于L1-范数规则化，可以解释如下：训练出来的参数代表权重，反应了特征的重要程度，比如y=20x1+5x2+3y=20x1+5x2+3中，特征x1x1明显比x2x2更加重要，因为x1的变动相较于x2的变动，会给y带来更大的变化。在人工选取的特征中，往往会存在一些冗余特征或者无用特征，L1-范数规则化将这些特征的权重置为0，实现了特征选择，同时也简化了模型。L1-范数在x=0处存在拐点，所以不能直接求得解析解，需要用次梯度方法处理不可导的凸函数。 L2-范数除了L1-范数，还有一种广泛使用的规则化范数：L2-范数。向量的L2-范数是向量的模长，即 当采用L2-范数作为规则化项对参数进行约束时，我们的优化问题可以写成以下形式： 同样可以将约束条件合并到最优化函数中，得到如下函数 也将损失函数的等高线图和L2-范数规则化约束画在同一个坐标轴下， L2-范数约束对应于平面上一个圆形norm ball。等高线与norm ball首次相交的地方就是最优解。与L1-范数不同，L2-范数使得每一个w都很小，都接近于0，但不会等于0，L2-范数规则化仍然试图使用每一维特征。对于L2-范数规则化可以解释如下：L2-范数规则化项将参数限制在一个较小的范围，参数越小，曲面越光滑，因而不会出现在很小区间内，弯曲度很大的情况，当xx一个较大的变化时，yy也只会变化一点点，模型因此更加稳定，也就是更加generalization。加入L2-范数规则化项后，目标函数扩展为如下形式： 同样，如果采用最小二乘法，正规方程的形式需要相应修改，并且对于样本数目少于特征维数的情况时，矩阵(XT X)将不满秩，(XT X)也就不可逆，确切地说，此时方程组是不定方程组，将会有无穷多解，已有的数据不足以确定一个解，数学上常加入约束项以使得唯一解成为可能，加入L2-范数规则化项正好对应了这种方法，此时解析解如下：","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://uscair.club/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://uscair.club/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"author":{"name":"Wonder"}},{"title":"人工智能--初级架构(1)","slug":"人工智能简介","date":"2020-02-22T16:00:00.000Z","updated":"2020-02-22T16:00:00.000Z","comments":true,"path":"2020/02/23/人工智能简介/","link":"","permalink":"http://uscair.club/2020/02/23/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AE%80%E4%BB%8B/","excerpt":"","text":"人工智能简介人工智能（Artificial Intelligence，缩写为AI）亦称智械、机器智能，指由人制造出来的机器所表现出来的智能。通常人工智能是指通过普通计算机程序来呈现人类智能的技术。该词也指出研究这样的智能系统是否能够实现，以及如何实现。人工智能于一般教材中的定义领域是“智能主体（intelligent agent）的研究与设计”，智能主体指一个可以观察周遭环境并作出行动以达致目标的系统。约翰·麦卡锡于1955年的定义是“制造智能机器的科学与工程”。安德里亚斯·卡普兰（Andreas Kaplan）和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及范围极广。 AI的核心问题包括建构能够跟人类似甚至超卓的推理、知识、规划、学习、交流、感知、移物、使用工具和操控机械的能力等。当前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基于仿生学、认知心理学，以及基于概率论和经济学的算法等等也在逐步探索当中。 思维来源于大脑，而思维控制行为，行为需要意志去实现，而思维又是对所有数据采集的整理，相当于数据库，所以人工智能最后会演变为机器替换人类。 人工智能的定义可以分为两部分，即“人工”和“智能”。“人工”比较好理解，争议性也不大。有时我们会要考虑什么是人力所能及制造的，或者人自身的智能程度有没有高到可以创造人工智能的地步，等等。但总的来说，“人工系统”就是通常意义下的人工系统。 人工智能是研究使计算机来模拟人的某些思维过程和智能行为（如学习、推理、思考、规划等）的学科，主要包括计算机实现智能的原理、制造类似于人脑智能的计算机，使计算机能实现更高层次的应用。人工智能将涉及到计算机科学、心理学、哲学和语言学等学科。可以说几乎是自然科学和社会科学的所有学科，其范围已远远超出了计算机科学的范畴，人工智能与思维科学的关系是实践和理论的关系，人工智能是处于思维科学的技术应用层次，是它的一个应用分支。从思维观点看，人工智能不仅限于逻辑思维，要考虑形象思维、灵感思维才能促进人工智能的突破性的发展，数学常被认为是多种学科的基础科学，数学也进入语言、思维领域，人工智能学科也必须借用数学工具，数学不仅在标准逻辑、模糊数学等范围发挥作用，数学进入人工智能学科，它们将互相促进而更快地发展。 强人工智能(BOTTOM-UP AI) 强人工智能观点认为有可能制造出真正能推理（REASONING）和解决问题（PROBLEM_SOLVING）的智能机器，并且，这样的机器能将被认为是有知觉的，有自我意识的。强人工智能可以有两类： 类人的人工智能，即机器的思考和推理就像人的思维一样。 非类人的人工智能，即机器产生了和人完全不一样的知觉和意识，使用和人完全不一样的推理方式。 弱人工智能(TOP-DOWN AI) 弱人工智能观点认为不可能制造出能真正地推理（REASONING）和解决问题（PROBLEM_SOLVING）的智能机器，这些机器只不过看起来像是智能的，但是并不真正拥有智能，也不会有自主意识。 主流科研集中在弱人工智能上，并且一般认为这一研究领域已经取得可观的成就。强人工智能的研究则处于停滞不前的状态下。 人工智能的实际应用： 机器视觉，指纹识别，人脸识别，视网膜识别，虹膜识别，掌纹识别，专家系统，自动规划，智能搜索，定理证明，博弈，自动程序设计，智能控制，机器人学，语言和图像理解，遗传编程。 人工智能架构一.机器人三大定律： (1)机器人不得伤害人类个体，或者目睹人类个体遭受危险而袖手不管。 (2)机器人必须服从人给予他的命令，当该命令与第一定律冲突时例外。 (3)机器人在不违法第一，第二定律情况下腰尽可能保护自己生存。 机器人第零定律：机器人必须保护人类的整体利益不受伤害，其他定律都是在这一前提才能成立。 二.机器人： 机器人是自动控制机器 ， 自动控制机器包括一切模拟人类行为或思想与模拟其他生物的机械（如机器狗，机器猫等）。狭义上对机器人的定义还有很多分类法及争议，有些电脑程序甚至也被称为机器人。在当代工业中，机器人指能自动执行任务的人造机器装置，用以取代或协助人类工作。 机器人一般由执行机构，驱动装置，检测装置和控制系统和复杂机械组成。 机器人本体执行机构，臀部采用空间开链连杆机构，运动副称为关节，关节个数称为机器人的自由度数，根据关节配置型式和运动坐标不同，机器人执行机构可分为直角坐标式，圆柱做标式，极坐标式，关节坐标式。 机器人的控制系统：一种是集中式控制，机器人全部控制由一台微型计算机完成，另一种是分散式控制。多台微型来分担控制。如当采用上、下两级微机共同完成机器人的控制时，主机常用于负责系统的管理、通讯、运动学和动力学计算，并向下级微机发送指令信息；作为下级从机，各关节分别对应一个CPU，进行插补运算和伺服控制处理，实现给定的运动，并向主机反馈信息。根据作业任务要求的不同，机器人的控制方式又可分为点位控制、连续轨迹控制和力（力矩）控制。 三.图灵测试： 电脑能在5分钟内回答由人类测试者提出的一系列问题，且其超过30%的回答让测试者误认为是人类所答 。 即一个人在不接触对方的情况下，通过一种特殊的方式，和对方进行一系列的问答，如果在相当长时间内，他无法根据这些问题判断对方是人还是计算机，那么，就可以认为这个计算机具有同人相当的智力，即这台计算机是能思维的 。","categories":[{"name":"人工智能","slug":"人工智能","permalink":"http://uscair.club/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"小白学习","slug":"小白学习","permalink":"http://uscair.club/tags/%E5%B0%8F%E7%99%BD%E5%AD%A6%E4%B9%A0/"}],"author":{"name":"HL"}},{"title":"卷积神经网络（3）","slug":"卷积神经网络（3）","date":"2020-02-22T16:00:00.000Z","updated":"2020-02-22T16:00:00.000Z","comments":true,"path":"2020/02/23/卷积神经网络（3）/","link":"","permalink":"http://uscair.club/2020/02/23/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%883%EF%BC%89/","excerpt":"","text":"padding当进行卷积操作时，例如一个3x3的过滤器卷积一个6x6的图像，不断地卷积过后，图像就会变得越来越小。并且边缘的像素卷积比中间的采用少，会造成边缘的信息丢失或者更准确来说角落或图像边缘的信息发挥的作用较小。因此需要运用padding进行填充。 如上图：这个像素点（绿色阴影标记）只被一个过滤器输出所触碰或者使用，因为它位于这个3×3的区域的一角。但如果是在中间的像素点，比如这个（红色方框标记），就会有许多3×3的区域与之重叠。所以那些在角落或者边缘区域的像素点在输出中采用较少，意味着你丢掉了图像边缘位置的许多信息。 因此，如果我们在卷积操作之前填充这幅图像。在图像边缘再填充一层像素，这个6x6的矩阵就会变为8x8，再进行3x3的卷积，得出后的图像就依然是6x6。 同时，padding还有两种形式，分别是SAME和Valid. SAME用SAME填充过后，输入大小如6x6则输出结果仍为6x6。| 1 |2 | 3 |0||–|–|–|–|| 5 | 6 |7|0|如上表，如步长为2，向右滑动两格。会发现剩下的不满足2x2，SAME方法便会填充增加第4列，通常为0。 ValidValid卷积意味着不填充，这样的话，如果你有一个nn的图像，用一个ff的过滤器卷积，它将会给你一个(n-f+1)*(n-f+1)维的输出。这类似于我们在前面的视频中展示的例子，有一个6×6的图像，通过一个3×3的过滤器，得到一个4×4的输出。 LeNet-5LeNet-5是一种用于手写体字符识别的非常高效的卷积神经网络。出自论文Gradient-Based Learning Applied to Document Recognition。LeNet-5共有7层，不包含输入，每层都包含可训练参数；每个层有多个Feature Map，每个FeatureMap通过一种卷积滤波器提取输入的一种特征。 input层，输入一个32x32的图像。在卷积时没有使用padding（文章中有提到32x32的输入实际上比常用的28x28的输入要大，可以认为是在输入的时候就已经padding过了）。 C1,C3,C5三层均为卷积层，卷积核均为5x5. S2,S4均为池化层，采样区域均为2x2. F6为全连接层，计算方式：计算输入向量和权重向量之间的点积，再加上一个偏置，结果通过sigmoid函数输出。 Output层也为全连接层，共有10个节点，分别代表数字0到9，且如果节点i的值为0，则网络识别的结果是数字i。采用的是径向基函数（RBF）的网络连接方式。假设x是上一层的输入，y是RBF的输出，则RBF输出的计算方式是：上式的值由i的比特图编码确定，i从0到9，j取值从0到7*12-1。RBF输出的值越接近于0，则越接近于i，即越接近于i的ASCII编码图，表示当前网络输入的识别结果是字符i。该层有84x10=840个参数和连接。 0 1 2 3 4 5 6 0 7 8 9","categories":[{"name":"数字图像处理","slug":"数字图像处理","permalink":"http://uscair.club/categories/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}],"tags":[{"name":"CNN","slug":"CNN","permalink":"http://uscair.club/tags/CNN/"}],"author":"name:ffffff"},{"title":"STM32单片机系列（三）","slug":"STM32 IO中断（F407）","date":"2020-02-21T16:00:00.000Z","updated":"2020-02-21T16:00:00.000Z","comments":true,"path":"2020/02/22/STM32 IO中断（F407）/","link":"","permalink":"http://uscair.club/2020/02/22/STM32%20IO%E4%B8%AD%E6%96%AD%EF%BC%88F407%EF%BC%89/","excerpt":"","text":"STM32 IO口中断中断STM32 F4 的每个 IO 都可以作为外部中断的中断输入口，这点也是 STM32 F4 的强大之处。 STM32 F407 的中断控制器支持 22 个外部中断事件请求。每个中断设有状态位，每个中断事件都有独立的触发和屏蔽设置。 STM32 F407的 22 个外部中断为：EXTI线 0~15 ：对应外部 IO 口的输入中断。EXTI线 16 ：连接到 PVD 输出。EXTI线 17 ：连接到 RTC 闹钟事件。EXTI线 18 ：连接到 USB OTG FS 唤醒事件。EXTI线 19 ：连接到以太网唤醒事件。EXTI线 20 ：连接到 USB OTG HS( 在 FS 中配置 唤醒事件。EXTI线 21 ：连接到 RTC 入侵和时间戳事件。EXTI线 22 ：连接到 RTC 唤醒事件。下面来重点介绍IO口的一些中断：如图所示：其中每一个中断线可以映射多个IO口，但是同组IO口里面一次只能有一个IO口占用中断线。如（PA0-PG0）是一组可以映射到中断线EXTI0但是一次只能有其中的一个IO口映射上去。 每一个中断线可以设置它的触发方式（上升沿触发，下降沿触发，边沿触发，上升沿和下降沿都可以触发）和使能位状态位。 IO在外部中断向量里面只分配了7个中断服务函数0，1，2，3，4，5-9，10-15中断的基本配置方法： 1. 首先使能对应的时钟线： RCC_APB2PeriphClockCmd(RCC_APB2Periph_SYSCFG, ENABLE); IO中断是挂载在APB2时钟线上的，通过设置ENABLE使能IO口时钟 2. 初始化中断： 第一个成员EXTI_Line 配置中断线，第二个成员EXTI_Mode 分为了事件触发和中断触发俩种： EXTI_Mode_Event EXTI_Mode_Interrupt第三个成员EXTI_Trigger 设置中断触发方式： EXTI_Trigger_Rising 上升沿触发 EXTI_Trigger_Falling 下降沿触发 EXTI_Trigger_Rising_Falling 上升下降沿同时触发第四个成员EXTI_LineCmd 使能对应的中断线： ENABLE 使能 DISABLE 失能 3. 接下来配置中断向量： 第一个成员NVIC_IRQChannel 配置对应的中断通道：可在IRQn_Type中查询对应的中断方式，由于数目太多在这里不一一列举第二个成员NVIC_IRQChannelPreemptionPriority 配置该中断的抢占优先级：抢占优先级分为四种用俩位二进制数表示 00 01 10 11 其中00最大第三个成员NVIC_IRQChannelSubPriority 配置该中断的响应优先级：同抢占优先级一样分为4种数字越大优先级数越低第四个成员NVIC_IRQChannelCmd 使能对应中断向量组： ENABLE 使能 DISABLE 失能 配置完以上就可以自由配置函数EXIT_IRQHandler（）对应的中断服务函数（发生中断就跳转至函数里面）来达到自己想要的目的。 最后介绍几个关于中断的函数：EXIT_GetITStatus()判断中断线上的中断是否发生。EXIT_ClearITPendingBit（）清楚对应线上的中断标志位。RCC_APB2PeriphClockCmd（）使能对应中断的时钟。","categories":[{"name":"单片机","slug":"单片机","permalink":"http://uscair.club/categories/%E5%8D%95%E7%89%87%E6%9C%BA/"}],"tags":[{"name":"STM32F407","slug":"STM32F407","permalink":"http://uscair.club/tags/STM32F407/"}],"author":{"name":"Page"}},{"title":"利用深度神经网络进行基本图像分类","slug":"利用深度神经网络进行基本图像分类","date":"2020-02-21T16:00:00.000Z","updated":"2020-02-21T16:00:00.000Z","comments":true,"path":"2020/02/22/利用深度神经网络进行基本图像分类/","link":"","permalink":"http://uscair.club/2020/02/22/%E5%88%A9%E7%94%A8%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%BF%9B%E8%A1%8C%E5%9F%BA%E6%9C%AC%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/","excerpt":"","text":"利用深度神经网络进行基本图像分类此代码在colab已经经过测试并且可以查看TensorBoard：地址 环境：Tensorflow-2.1.0、Python3.6、google colab In[1]: 123import sslssl._create_default_https_context = ssl._create_unverified_context# 不知道为什么在本地的jupyter notebook上无法导入fashion_mnist数据集(本地需要，google colab不需要) In[2]: 1234567891011121314151617import matplotlib as mplimport matplotlib.pyplot as plt%matplotlib inlineimport numpy as npimport sklearn import pandas as pdimport osimport sysimport timeimport tensorflow as tffrom tensorflow import keras as kerasfrom sklearn.preprocessing import StandardScalerfor module in mpl,np,pd,sklearn,tf,keras: print(module.__name__,module.__version__)# 打印版本库 Out[1]: matplotlib 3.1.2 numpy 1.18.1 pandas 0.25.3 sklearn 0.22.1 tensorflow 2.1.0 tensorflow_core.keras 2.2.4-tfIn[3]: 123fashion_mnist=keras.datasets.fashion_mnist(x_train_all, y_train_all),(x_test, y_test)=fashion_mnist.load_data()# 导入fashion_mnist数据集 In[4] 1234567x_valid,x_train=x_train_all[:5000],x_train_all[5000:]y_valid,y_train=y_train_all[:5000],y_train_all[5000:]# fashion_mnist有6w个数据，前5k个为验证集，其中x为图片，y为序列号print(x_valid.shape,y_valid.shape)print(x_train.shape,y_valid.shape)print(x_test.shape,y_test.shape)# 打印数据集的格式 Out[2] (5000, 28, 28) (5000,) (55000, 28, 28) (5000,) (10000, 28, 28) (10000,)In[5]: 12print(np.max(x_train),np.min(x_train))# 打印数据集中的最大值和最小值 Out[3]: 255 0In[6]: 123456789# x= (x-u)/stdscaler=StandardScaler()# x_train:[None, 28, 28] -&gt; [None, 784]x_train_scaled=scaler.fit_transform(x_train.astype(np.float32).reshape(-1,1)).reshape(-1,28,28) #会自动记录方差u和均值std，并进行归一化x_valid_scaled=scaler.transform(x_valid.astype(np.float32).reshape(-1,1)).reshape(-1,28,28) # 会根据自动记录的方差u和均值std进行归一化x_test_scaled=scaler.transform(x_test.astype(np.float32).reshape(-1,1)).reshape(-1,28,28) # 会根据自动记录的方差u和均值std进行归一化 Out[4]: 2.0231433 -0.8105136In[7]: 123456def show_single_image(img_arr): plt.imshow(img_arr,cmap='binary') plt.show()# 打印单张图片 show_single_image(x_train[0]) Out[5]: In[8]: 1234567891011121314151617181920def show_images(n_rows,n_cols,x_data,y_data,class_names): assert len(x_data)==len(y_data) assert n_cols*n_rows&lt;len(x_data) plt.figure(figsize=(n_cols*1.4,n_rows*1.6)) for row in range(n_rows): for col in range(n_cols): index=n_cols*row+col plt.subplot(n_rows,n_cols,index+1) plt.imshow(x_data[index],cmap='binary', interpolation='nearest') plt.axis('off') plt.title(class_names[y_data[index]]) plt.show()# 打印n_rows行n_cols列的图片 class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']# 所对应的名称show_images(3,5,x_train,y_train,class_names) Out[6]: In[9]: 1234567891011121314151617181920212223242526272829303132333435363738394041# 构建一个三层的神经网络# model=keras.models.Sequential()# model.add(keras.layers.Flatten(input_shape=[28,28])) # 展开成28*28的向量# model.add(keras.layers.Dense(300,activation='relu')) # 全链接层，层数300，激活函数relu# model.add(keras.layers.Dense(100,activation='relu')) # model.add(keras.layers.Dense(10,activation='softmax')) # 有10个输出# model=keras.models.Sequential([# keras.layers.Flatten(input_shape=[28,28]),# keras.layers.Dense(300,activation='relu'),# keras.layers.Dense(100,activation='relu'),# keras.layers.Dense(10,activation='softmax')# ])model=keras.models.Sequential()model.add(keras.layers.Flatten(input_shape=[28,28]))for _ in range(20): model.add(keras.layers.Dense(100,activation='selu')) # model.add(keras.layers.Dense(100,activation='relu')) # model.add(keras.layers.BatchNormalization()) # 激活函数在前的后的批归一化 # model.add(keras.layers.Dense(100)) # model.add(keras.layers.BatchNormalization()) # model.add(keras.layers.Activation('relu')) # model.add(keras.layers.Dropout(rate=0.5))model.add(keras.layers.AlphaDropout(rate=0.5))# AlphaDropout与Dropout的区别：1、均值方差不变 2、归一化性质不变model.add(keras.layers.Dense(10,activation='softmax'))# relu: y=max(0,x)# softmax: 将向量变成概率分布 x=[x1,x2,x3]# y=[e^x1/sum,e^x2/sum,e^x3/sum],sum=e^x1+e^x2+e^x3# reason for sparse: y-&gt;index y-&gt;one_hot-&gt;[]model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy']) tensorflow.keras.model.compile In[10]: 1model.layers Out[7]: [&lt;tensorflow.python.keras.layers.core.Flatten at 0x136ef6a90&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x136ef6ad0&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x136eb5f90&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x13689dcd0&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x136ed6990&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x136894090&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x13689b450&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x13689b110&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x111477050&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x13a68c7d0&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x1114bd810&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x13a7035d0&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x13a6a9050&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x13a6a9bd0&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x107df4650&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x107e2b410&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x13a724910&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x13a6dd210&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x13e4b1b90&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x137080b10&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x13e4a1a10&gt;, &lt;tensorflow.python.keras.layers.noise.AlphaDropout at 0x136ed69d0&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x1370af710&gt;]In[11]: 1model.summary() #打印模型的结构 Out[8]: Model: &quot;sequential&quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= flatten (Flatten) (None, 784) 0 _________________________________________________________________ dense (Dense) (None, 100) 78500 _________________________________________________________________ dense_1 (Dense) (None, 100) 10100 _________________________________________________________________ dense_2 (Dense) (None, 100) 10100 _________________________________________________________________ dense_3 (Dense) (None, 100) 10100 _________________________________________________________________ dense_4 (Dense) (None, 100) 10100 _________________________________________________________________ dense_5 (Dense) (None, 100) 10100 _________________________________________________________________ dense_6 (Dense) (None, 100) 10100 _________________________________________________________________ dense_7 (Dense) (None, 100) 10100 _________________________________________________________________ dense_8 (Dense) (None, 100) 10100 _________________________________________________________________ dense_9 (Dense) (None, 100) 10100 _________________________________________________________________ dense_10 (Dense) (None, 100) 10100 _________________________________________________________________ dense_11 (Dense) (None, 100) 10100 _________________________________________________________________ dense_12 (Dense) (None, 100) 10100 _________________________________________________________________ dense_13 (Dense) (None, 100) 10100 _________________________________________________________________ dense_14 (Dense) (None, 100) 10100 _________________________________________________________________ dense_15 (Dense) (None, 100) 10100 _________________________________________________________________ dense_16 (Dense) (None, 100) 10100 _________________________________________________________________ dense_17 (Dense) (None, 100) 10100 _________________________________________________________________ dense_18 (Dense) (None, 100) 10100 _________________________________________________________________ dense_19 (Dense) (None, 100) 10100 _________________________________________________________________ alpha_dropout (AlphaDropout) (None, 100) 0 _________________________________________________________________ dense_20 (Dense) (None, 10) 1010 ================================================================= Total params: 271,410 Trainable params: 271,410 Non-trainable params: 0 _________________________________________________________________In[12]: 1# 第一层 [None, 784] * w + b -&gt; [None, 300] w.shape=[784,300], b=[300] In[13]: 123456789101112131415# TensorBoard,EarlyStopping,ModelCheckPointlogdir='./dnn-selu-dropout-callbacks' # 设置一个文件夹路径if not os.path.exists(logdir): # 若文件夹不存在，则创建文件夹 os.mkdir(logdir)output_model_file=os.path.join(logdir, 'fashion_mnist_model.h5') #放入文件夹内，文件名fashion_mnist_model.h5callbacks=[ keras.callbacks.TensorBoard(logdir), keras.callbacks.ModelCheckpoint(output_model_file, save_best_only=True), # 保存最好的模型，如果不是这个会默认保存最近的一个模型 keras.callbacks.EarlyStopping(patience=5,min_delta=1e-3)]history=model.fit(x_train_scaled,y_train,epochs=10, validation_data=(x_valid_scaled,y_valid), callbacks=callbacks) tensorflow.keras.model.fit Out[9]: Train on 55000 samples, validate on 5000 samples Epoch 1/10 55000/55000 [==============================] - 11s 195us/sample - loss: 0.6998 - accuracy: 0.7617 - val_loss: 0.5656 - val_accuracy: 0.8536 Epoch 2/10 55000/55000 [==============================] - 8s 144us/sample - loss: 0.4626 - accuracy: 0.8428 - val_loss: 0.6195 - val_accuracy: 0.8558 Epoch 3/10 55000/55000 [==============================] - 9s 162us/sample - loss: 0.4065 - accuracy: 0.8581 - val_loss: 0.5300 - val_accuracy: 0.8668 Epoch 4/10 55000/55000 [==============================] - 8s 142us/sample - loss: 0.3755 - accuracy: 0.8717 - val_loss: 0.6154 - val_accuracy: 0.8664 Epoch 5/10 55000/55000 [==============================] - 8s 152us/sample - loss: 0.3521 - accuracy: 0.8774 - val_loss: 0.5287 - val_accuracy: 0.8766 Epoch 6/10 55000/55000 [==============================] - 8s 153us/sample - loss: 0.3343 - accuracy: 0.8815 - val_loss: 0.4956 - val_accuracy: 0.8856 Epoch 7/10 55000/55000 [==============================] - 8s 143us/sample - loss: 0.3193 - accuracy: 0.8857 - val_loss: 0.5349 - val_accuracy: 0.8716 Epoch 8/10 55000/55000 [==============================] - 8s 144us/sample - loss: 0.3085 - accuracy: 0.8916 - val_loss: 0.5294 - val_accuracy: 0.8842 Epoch 9/10 55000/55000 [==============================] - 8s 145us/sample - loss: 0.2955 - accuracy: 0.8946 - val_loss: 0.4668 - val_accuracy: 0.8822 Epoch 10/10 55000/55000 [==============================] - 8s 152us/sample - loss: 0.2839 - accuracy: 0.8975 - val_loss: 0.4907 - val_accuracy: 0.8860In[14]: 1type(history) Out[10]: tensorflow.python.keras.callbacks.HistoryIn[15]: 12history.history# 打印每次学习的结果 Out[11]: {&apos;loss&apos;: [0.6997782779043371, 0.4625766654621471, 0.4064591264659708, 0.37553091496554286, 0.35207060631621967, 0.3343261710730466, 0.3193407494176518, 0.30854321794509887, 0.29552189791636035, 0.28390346760099583], &apos;accuracy&apos;: [0.76165456, 0.84276366, 0.85809094, 0.8717273, 0.87743634, 0.8814909, 0.8856909, 0.89156365, 0.89461815, 0.8974909], &apos;val_loss&apos;: [0.5656432386219501, 0.6194551657661795, 0.5299783393919468, 0.6153697894215584, 0.5287225459891837, 0.49561948866695166, 0.5348633618405322, 0.5294362505242228, 0.4668049536377192, 0.4907300000913441], &apos;val_accuracy&apos;: [0.8536, 0.8558, 0.8668, 0.8664, 0.8766, 0.8856, 0.8716, 0.8842, 0.8822, 0.886]}In[16] 12345678def plot_learning_curves(history): pd.DataFrame(history.history).plot(figsize=(8,5)) plt.grid(True) plt.gca().set_ylim(0,1) plt.show()# 打印学习曲线plot_learning_curves(history) Out[12]: In[17]: 1model.evaluate(x_test_scaled,y_test) # 在测试集上验证 tensorflow.keras.model.evaluate Out[13]: 10000/10000 [==============================] - 1s 95us/sample - loss: 0.5799 - accuracy: 0.8741Out[14]: [0.5799049034297467, 0.8741]汇总： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226#!/usr/bin/env python# coding: utf-8# In[1]:import sslssl._create_default_https_context = ssl._create_unverified_context# 不知道为什么在本地的jupyter notebook上无法导入fashion_mnist数据集(本地需要，google colab不需要)# In[23]:import matplotlib as mplimport matplotlib.pyplot as pltget_ipython().run_line_magic('matplotlib', 'inline')import numpy as npimport sklearn import pandas as pdimport osimport sysimport timeimport tensorflow as tffrom tensorflow import keras as kerasfrom sklearn.preprocessing import StandardScalerfor module in mpl,np,pd,sklearn,tf,keras: print(module.__name__,module.__version__)# 打印版本库# In[3]:fashion_mnist=keras.datasets.fashion_mnist(x_train_all, y_train_all),(x_test, y_test)=fashion_mnist.load_data()# 导入fashion_mnist数据集# In[4]:x_valid,x_train=x_train_all[:5000],x_train_all[5000:]y_valid,y_train=y_train_all[:5000],y_train_all[5000:]# fashion_mnist有6w个数据，前5k个为验证集，其中x为图片，y为序列号print(x_valid.shape,y_valid.shape)print(x_train.shape,y_valid.shape)print(x_test.shape,y_test.shape)# 打印数据集的格式# In[5]:print(np.max(x_train),np.min(x_train))# 打印数据集中的最大值和最小值# In[6]:# x= (x-u)/stdscaler=StandardScaler()# x_train:[None, 28, 28] -&gt; [None, 784]x_train_scaled=scaler.fit_transform(x_train.astype(np.float32).reshape(-1,1)).reshape(-1,28,28) #会自动记录方差u和均值std，并进行归一化x_valid_scaled=scaler.transform(x_valid.astype(np.float32).reshape(-1,1)).reshape(-1,28,28) # 会根据自动记录的方差u和均值std进行归一化x_test_scaled=scaler.transform(x_test.astype(np.float32).reshape(-1,1)).reshape(-1,28,28) # 会根据自动记录的方差u和均值std进行归一化# In[7]:def show_single_image(img_arr): plt.imshow(img_arr,cmap='binary') plt.show()# 打印单张图片 show_single_image(x_train[0])# In[8]:def show_images(n_rows,n_cols,x_data,y_data,class_names): assert len(x_data)==len(y_data) assert n_cols*n_rows&lt;len(x_data) plt.figure(figsize=(n_cols*1.4,n_rows*1.6)) for row in range(n_rows): for col in range(n_cols): index=n_cols*row+col plt.subplot(n_rows,n_cols,index+1) plt.imshow(x_data[index],cmap='binary', interpolation='nearest') plt.axis('off') plt.title(class_names[y_data[index]]) plt.show()# 打印n_rows行n_cols列的图片 class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']# 所对应的名称show_images(3,5,x_train,y_train,class_names)# In[9]:# 构建一个三层的神经网络# model=keras.models.Sequential()# model.add(keras.layers.Flatten(input_shape=[28,28])) # 展开成28*28的向量# model.add(keras.layers.Dense(300,activation='relu')) # 全链接层，层数300，激活函数relu# model.add(keras.layers.Dense(100,activation='relu')) # model.add(keras.layers.Dense(10,activation='softmax')) # 有10个输出# model=keras.models.Sequential([# keras.layers.Flatten(input_shape=[28,28]),# keras.layers.Dense(300,activation='relu'),# keras.layers.Dense(100,activation='relu'),# keras.layers.Dense(10,activation='softmax')# ])model=keras.models.Sequential()model.add(keras.layers.Flatten(input_shape=[28,28]))for _ in range(20): model.add(keras.layers.Dense(100,activation='selu')) # model.add(keras.layers.Dense(100,activation='relu')) # model.add(keras.layers.BatchNormalization()) # 激活函数在前的后的批归一化 # model.add(keras.layers.Dense(100)) # model.add(keras.layers.BatchNormalization()) # model.add(keras.layers.Activation('relu')) # model.add(keras.layers.Dropout(rate=0.5))model.add(keras.layers.AlphaDropout(rate=0.5))# AlphaDropout与Dropout的区别：1、均值方差不变 2、归一化性质不变model.add(keras.layers.Dense(10,activation='softmax'))# relu: y=max(0,x)# softmax: 将向量变成概率分布 x=[x1,x2,x3]# y=[e^x1/sum,e^x2/sum,e^x3/sum],sum=e^x1+e^x2+e^x3# reason for sparse: y-&gt;index y-&gt;one_hot-&gt;[]model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy']) # In[10]:model.layers# In[11]:model.summary() #打印模型的结构# In[12]:# 第一层 [None, 784] * w + b -&gt; [None, 300] w.shape=[784,300], b=[300]# In[15]:# TensorBoard,EarlyStopping,ModelCheckPointlogdir='./dnn-selu-dropout-callbacks' # 设置一个文件夹路径if not os.path.exists(logdir): # 若文件夹不存在，则创建文件夹 os.mkdir(logdir)output_model_file=os.path.join(logdir, 'fashion_mnist_model.h5') #放入文件夹内，文件名fashion_mnist_model.h5callbacks=[ keras.callbacks.TensorBoard(logdir), keras.callbacks.ModelCheckpoint(output_model_file, save_best_only=True), # 保存最好的模型，如果不是这个会默认保存最近的一个模型 keras.callbacks.EarlyStopping(patience=5,min_delta=1e-3)]history=model.fit(x_train_scaled,y_train,epochs=10, validation_data=(x_valid_scaled,y_valid), callbacks=callbacks)# In[16]:type(history)# In[17]:history.history# 打印每次学习的结果# In[18]:def plot_learning_curves(history): pd.DataFrame(history.history).plot(figsize=(8,5)) plt.grid(True) plt.gca().set_ylim(0,1) plt.show()# 打印学习曲线plot_learning_curves(history) # In[19]:model.evaluate(x_test_scaled,y_test) # 在测试集上验证","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://uscair.club/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"DNN","slug":"DNN","permalink":"http://uscair.club/tags/DNN/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://uscair.club/tags/TensorFlow/"}],"author":{"name":"Gowi"}},{"title":"机器学习系列（三）——误差（error），偏差（bias），方差（variance）","slug":"机器学习系列（三）——误差（error），偏差（bias），方差（variance）","date":"2020-02-17T08:25:19.546Z","updated":"2020-02-17T08:25:19.546Z","comments":true,"path":"2020/02/17/机器学习系列（三）——误差（error），偏差（bias），方差（variance）/","link":"","permalink":"http://uscair.club/2020/02/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%89%EF%BC%89%E2%80%94%E2%80%94%E8%AF%AF%E5%B7%AE%EF%BC%88error%EF%BC%89%EF%BC%8C%E5%81%8F%E5%B7%AE%EF%BC%88bias%EF%BC%89%EF%BC%8C%E6%96%B9%E5%B7%AE%EF%BC%88variance%EF%BC%89/","excerpt":"","text":"机器学习系列（三）——误差（error），偏差（bias），方差（variance）训练机器学习模型时，我们希望得到一个泛化性能优异的模型。在上一篇博客回归模型中，当我们采用多项式回归，并不断增加多项式的次数时，模型越来越复杂，但是在测试集上的误差并没有逐步降低。 这表明一个复杂的模型并不总是能在测试集上表现出更好的性能，那么误差来自哪里呢？ 泛化误差（error）我们知道，算法在不同训练集上学得的结果很可能不同，即便这些训练集是来自于同一个分布。以回归任务为例，对测试样本x，令yD为x在数据集上的标记，y为x的真实标记，由于噪声的存在，有可能yD≠y,f(x;D)为在训练集D上学得函数f对x的预测输出。因此，算法的期望预测（在不同训练集上学得的模型对样本x的结果的预测值的均值）可以表示为 不同训练集学得的函数f的预测输出的方差（variance）为 期望输出与真实标记之间的差距称为偏差（bias），即 噪声为 为方便讨论，假定噪声期望为零，即ED[yD−y]=0。算法的期望泛化误差（也采用平方误差度量）为 式中，第一个加红公式等于0，因为fˉ(x)−yD是一个标量，而根据期望预测公式fˉ(x)=ED[f(x;D)]，我们可以得到ED[(f(x;D)−f¯(x))]=0，所以整个加红式子的值为0。同理第二个加红公式等于0，因为噪声期望为0。于是 也就是说，泛化误差可分解为偏差、方差与噪声之和。噪声无法人为控制，所以通常我们认为 现在知道了泛化误差来自哪，就需要进行针对性控制。 偏差（bias）与方差（variance）根据上面的定义，偏差（bias）反映了模型在样本上的期望输出与真实标记之间的差距，即模型本身的精准度，反映的是模型本身的拟合能力。方差（variance）反映了模型在不同训练数据集下学得的函数的输出与期望输出之间的误差，即模型的稳定性，反应的是模型的波动情况。下面用打靶的例子直观展示了偏差和方差。 图中红色的靶心表示测试样本的真实标记，蓝色的点表示模型在不同训练集上选出的函数的输出。第一列的两个图中，蓝色的点都比较集中，说明模型的稳定性好，也就是方差小；第一行的两个图中，蓝色点的中心都比较靠近红色靶心，说明模型的拟合能力强，也就是偏差小。所以总结如下：low bias and low variance：又准又稳low bias and high variance： 准但不稳high bias and low variance：不准但稳high bias and high variance：不准又不稳那模型和偏差、方差之间的对应关系是什么样呢？还是以回归任务为例，看一个极端例子，y=c ，不论模型的训练数据如何变化，学得的函数都不会变，因此f(x;D)的输出都相同，即模型的稳定性非常好，但是对训练集的拟合也不是很好，显然对于测试样本的预测也不会很准确，这种对训练集刻画不足的情况，称为欠拟合（underfitting）。逐渐增加模型的复杂度，学得的函数对训练数据的拟合越来越好 但是，对于一个复杂的模型，当我们稍微改变训练样本时，学得的函数差距将非常的大 这说明复杂的模型对训练样本拟合很好，但是模型的波动性也很大，很可能在测试样本的表现非常差。可以理解为，复杂的模型将训练样本的特性当作全体样本的通性，将噪声引入了模型中，这种现象称之为过拟合（overfitting）。所以我们需要在模型复杂度之间权衡，使偏差和方差得以均衡（trade-off），这样模型的整体误差才会最小。 欠拟合和过拟合应对策略欠拟合（刻画不够） 寻找更好的特征，提升对数据的刻画能力 增加特征数量 重新选择更加复杂的模型 过拟合（刻画太细，泛化太差） 增加训练样本数量，样本多了，噪声比中就减少了 减少特征维数，高维空间密度小 加入正则化项，使得模型更加平滑 模型选择同一模型在不同训练集上学得的函数往往不同，那我们怎样才能选出最好的模型和最好的函数呢？可以采用交叉验证（Cross Validation）法，其基本思路如下：将训练集划分为K份，每次采用其中K-1份作为训练集，另外一份作为验证集，在训练集上学得函数后，然后在验证集上计算误差。再次选择另外K-1份数据再次重复上述过程，最终模型的误差为学得的K个函数的误差的平均值，并依据此值选择最佳模型，最后在整个训练集上训练选择的最佳模型，并在测试集上进行测试。 同时，交叉验证也解决了上面说的variance（不同训练集学得的函数的差异）和bias（不同函数的平均值）两大问题。说白了，交叉验证验证了你的模型是否够精确，够稳定，不能说在某个数据集上表现好就可以，你做的模型是要放在整个数据集上来看的，毕竟泛化能力才是机器学习的核心。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://uscair.club/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://uscair.club/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"author":{"name":"Wonder"}},{"title":"智能算法","slug":"智能算法","date":"2020-02-16T11:58:00.000Z","updated":"2020-02-16T11:58:00.000Z","comments":true,"path":"2020/02/16/智能算法/","link":"","permalink":"http://uscair.club/2020/02/16/%E6%99%BA%E8%83%BD%E7%AE%97%E6%B3%95/","excerpt":"","text":"一、简介什么是群体智能优化算法群体智能优化算法属于一种生物启发式方法。群体智能优化算法主要模拟了昆虫、兽群、鸟群和鱼群的群集行为，这些群体按照一种合作的方式寻找食物，群体中的每个成员通过学习它自身的经验和其他成员的经验来不断地改变搜索的方向。群体智能优化算法的突出特点就是利用了种群的群体智慧进行协同搜索，从而在解空间内找到最优解。 二、群体智能优化算法1.常见的群体智能优化算法分类常见的群体智能优化算法主要有如下几类： （1）蚁群算法（Ant Colony Optimization，简称ACO）[1992年提出]； （2）粒子群优化算法（Particle Swarm Optimization，简称PSO）[1995年提出]（简单易于实现，也是目前应用最为广泛的群体智能优化算法）； （3）菌群优化算法（Bacterial Foraging Optimization，简称BFO）[2002年提出]； （4）蛙跳算法（Shuffled Frog Leading Algorithm，简称SFLA）[2003年提出]； （5）人工蜂群算法（Artificial Bee Colony Algorithm，简称ABC）[2005年提出]； 除了上述几种常见的群体智能算法以外，还有一些并不是广泛应用的群体智能算法，比如萤火虫算法、布谷鸟算法、蝙蝠算法以及磷虾群算法等等。 2.粒子群优化算法思想 粒子群优化算法是在1995年由Eberhart博士和Kennedy博士一起提出的，它源于对鸟群捕食行为的研究。它的基本核心是利用群体中的个体对信息的共享从而使得整个群体的运动在问题求解空间中产生从无序到有序的演化过程，从而获得问题的最优解。我们可以利用一个有关PSO的经典描述来对PSO算法进行一个直观的描述。设想这么一个场景：一群鸟进行觅食，而远处有一片玉米地，所有的鸟都不知道玉米地到底在哪里，但是它们知道自己当前的位置距离玉米地有多远。那么找到玉米地的最佳策略，也是最简单有效的策略就是是搜寻目前距离玉米地最近的鸟群的周围区域。PSO就是从这种群体觅食的行为中得到了启示，从而构建的一种优化模型。 在PSO中，每个优化问题的解都是搜索空间中的一只鸟，称之为“粒子”，而问题的最优解就对应为鸟群要寻找的“玉米地”。所有的粒子都具有一个位置向量（粒子在解空间的位置）和速度向量（决定下次飞行的方向和速度），并可以根据目标函数来计算当前的所在位置的适应值（fitness value），可以将其理解为距离“玉米地”的距离。在每次的迭代中，种群中的粒子除了根据自身的“经验”（历史位置）进行学习以外，还可以根据种群中最优粒子的“经验”来学习，从而确定下一次迭代时需要如何调整和改变飞行的方向和速度。就这样逐步迭代，最终整个种群的粒子就会逐步趋于最优解。 3. 粒子群优化算法的基本框架 在介绍PSO的算法流程之前，我们写给出PSO中常用的迭代算子的形式。代表粒子i的位置向量,代表粒子i的速度向量（其中n为优化问题的维度大小），最早版本的粒子群优化算法的迭代算子形式如下：其中在公式(1)中，Pbesti与Gbest分别代表粒子i历史最佳位置和种群历史最佳位置向量。根据公式(1)(2)可以看出，种群中的粒子通过不断地向自身和种群的历史信息进行学习，从而可以找出问题的最优解。 但是，在后续的研究中表明，上述原始的公式中存在一个问题：公式(1)中Vi的更新太具有随机性，从而使得整个PSO算法的全局优化能力很强，但是局部搜索能力较差。而实际上，我们需要在算法迭代初期PSO有着较强的全局优化能力，而在算法的后期，整个种群应该具有更强的局部搜索能力。所以根据上述的弊端，Shi和Eberhart通过引入惯性权重修改了公式(1)，从而提出了PSO的惯性权重模型：其中参数 w 称为是PSO的惯性权重(inertia weight)， w 为控制单个粒子之前速度影响以及对后续行为影响的内置权重，它的取值介于[0,1]区间，一般应用中均采取自适应的取值方法，即一开始令 w=0.9，使得PSO全局优化能力较强，随着迭代的深入，参数w进行递减，从而使得PSO具有较强的局部优化能力，当迭代结束时，w=0.1。参数 c1 和 c2 称为是学习因子(learn factor)，一般设置为1.4961；而 r1 和 r2 为介于[0,1]之间的随机概率值。(可以用rand()代替，rand()为 0~1 之间的归一化随机数) 整个粒子群优化算法的算法框架如下： Step 1 种群初始化：可以进行随机初始化或者根据被优化的问题设计特定的初始化方法，然后计算个体的适应值，从而选择出个体的局部最优位置向量Pbesti和种群全局最优位置向量Gbest。 Step 2 迭代设置：设置迭代次数 gmax，并令当前迭代次数 g=1; Step 3 速度更新：根据公式（3）更新每个个体的速度向量； Step 4 位置更新：根据公式（2）更新每个个体的位置向量； Step 5 局部位置向量和全局位置向量更新：更新每个个体的Pbesti和Gbest ； Step 6终止条件判断：判断迭代次数时都达到 gmax 。如果满足，输出 Gbest否则继续进行迭代，跳转至 Step 3 。 对于粒子群优化算法的运用，主要是对速度和位置向量迭代算子的设计。迭代算子是否有效将决定整个PSO算法性能的优劣，所以如何设计PSO的迭代算子是PSO算法应用的研究重点和难点。","categories":[{"name":"智能算法","slug":"智能算法","permalink":"http://uscair.club/categories/%E6%99%BA%E8%83%BD%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"AI大数据","slug":"AI大数据","permalink":"http://uscair.club/tags/AI%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"author":{"name":"戴挽舟（BbiHH）"}},{"title":"STM32单片机系列（二）","slug":"32串口通信 (2)","date":"2020-02-15T16:00:00.000Z","updated":"2020-02-15T16:00:00.000Z","comments":true,"path":"2020/02/16/32串口通信 (2)/","link":"","permalink":"http://uscair.club/2020/02/16/32%E4%B8%B2%E5%8F%A3%E9%80%9A%E4%BF%A1%20(2)/","excerpt":"","text":"串口通信与配置：串行通信 同步通信带时钟如：SPI,IIC。 异步通信：不带有时钟信号UART。 同步通信一般都有同步时钟全双工一般都有独立的发送和接收的引脚半双工一般只要一个共用的发送和接收的引脚 STM32串口通信的接口：UART通用异步收发器，USART 通用同步异步收发器，使用了RS232接口，使不同的设备可以进行方便的通讯。其全名为：数据终端设备(DTE)和数据通讯设备(DCE)之间串行二进制数据交换接口技术标准。(有9针或25针的D型插头，一般为9针插头)。 STM32串口通信UART异步通信预先定义： 起始位 数据位（8位或者9位） 奇偶校验位（第9位） 停止位（1，15，2位） 波特率设置 STM32串口1和6使用PCLK2(x=2) 2-5s使用PCLK1(x=1)STM32F4 给IO的中断线为0-15一共16个中断线对应112（16x7）个IO口。 每一个中断线可以映射的IO口有7个但是同组IO口里面一次只能有一个IO口占用中断线。如（PA0-PG0）是一组可以映射到中断线EXTI0但是一次只能有其中的一个IO口映射上去。每一个中断线可以设置它的触发方式（上升沿触发，下降沿触发，边沿触发【上升沿的下降沿都可以触发】）和使能位状态位。IO在外部中断向量里面只分配了7个中断服务函数0，1，2，3，4，5-9，10-15库函数：SYSCFG_EXTILineConfig(EXIT_PortSourceGPIOE,EXIT_PinSource2)【把PE2口连接到中断线2】为IO设置对应的中断线EXTI_Init()【】初始化中断线上的触发方式。EXIT_GetITStatus()判断中断线上的中断是否发生EXIT_ClearITPendingBit（）清楚对应线上的中断标志位。RCC_APB2PeriphClockCmd（）使能对应中断的时钟EXIT_IRQHandler（）对应的中断服务函数（发生中断就跳转至函数里面）","categories":[{"name":"单片机","slug":"单片机","permalink":"http://uscair.club/categories/%E5%8D%95%E7%89%87%E6%9C%BA/"}],"tags":[{"name":"STM32F407","slug":"STM32F407","permalink":"http://uscair.club/tags/STM32F407/"}],"author":{"name":"Page"}},{"title":"关于numpy矩阵运算的小记","slug":"关于numpy矩阵运算的小记","date":"2020-02-15T16:00:00.000Z","updated":"2020-02-15T16:00:00.000Z","comments":true,"path":"2020/02/16/关于numpy矩阵运算的小记/","link":"","permalink":"http://uscair.club/2020/02/16/%E5%85%B3%E4%BA%8Enumpy%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97%E7%9A%84%E5%B0%8F%E8%AE%B0/","excerpt":"","text":"关于numpy矩阵运算的小记[toc] 发现做矩阵处理是numpy忘了好多，所以记录下来. array与matrixmatrix是array的分支，matrix和array在很多时候都是通用的，你用哪一个都一样。但这时候，官方建议大家如果两个可以通用，那就选择array，因为array更灵活，速度更快，很多人把二维的array也翻译成矩阵。但是matrix的优势就是相对简单的运算符号，比如两个矩阵相乘，就是用符号*，但是array相乘不能这么用，得用方法.dot()array的优势就是不仅仅表示二维，还能表示3、4、5…维，而且在大部分Python程序里，array也是更常用的。 123456789101112import numpy as npa1 = np.array([[1, 2], [3, 4]])a2 = np.array([[5, 6], [7, 8]])b1 = np.mat([[1, 2], [3, 4]])b2 = np.mat([[5, 6], [7, 8]])print((np.dot(a1, a2)).all() == (b1 * b2).all()) 输出 True 矩阵判等在矩阵判等中存在各个元素相等和整个矩阵相等两种情况 1234567891011121314import numpy as npa1 = np.array([[1, 2], [3, 4]])a2 = np.array([[5, 6], [7, 8]])b1 = np.mat([[1, 2], [3, 4]])b2 = np.mat([[5, 6], [7, 8]])print('np.dot(a1, a2):\\n', np.dot(a1, a2))print('b1 * b2:\\n', b1 * b2)print((np.dot(a1, a2)) == (b1 * b2))print((np.dot(a1, a2)).all() == (b1 * b2).all()) 输出： 其中==用于判等各个元素相等，用all()方法可以判断整个矩阵相等 矩阵的连接在numpy中存在按行连接与按列连接两种形式 1234567891011121314151617import numpy as npx = np.array([[1, 2, 3], [4, 5, 6]])print(\"x:\\n\", x)y = np.array([[7, 8, 9], [10, 11, 12]])print(\"y:\\n\", y)z = np.array([[13, 14, 15]])print(\"z:\\n\", z)a = np.vstack((x, y, z))print('np.vstack((x,y,z)):\\n', a)b = np.hstack((x, y))print('np.hstack((x,y)):\\n', b) 输出： 其中np.hstack()是按行连接：行数相同的的连接在一起；np.vstack()按列连接：列书相同的连接在一起。 矩阵的向量化在矩阵中我们可以使用reshape方法来实现矩阵的向量化，如果在整形操作中将尺寸标注为-1，则会自动计算其他尺寸 1234567891011121314151617181920import numpy as npx = np.array([[1, 2, 3], [4, 5, 6]])print(\"x:\\n\", x)y = np.array([[7, 8, 9], [10, 11, 12]])print(\"y:\\n\", y)z = np.array([[13, 14, 15]])print(\"z:\\n\", z)a = np.vstack((x, y, z))print('np.vstack((x,y,z)):\\n', a)b = np.hstack((x, y))print('np.hstack((x,y)):\\n', b)print(a.shape)print(a.reshape(-1,1)) 输出： 矩阵的拆分使用hsplit，您可以沿数组的水平轴拆分数组，方法是指定要返回的形状相同的数组的数量，或者指定要在其后进行划分的列，使用vsplit，您可以沿数组的竖直轴拆分数组，方法是指定要返回的形状相同的数组的数量，或者指定要在其后进行划分的列。 12345678import numpy as npa = np.array([[1, 1, 2, 3], [1, 5, 7, 3], [7, 3, 9, 3], [1, 7, 3, 0]])print(np.hsplit(a, 2))print(np.vsplit(a, 2)) 矩阵的复制用=的简单分配不会复制数组对象或其数据，该copy方法对数组及其数据进行完整复制。 12345678910111213import numpy as npa = np.array([[1, 1, 2, 3], [1, 5, 7, 3], [7, 3, 9, 3], [1, 7, 3, 0]])# print(np.hsplit(a, 2))# print(np.vsplit(a, 2))b = aprint(id(a))print(id(b))c = a.copy()print(id(c)) 矩阵的逆 利用numpy.linalg.inv()可以求得矩阵的逆矩阵 123456789import numpy as npa = np.array([[1, 1, 2, 3], [1, 5, 7, 3], [7, 3, 9, 3], [1, 7, 3, 0]])b = np.linalg.inv(a)print(np.dot(a, b)) 矩阵的索引12345678910111213import numpy as npa = np.array([[1, 1, 2, 3], [1, 5, 7, 3], [7, 3, 9, 3], [1, 7, 3, 0]])print(a[2, 3]) # 输出第2+1行第3+1列的数字print(a[1:]) # 以矩阵形式输出从第1+1行开始的所有数print(a[1:3]) # 以矩阵形式输出第1+1到第3+1-1行的数print(a[:, 1]) # 输出矩阵的第1+1列的所有数print(a[0:3, 1]) # 输出矩阵从0+1行到第3+1-1行的第1+1列的所有数print(type(a[:3]))","categories":[{"name":"python基础","slug":"python基础","permalink":"http://uscair.club/categories/python%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Numpy","slug":"Numpy","permalink":"http://uscair.club/tags/Numpy/"}],"author":{"name":"Gowi"}},{"title":"卷积神经网络（二）","slug":"卷积神经网络（二）","date":"2020-02-15T16:00:00.000Z","updated":"2020-02-15T16:00:00.000Z","comments":true,"path":"2020/02/16/卷积神经网络（二）/","link":"","permalink":"http://uscair.club/2020/02/16/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%BA%8C%EF%BC%89/","excerpt":"","text":"卷积神经网络中全连接，局部连接和权值共享卷积神经网络与一般神经网络不同在于其连接还具有局部连接和参数共享的特点。依据上图：全连接连接个数：nm（左图） 局部连接连接个数：im（这一层的某个节点只与上一层的部分节点相连） 依据上图：权值不共享且仅为局部连接权值参数为：3*4=12 权值共享参数为：3","categories":[{"name":"数字图像处理","slug":"数字图像处理","permalink":"http://uscair.club/categories/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}],"tags":[{"name":"CNN","slug":"CNN","permalink":"http://uscair.club/tags/CNN/"}],"author":{"name":"ffffff"}},{"title":"神经网络--反向传播算法推导","slug":"神经网络--反向传播算法推导","date":"2020-02-12T16:00:00.000Z","updated":"2020-02-12T16:00:00.000Z","comments":true,"path":"2020/02/13/神经网络--反向传播算法推导/","link":"","permalink":"http://uscair.club/2020/02/13/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95%E6%8E%A8%E5%AF%BC/","excerpt":"","text":"概述以监督学习为例，假设我们有训练样本集$(x^{(i)},y^{(i)})$，那么神经网络算法能提供一种复杂且非线性的假设模型$h_{(W,b)}(x)$,它具有参数$W$，$b$，可以以此参数来拟合我们的数据。 为了描述神经网络，我们先从最简单的神经网络讲起，这个神经网络仅由一个“神经元”构成，以下即是这个“神经元”的图示： 这个神经元是一个以$x_1,x_2,x_3$以及截距+1为输入值的运算单元，其输出为$h_{(W,b)}(x)=f(W^Tx)=f(\\overset{3}{\\underset{i=1}{\\sum}}W_iX_i+b)$,其中函数$f:\\mathbb{R}\\to\\mathbb{R}$被称为激活函数 我们选用$sigmoid$函数为激活函数$$f(z)=\\frac{1}{1+e^{-z}}$$可以看出，这个单一“神经元”的输入－输出映射关系其实就是一个逻辑回归（logistic regression）。 我们采用$sigmoid$函数 其中$f’(z)=f(z)(1-f(z))$,如果是$tanh$函数，则$f’(z)=1-(f(z))^2$。 神经网络模型所谓神经网络就是将许多个单一“神经元”联结在一起，这样，一个“神经元”的输出就可以是另一个“神经元”的输入。例如，下图就是一个简单的神经网络： 我们使用圆圈来表示神经网络的输入，标上“+1”的圆圈被称为偏置节点，也就是截距项。神经网络最左边的一层叫做输入层，最右的一层叫做输出层（本例中，输出层只有一个节点）。中间所有节点组成的一层叫做隐藏层，因为我们不能在训练样本集中观测到它们的值。同时可以看到，以上神经网络的例子中有3个输入单元（偏置单元不计在内），3个隐藏单元及一个输出单元。 我们用$n_l$来表示网络的层数，本例中 $\\textstyle n_l=3$ ，我们将第 $\\textstyle l$ 层记为 $\\textstyle L_l$ ，于是$\\textstyle L_1$ 是输入层，输出层是 $\\textstyle L_{n_l}$ 。本例神经网络有参数 $\\textstyle (W,b) = (W^{(1)}, b^{(1)}, W^{(2)}, b^{(2)})$ ，其中$\\textstyle W^{(l)}_{ij}$（下面的式子中用到）是第 $\\textstyle l$ 层第 $\\textstyle j$ 单元与第 $\\textstyle l+1$ 层第 $i$ 单元之间的联接参数（其实就是连接线上的权重，注意标号顺序）， $\\textstyle b^{(l)}_i$ 是第 $\\textstyle l+1$ 层第$i$单元的偏置项。因此在本例中， $\\textstyle W^{(1)} \\in \\Re^{3\\times 3}$ ， $\\textstyle W^{(2)} \\in \\Re^{1\\times 3}$ 。注意，没有其他单元连向偏置单元(即偏置单元没有输入)，因为它们总是输出 $\\textstyle +1$。同时，我们用 $\\textstyle s_l$ 表示第 $\\textstyle l$ 层的节点数（偏置单元不计在内）。 我们用 $\\textstyle a^{(l)}_i$ 表示第 $\\textstyle l$层第 $\\textstyle i$ 单元的激活值（输出值）。当$\\textstyle l=1$ 时，$ \\textstyle a^{(1)}_i = x_i $，也就是第 $\\textstyle i$ 个输入值（输入值的第$\\textstyle i$个特征)。对于给定参数集合 $\\textstyle W,b$，我们的神经网络就可以按照函数 $\\textstyle h_{W,b}(x)$ 来计算输出结果。本例神经网络的计算步骤如下：$$a_1^{(2)}=f(W_{11}^{(1)}x_1+W_{12}^{(1)}x_2+W_{13}^{(1)}x_3+b_1^{(1)})\\a_1^{(2)}=f(W_{21}^{(1)}x_1+W_{22}^{(1)}x_2+W_{23}^{(1)}x_3+b_1^{(1)})\\a_1^{(2)}=f(W_{31}^{(1)}x_1+W_{32}^{(1)}x_2+W_{33}^{(1)}x_3+b_1^{(1)})\\h_{W,b}(x)=a_1^{(3)}=f(W_{11}^{(2)}a_1^{(2)}+W_{12}^{(2)}a_2^{(2)}+W_{13}^{(2)}a_3^{(2)}+b_1^{(2)})$$我们用 $\\textstyle z^{(l)}_i$ 表示第$\\textstyle l$ 层第 $\\textstyle i$ 单元输入加权和（包括偏置单元），比如， $\\textstyle z_i^{(2)} = \\sum_{j=1}^n W^{(1)}_{ij} x_j + b^{(1)}_i$ ，则 $\\textstyle a^{(l)}_i = f(z^{(l)}_i)$ 。 这样我们就可以得到一种更简洁的表示法。这里我们将激活函数 $\\textstyle f(\\cdot)$ 扩展为用向量（分量的形式）来表示，即 $\\textstyle f([z_1, z_2, z_3]) = [f(z_1), f(z_2), f(z_3)]$，那么，上面的等式可以更简洁地表示为：$$z^{(2)}=W^{(1)}x+b^{(1)}\\a^{(2)}=f(z^{(2)})\\z^{(3)}=W^{(2)}x+b^{(2)}\\h_{W,b}(x)=a^{(3)}=f(z^{(3)})$$我们将上面的计算步骤叫作前向传播。回想一下，之前我们用 $\\textstyle a^{(1)} = x$ 表示输入层的激活值，那么给定第 $\\textstyle l$的激活值 $\\textstyle a^{(l)}$ 后，第 $\\textstyle l+1$ 层的激活值 $\\textstyle a^{(l+1)}$ 就可以按照下面步骤计算得到：$$z^{(l+1)}=W^{(l)}a^{(l)}+b^{(l)}\\a^{(l+1)}=f(z^{(l+1)})$$将参数矩阵化，使用矩阵－向量运算方式，我们就可以利用线性代数的优势对神经网络进行快速求解。 目前为止，我们讨论了一种神经网络，我们也可以构建另一种结构的神经网络（这里结构指的是神经元之间的联接模式），也就是包含多个隐藏层的神经网络。最常见的一个例子是 $\\textstyle n_l$ 层的神经网络，第 $\\textstyle 1$ 层是输入层，第 $\\textstyle n_l$ 层是输出层，中间的每个层 $\\textstyle l$ 与层 $\\textstyle l+1$ 紧密相联。这种模式下，要计算神经网络的输出结果，我们可以按照之前描述的等式，按部就班，进行前向传播，逐一计算第 $\\textstyle L_2$ 层的所有激活值，然后是第 $\\textstyle L_3$ 层的激活值，以此类推，直到第 $\\textstyle L_{n_l}$层。这是一个前馈神经网络的例子，因为这种联接图没有闭环或回路。 神经网络也可以有多个输出单元。比如，下面的神经网络有两层隐藏层： $\\textstyle L_2$ 及 $\\textstyle L_3$ ，输出层 $\\textstyle L_4$ 有两个输出单元。 要求解这样的神经网络，需要样本集 $\\textstyle (x^{(i)}, y^{(i)})$ ，其中 $\\textstyle y^{(i)} \\in \\Re^2$ 。如果你想预测的输出是多个的，那这种神经网络很适用。（比如，在医疗诊断应用中，患者的体征指标就可以作为向量的输入值，而不同的输出值$\\textstyle y_i$可以表示不同的疾病存在与否。） 反向传导算法假设我们有一个固定样本集 $\\textstyle \\{ (x^{(1)}, y^{(1)}), \\ldots, (x^{(m)}, y^{(m)}) \\}$，它包含 $\\textstyle m$ 个样例。我们可以用批量梯度下降法来求解神经网络。具体来讲，对于单个样例 $\\textstyle (x,y)$)，其代价函数为：$$\\begin{align}J(W,b; x,y) = \\frac{1}{2} \\left| h_{W,b}(x) - y \\right|^2.\\end{align}$$这是一个（二分之一的）方差代价函数。给定一个包含 $\\textstyle m$ 个样例的数据集，我们可以定义整体代价函数为：$$\\begin{align}J(W,b)&amp;= \\left[ \\frac{1}{m} \\sum_{i=1}^m J(W,b;x^{(i)},y^{(i)}) \\right] + \\frac{\\lambda}{2} \\sum_{l=1}^{n_l-1} \\; \\sum_{i=1}^{s_l} \\; \\sum_{j=1}^{s_{l+1}} \\left( W^{(l)}_{ji} \\right)^2 \\\\&amp;= \\left[ \\frac{1}{m} \\sum_{i=1}^m \\left( \\frac{1}{2} \\left| h_{W,b}(x^{(i)}) - y^{(i)} \\right|^2 \\right) \\right] + \\frac{\\lambda}{2} \\sum_{l=1}^{n_l-1} \\; \\sum_{i=1}^{s_l} \\; \\sum_{j=1}^{s_{l+1}} \\left( W^{(l)}_{ji} \\right)^2\\end{align}$$以上关于$\\textstyle J(W,b)$定义中的第一项是一个均方差项。第二项是一个规则化项（也叫权重衰减项），其目的是减小权重的幅度，防止过度拟合。 [注：通常权重衰减的计算并不使用偏置项 $\\textstyle b^{(l)}_i$，比如我们在 $\\textstyle J(W, b)$ 的定义中就没有使用。一般来说，将偏置项包含在权重衰减项中只会对最终的神经网络产生很小的影响。在贝叶斯规则化方法中，我们将高斯先验概率引入到参数中计算MAP（极大后验）估计（而不是极大似然估计）。] 权重衰减参数 $\\textstyle \\lambda$ 用于控制公式中两项的相对重要性。在此重申一下这两个复杂函数的含义：$\\textstyle J(W,b;x,y)$ 是针对单个样例计算得到的方差代价函数；$\\textstyle J(W,b)$ 是整体样本代价函数，它包含权重衰减项。 以上的代价函数经常被用于分类和回归问题。在分类问题中，我们用 $\\textstyle y = 0$ 或 $\\textstyle 1$，来代表两种类型的标签（回想一下，这是因为 sigmoid激活函数的值域为 !$\\textstyle [0,1]$；如果我们使用双曲正切型激活函数，那么应该选用 $\\textstyle -1$ 和 $\\textstyle +1$ 作为标签）。对于回归问题，我们首先要变换输出值域（也就是$y$），以保证其范围为 $\\textstyle [0,1]$ （同样地，如果我们使用双曲正切型激活函数，要使输出值域为 $\\textstyle [-1,1]$）。 我们的目标是针对参数 $\\textstyle W$ 和 $\\textstyle b$ 来求其函数 $\\textstyle J(W,b)$ 的最小值。为了求解神经网络，我们需要将每一个参数 $\\textstyle W^{(l)}_{ij}$ 和 $\\textstyle b^{(l)}_i$ 初始化为一个很小的、接近零的随机值（比如说，使用正态分布 $\\textstyle {Normal}(0,\\epsilon^2)$ 生成的随机值，其中 $\\textstyle \\epsilon$ 设置为 $\\textstyle 0.01$ ），之后对目标函数使用诸如批量梯度下降法的最优化算法。因为 $\\textstyle J(W, b)$ 是一个非凸函数，梯度下降法很可能会收敛到局部最优解；但是在实际应用中，梯度下降法通常能得到令人满意的结果。最后，需要再次强调的是，要将参数进行随机初始化，而不是全部置为$\\textstyle 0$。如果所有参数都用相同的值作为初始值，那么所有隐藏层单元最终会得到与输入值有关的、相同的函数（也就是说，对于所有 $\\textstyle i$，$\\textstyle W^{(1)}_{ij}$都会取相同的值，那么对于任何输入 $\\textstyle x$ 都会有：$\\textstyle a^{(2)}_1 = a^{(2)}_2 = a^{(2)}_3 = \\ldots$ ）。随机初始化的目的是使对称失效。 梯度下降法中每一次迭代都按照如下公式对参数 $\\textstyle W$ 和$\\textstyle b$ 进行更新：$$\\begin{align}W_{ij}^{(l)} &amp;= W_{ij}^{(l)} - \\alpha \\frac{\\partial}{\\partial W_{ij}^{(l)}} J(W,b) \\\\b_{i}^{(l)} &amp;= b_{i}^{(l)} - \\alpha \\frac{\\partial}{\\partial b_{i}^{(l)}} J(W,b)\\end{align}$$其中 $\\textstyle \\alpha$ 是学习速率。其中关键步骤是计算偏导数。我们现在来讲一下反向传播算法，它是计算偏导数的一种有效方法。 我们首先来讲一下如何使用反向传播算法来计算 $\\textstyle \\frac{\\partial}{\\partial W_{ij}^{(l)}} J(W,b; x, y)$ 和 $\\textstyle \\frac{\\partial}{\\partial b_{i}^{(l)}} J(W,b; x, y)$，这两项是单个样例 $\\textstyle (x,y)$ 的代价函数 $\\textstyle J(W,b;x,y)$ 的偏导数。一旦我们求出该偏导数，就可以推导出整体代价函数$\\textstyle J(W,b)$的偏导数：$$\\begin{align}\\frac{\\partial}{\\partial W_{ij}^{(l)}} J(W,b) &amp;=\\left[ \\frac{1}{m} \\sum_{i=1}^m \\frac{\\partial}{\\partial W_{ij}^{(l)}} J(W,b; x^{(i)}, y^{(i)}) \\right] + \\lambda W_{ij}^{(l)} \\\\\\frac{\\partial}{\\partial b_{i}^{(l)}} J(W,b) &amp;=\\frac{1}{m}\\sum_{i=1}^m \\frac{\\partial}{\\partial b_{i}^{(l)}} J(W,b; x^{(i)}, y^{(i)})\\end{align}$$以上两行公式稍有不同，第一行比第二行多出一项，是因为权重衰减是作用于 $\\textstyle W$ 而不是$\\textstyle b$。 反向传播算法的思路如下：给定一个样例 $\\textstyle (x,y)$，我们首先进行“前向传导”运算，计算出网络中所有的激活值，包括 $\\textstyle h_{W,b}(x)$ 的输出值。之后，针对第 $\\textstyle l$ 层的每一个节点 $\\textstyle i$，我们计算出其“残差” $\\textstyle \\delta^{(l)}_i$，该残差表明了该节点对最终输出值的残差产生了多少影响。对于最终的输出节点，我们可以直接算出网络产生的激活值与实际值之间的差距，我们将这个差距定义为 $\\textstyle \\delta^{(n_l)}_i$ （第 $\\textstyle n_l$ 层表示输出层）。对于隐藏单元我们如何处理呢？我们将基于节点（第 $\\textstyle l+1$ 层节点）残差的加权平均值计算 $\\textstyle \\delta^{(l)}_i$，这些节点以 $\\textstyle a^{(l)}_i$ 作为输入。下面将给出反向传导算法的细节： 进行前馈传导计算，利用前向传导公式，得到 $\\textstyle L_2, L_3, \\ldots$ 直到输出层 $\\textstyle L_{n_l}$ 的激活值。 对于第 $n_l$（输出层）的每个输出单元$i$我们根据以下公式计算残差： 对 $\\textstyle l = n_l-1, n_l-2, n_l-3, \\ldots, 2$ 的各个层，第$\\textstyle l$层的第 $\\textstyle i$ 个节点的残差计算方法如下： $$\\delta_i^{(n_l)}=(\\overset{s_{l+1}}{\\underset{j=1}{\\sum}}W_{ji}^{(l)}\\delta_j^{(l+1)})f’(z_i^{(l)})$$ $$\\begin{align}\\delta^{(n_l-1)}_i &amp;=\\frac{\\partial}{\\partial z^{n_l-1}_i}J(W,b;x,y) = \\frac{\\partial}{\\partial z^{n_l-1}_i}\\frac{1}{2} \\left|y - h_{W,b}(x)\\right|^2 = \\frac{\\partial}{\\partial z^{n_l-1}_i}\\frac{1}{2} \\sum_{j=1}^{S_{n_l}}(y_j-a_j^{(n_l)})^2 \\\\&amp;= \\frac{1}{2} \\sum_{j=1}^{S_{n_l}}\\frac{\\partial}{\\partial z^{n_l-1}_i}(y_j-a_j^{(n_l)})^2 = \\frac{1}{2} \\sum_{j=1}^{S_{n_l}}\\frac{\\partial}{\\partial z^{n_l-1}_i}(y_j-f(z_j^{(n_l)}))^2 \\\\&amp;= \\sum_{j=1}^{S_{n_l}}-(y_j-f(z_j^{(n_l)})) \\cdot \\frac{\\partial}{\\partial z_i^{(n_l-1)}}f(z_j^{(n_l)}) = \\sum_{j=1}^{S_{n_l}}-(y_j-f(z_j^{(n_l)})) \\cdot f’(z_j^{(n_l)}) \\cdot \\frac{\\partial z_j^{(n_l)}}{\\partial z_i^{(n_l-1)}} \\\\&amp;= \\sum_{j=1}^{S_{n_l}} \\delta_j^{(n_l)} \\cdot \\frac{\\partial z_j^{(n_l)}}{\\partial z_i^{n_l-1}} = \\sum_{j=1}^{S_{n_l}} \\left(\\delta_j^{(n_l)} \\cdot \\frac{\\partial}{\\partial z_i^{n_l-1}}\\sum_{k=1}^{S_{n_l-1}}f(z_k^{n_l-1}) \\cdot W_{jk}^{n_l-1}\\right) \\\\&amp;= \\sum_{j=1}^{S_{n_l}} \\delta_j^{(n_l)} \\cdot W_{ji}^{n_l-1} \\cdot f’(z_i^{n_l-1}) = \\left(\\sum_{j=1}^{S_{n_l}}W_{ji}^{n_l-1}\\delta_j^{(n_l)}\\right)f’(z_i^{n_l-1})\\end{align}$$ 将上式中的$\\textstyle n_l-1$与$\\textstyle n_l$的关系替换为$\\textstyle l$与$\\textstyle l+1$的关系，就可以得到：$$\\delta^{(l)}_i = \\left( \\sum_{j=1}^{s_{l+1}} W^{(l)}_{ji} \\delta^{(l+1)}_j \\right) f’(z^{(l)}_i)$$以上逐次从后向前求导的过程即为“反向传导”的本意所在。 ​ 4.计算我们需要的偏导数，计算方法如下 ：$$\\begin{align}\\frac{\\partial}{\\partial W_{ij}^{(l)}} J(W,b; x, y) &amp;= a^{(l)}_j \\delta_i^{(l+1)} \\\\\\frac{\\partial}{\\partial b_{i}^{(l)}} J(W,b; x, y) &amp;= \\delta_i^{(l+1)}.\\end{align}\\$$求$\\begin{align}\\frac{\\partial}{\\partial W_{ij}^{(l)}} J(W)\\end{align}$?$$\\begin{align}\\frac{\\partial}{\\partial W_{ij}^{(l)}} J(W)&amp;=\\frac{\\partial }{\\partial Z_{ij}^{(l)}}J(W)=\\frac{\\partial J(W)}{\\partial Z_{i}^{(l+1)}}\\times\\frac{\\partial Z_{i}^{(l+1)}}{\\partial Z_{ij}^{(l)}} &amp;(问题拆解)\\Z_i^{(l+1)} &amp;= \\overset{n}{\\underset{i}{\\sum}}W_{ij}^{l}\\times a_j^{(l)}&amp;(神经元求和)\\\\frac{\\partial Z_{i}^{(l+1)}}{\\partial Z_{ij}^{(l)}}&amp;=\\frac{\\partial \\overset{n}{\\underset{i}{\\sum}}W_{ij}^{(l)}\\times a_j^{(l)}}{\\partial W_{ij}^{(l)}}=a_j^{(l)}&amp;(输出对权值的偏导数)\\\\delta_i^{l+1}&amp;=\\frac{\\partial J(W)}{\\partial Z_i^{(l+1)}}&amp;(神经元的错误变化率为)\\\\frac{\\partial}{\\partial W_i^{(l)}} J(W) &amp;= \\delta_i^{l+1}\\times a_j^{(l)}&amp;(最终)\\end{align}$$最后，我们用矩阵-向量表示法重写以上算法。我们使用“$\\textstyle \\bullet$” 表示向量乘积运算符（在Matlab或Octave里用“.*”表示，也称作阿达马乘积）。若$\\textstyle a = b \\bullet c$，则 $\\textstyle a_i = b_ic_i$。在上一个教程中我们扩展了 $\\textstyle f(\\cdot)$ 的定义，使其包含向量运算，这里我们也对偏导数 $\\textstyle f’(\\cdot)$ 也做了同样的处理（于是又有 $\\textstyle f’([z_1, z_2, z_3]) = [f’(z_1), f’(z_2), f’(z_3)]$ ）。 么，反向传播算法可表示为以下几个步骤： 进行前馈传导计算，利用前向传导公式，得到 $\\textstyle L_2, L_3, \\ldots$直到输出层 $\\textstyle L_{n_l}$ 的激活值。 对输出层（第 $n_l$层），计算： $$ \\begin{align}\\delta^{(n_l)}= - (y - a^{(n_l)}) \\bullet f’(z^{(n_l)})\\end{align} $$ 对于$ \\textstyle l = n_l-1, n_l-2, n_l-3, \\ldots, 2$的各层，计算： $$ \\begin{align}\\delta^{(l)} = \\left((W^{(l)})^T \\delta^{(l+1)}\\right) \\bullet f’(z^{(l)})\\end{align} $$ 计算最终需要的偏导数值： $$ \\begin{align}\\nabla_{W^{(l)}} J(W,b;x,y) &amp;= \\delta^{(l+1)} (a^{(l)})^T, \\\\\\nabla_{b^{(l)}} J(W,b;x,y) &amp;= \\delta^{(l+1)}.\\end{align} $$ 实现中应注意：在以上的第2步和第3步中，我们需要为每一个 $\\textstyle i$ 值计算其 $\\textstyle f’(z^{(l)}_i)$。假设 $\\textstyle f(z)$ 是sigmoid函数，并且我们已经在前向传导运算中得到了 $\\textstyle a^{(l)}_i$。那么，使用我们早先推导出的 !$\\textstyle f’(z)$表达式，就可以计算得到 $\\textstyle f’(z^{(l)}_i) = a^{(l)}_i (1- a^{(l)}_i)$。 最后，我们将对梯度下降算法做个全面总结。在下面的伪代码中，$\\textstyle \\Delta W^{(l)}$ 是一个与矩阵 $\\textstyle W^{(l)}$ 维度相同的矩阵，$\\textstyle \\Delta b^{(l)}$ 是一个与 $\\textstyle b^{(l)}$ 维度相同的向量。注意这里“$\\textstyle \\Delta W^{(l)}$”是一个矩阵，而不是“$\\textstyle \\Delta$ 与 $\\textstyle W^{(l)}$ 相乘”。下面，我们实现批量梯度下降法中的一次迭代： 对于所有 $\\textstyle l$，令 $\\textstyle \\Delta W^{(l)} := 0$ , $\\textstyle \\Delta b^{(l)} := 0$ （设置为全零矩阵或全零向量） 对于$i=1$到$m$ 使用反向传播算法计算 $\\textstyle \\nabla_{W^{(l)}} J(W,b;x,y)$ 和 $\\textstyle \\nabla_{b^{(l)}} J(W,b;x,y)$ 计算$\\textstyle \\Delta W^{(l)} := \\Delta W^{(l)} + \\nabla_{W^{(l)}} J(W,b;x,y)$ 计算 $\\textstyle \\Delta b^{(l)} := \\Delta b^{(l)} + \\nabla_{b^{(l)}} J(W,b;x,y)$ 更新权重参数 $\\begin{align}W^{(l)} &amp;= W^{(l)} - \\alpha \\left[ \\left(\\frac{1}{m} \\Delta W^{(l)} \\right) + \\lambda W^{(l)}\\right] \\\\b^{(l)} &amp;= b^{(l)} - \\alpha \\left[\\frac{1}{m} \\Delta b^{(l)}\\right]\\end{align}$ 现在，我们可以重复梯度下降法的迭代步骤来减小代价函数 $\\textstyle J(W,b)$ 的值，进而求解我们的神经网络。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://uscair.club/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://uscair.club/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"},{"name":"神经网络","slug":"神经网络","permalink":"http://uscair.club/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"author":{"name":"Gowi"}},{"title":"机器学习第一章【Introduction】","slug":"机器学习系列（一）——回归模型","date":"2020-02-09T17:33:36.400Z","updated":"2020-02-09T17:33:36.400Z","comments":true,"path":"2020/02/10/机器学习系列（一）——回归模型/","link":"","permalink":"http://uscair.club/2020/02/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"机器学习系列（一）——回归模型回归（Regression）模型是指机器学习方法学到的函数的输出是连续实数值，回归模型可以用于预测或者分类，这篇博客中主要整理用于预测的线性回归模型和多项式回归模型。 线性回归按照机器学习建模的三个步骤，首先需要确定选用的模型，这里就是线性回归（Linear regression）模型，然后将其形式化表达： 其中，x1,x2,⋯,xn是样本数据的n维属性描述，每一组w和b能确定一个不一样的h(x)，w和b的所有取值组合就构成了可选函数集合，我们的任务就是要从这个函数集合中选出“最好”的那个函数。对于训练数据集D描述如下： 其中)是样本的n维特征向量表示，y(i)∈R是样本标记。线性回归的目标是学得一个线性函数以尽可能准确的预测实值输出标记。因此我们需要确定一个衡量标准用以度量一个函数的好坏，也就是选择合适的损失函数（Loss Function）。根据线性回归的目标，我们只需要度量h(x)与y之间的差距，均方误差（Mean Square Error，MSE）是回归任务中最常用的损失函数。 因为hh是关于w,bw,b的函数，所以上式也可以写成能够让LL最小的w,bw,b所确定的函数就是我们要找的最好的那个函数，记为w∗,b∗ 现在需要选择一种优化算法从众多w,b中找出w∗,b∗w∗,b∗，常用的方法有梯度下降算法（Gradient Descent）和最小二乘法（Least Square Method，LSM）。 梯度下降法对多元函数的每一个变量分别求∂∂偏导数，并将结果写成向量形式，就是梯度。比如函数f(x,y)，分别对x,y求偏导数，(∂f/∂x,∂f/∂y)^T就是梯度。从几何意义上讲，梯度是函数在该点变化最快的方向，因此沿着梯度的反方向，会更加容易找到函数的最小值点。下图是梯度下降的一个直观解释 比如我们在一座大山的某个位置想要到达山脚下，由于我们不知道怎么下山，于是决定走一步算一步，每次走到一个位置后，求解当前位置的梯度，沿着梯度的负方向，也就是当前最陡峭的方向向下走，直到走到梯度为零的位置。当然这样走下去，有可能不能走到山脚，而是到了某一个局部山峰低处。因此梯度下降不一定能够找到全局最优解，有可能是一个局部最优解，如果损失函数是凸函数，梯度下降算法就一定能找到全局最优解。梯度下降算法步骤如下： 随机选取一个初始值w^0计算，其中ηη是学习速率，决定了每一次调整的步长 迭代第二步多次直至梯度为零，或者损失达到允许范围，或者达到迭代次数。 最小二乘法同样可以采用最小二乘法来对w,b进行估计，最小二乘法直接求解得到解析解。为了方便讨论，我们把w,b合并组成一个向量)，同时给每一个样本增加一个恒定属性值1。同时，把数据集D表示成一个m∗(n+1)m∗(n+1)大小的矩阵X再把标记也写成向量形式y=(y1;y2;⋯;ym)，则类似的有损失函数对w^求导得到令上式等于零，可得w^w^最优解的闭式解其中，(X^TX)−1是(X^TX)的逆矩阵，可能存在(X^TX)不是满秩矩阵，常见的作法是引入正则化（regularization）项。 多项式回归有些样本数据用线性回归拟合时可能不是特别恰当，这时候可以尝试采用多项式回归，如下图所示，是一个房屋价格与房屋面积的样本数据集，可以明显发现所有数据点并不分布在某一条直线附近，这时候可以考虑尝试二次函数或者三次函数 对于多项式回归，可以将x^2,x^3也看作是一个新的属性，这时多项式回归就和线性回归一样了，因此多项式回归的训练方法依旧和线性回归一样。需要注意的是，能够选择简单的线性模型时就不要选择相对复杂的多项式模型。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://uscair.club/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://uscair.club/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"author":{"name":"Wonder"}},{"title":"Nao  机器人入门","slug":"NAO机器人（python语言）","date":"2020-02-09T11:28:56.705Z","updated":"2020-02-09T11:28:56.705Z","comments":true,"path":"2020/02/09/NAO机器人（python语言）/","link":"","permalink":"http://uscair.club/2020/02/09/NAO%E6%9C%BA%E5%99%A8%E4%BA%BA%EF%BC%88python%E8%AF%AD%E8%A8%80%EF%BC%89/","excerpt":"","text":"NAO机器人（python语言） 是一种双足人形机器人，58公分高，可以做出各种与人类一样的 肢体语言，通过代码实现了识别语言并根据代码做出相应的回应，能够通过感应器识别物体，与人类互动，NAO提供了一个独立的编程环境（Choregraphe），需要密匙才能激活对应 机器人环境（到时候会帮助你们建立起来）。 NAO机器人是人工智能机器人，嵌入式软件使得NAO可以声音合成，图像识别，行为控制，双通道超声波探测障碍物，以及自身二极管进行视觉效果。 在C++、Python、Choregraphe中，我们是通过编译代码实现对机器人控制实现，多看NAOqi API ,在那之前我们了解一下NAO机器人的基本情况： 1.NAO能够探测前方0.25-2.55m内是否有障碍物，探测角度60°。 2.触摸、按压、划过接触传感器可以出发接触传感器产生电信号，进而完成向机器人输入信息.头部：前中后三个触摸传感器。手部触摸传感器，脚前部的碰撞传感器（也起到缓冲作用）。胸前：长按、短按、连按。开机：按胸前按钮。报IP地址：在开机并且联网状态下，按胸前按钮。关机：在开机状态下，按胸前按钮。自主生活状态：连续按两次胸前按钮进入或退出。 3.测量身体状态以及加速度，包括2个陀螺仪，1个加速度计。4.（MRE磁性编码器）：测量机器人自身关节位置，36个。5.每只脚上有4个压力传感器，用来确定每只脚重心的位置。在行走过程中，NAO根据重心为在进行不太调整以保持身体平衡。6.头部传感器周围：12个LED耳部：2的10次方个16级蓝色LED, 2的8次方个全彩色LED, 胸前按钮和双足各有1个RGB全彩色LED。 使用的坐标系：笛卡尔坐标系，X轴指向身体前方，Y为由右向左方向，Z轴为垂直向上方向。 沿Z轴方向的旋转称为偏转(Yam), 沿Y轴的旋转称为俯仰（Pitch)，沿X轴方向的旋转称为横滚（Roll）。 关节运动范围:头部两个自由度分别控制Nao脑袋的扭转，其中控制头部关节在Z轴扭转的范围为-120°到120°，在Y轴前后运动的范围为-39°到39°；左右手臂各有5个自由度且呈对称分布，肩关节控制Y轴前后运动的范围为-120°到120°，控制Z轴左右运动的范围为0°到95°，肩关节控制在X轴扭转的范围为-90°到0°，肘关节控制在Z轴运动的范围为-120°到120°，腕关节控制在X轴扭转的范围为-105°到105°；Nao的左右手上各有一个自由度，其控制Nao的手部的打开或合拢；Nao左右腿的关节除髋关节和踝关节外其余均呈对称分布的，左髋关节控制腿部在Y轴前后运动的范围为-104.5°到28.5°，左髋关节控制腿部在X轴左右运动的范围为-25°到45°，左踝关节控制在Y轴前后运动的范围为-70.5°到54°，左控制X轴左右运动的范围为-45°到25°，右髋关节控制腿部在Y轴前后运动的范围为-104.5°到28.5°，右髋关节控制腿部在X轴左右运动的范围为-45°到25°，右踝关节控制在Y轴前后运动的范围为-70.5°到54°，右踝关节控制X轴左右运动的范围为-25°到45°；膝关节控制腿部在Y轴运动的范围为-5°到125°；髋部存在一个控制其髋部在Y轴运动的自由度，其运动范围为-65.62°到42.44°。 自由度： 机器人能够独立运动的关节数目称为机器人的运动自由度。头部有两个关节，可以做偏转(Yam)和俯仰（pitch），因此，头部的自由度为2.全身共有26个自由度。 转矩是一种力矩，力矩=力力臂 （N m)堵转转矩和标称转矩反应了电机在启动和政策工作状态下驱动力的大小。堵转转矩是指当电机转速为0时的转矩，如膝关节电机在启动或维持半蹲状态都处于堵转状态。额定转矩是电机可以长期稳定运行的转矩。 主要方法：学习NAOqi API goToPosture(postureName, speed):转到预定义姿势。阻塞调用。getPosture():返回当前姿势名称，如果当前姿势不是预定义姿势，返回unknow。阻塞调用。getPostureList():返回预定义姿势列表。阻塞调用。applayPosture(postureName, speed)：将机器人关节设置为预定义姿势对应的状态（没有中间动作）。阻塞调用。stopMove():停止当前动作。 Nao行走控制主要的三种方式moveTo:使机器人移动到指定位置，阻塞调用。(1).moveTo(x, y, theta), 移动到指定位置。(2)moveTo(x, y, theta, MoveConfig), 按给定的步态参数移动到指定位置。moveConfig为自定义步态参数列表，列表中的内容为步态参数键值对。(3)moveTo(controlPoints)，沿控制点移动到指定位置，controlPoints为控制点列表。(4)moveTo(controlPoints, moveConfig), movetoConfig为自定义步态参数列表。 move:move方法是机器人按指定速度行走,非阻塞调用。 (1)move(x, y, theta), 按指定速度行走，x为绕X方向速度（m/s), theta为绕Z轴旋转角速度(rad/s), 负数表示顺时针转动。非阻塞调用方法，需要time.sleep()延时，延时时间除了行走过程时间外，应还包括机器人走过程的初始化阶段和终止阶段。(2)move(x, y, theata, moveConfig), 按给定的步态参数和指定速度行走。其中x为X方向，moveConfig为自定义步态参数列表可以分别设置左脚和右脚的步态参数。 moveToward:moveToward()方法是机器人按指定速度行走，非阻塞调用方法。(1)moveToward(x, y, theta), 按指定速度行走，其中x为X方向速度，取值范围[-1, 1], theta为绕Z轴旋转速度。(2)moveToward(x, y, moveConfig), 按给定的步态参数、指定速度行走。","categories":[{"name":"NAO","slug":"NAO","permalink":"http://uscair.club/categories/NAO/"}],"tags":[{"name":"NAOqi","slug":"NAOqi","permalink":"http://uscair.club/tags/NAOqi/"}],"author":{"name":"HL"}},{"title":"STM32单片机系列(一)","slug":"STM32-CubMx","date":"2020-02-08T16:00:00.000Z","updated":"2020-02-08T16:00:00.000Z","comments":true,"path":"2020/02/09/STM32-CubMx/","link":"","permalink":"http://uscair.club/2020/02/09/STM32-CubMx/","excerpt":"","text":"介绍STM32CubeMX是一个图形化的工具，也是配置和初始化C代码生成器（STM32 configuration and initialization C code generation），也就是自动生成开发初期关于芯片相关的一些初始化代码。它包含了STM32所有系列的芯片，包含示例和样本（Examples and demos）、中间组件（Middleware Components）、硬件抽象层（Hardwaree abstraction layer）。CubMX对一些开发工程的基本配置提供了很大的帮助，大大减少了编写基础代码所耗费的时间以及精力。内容今天就以点亮LED灯为例通过CubMX来编写相关程序。首先选择对应的芯片类型这里以STM32F407IE为例：其次可以通过对应芯片的用户手册来确定对应的IO口：407对应的是F9,F10俩个IO口（任选其一即可）。)然后就是最重要的时钟配置，时钟是心脏是重中之重。设置了对应时钟源之后可以看到对应的IO口也有所改变 F407 LED的IO挂载在了APB1时钟线上，配置对应的时钟频率 其次就是代码生成的一些配置：选择工程的名字，以及生成的工程文件的类型，这我这里由于我选择的是Keil5所以我选择了MDK-ARM V5然后记得勾选生成外设源文件和头文件的选项最后点击生成代码","categories":[{"name":"单片机","slug":"单片机","permalink":"http://uscair.club/categories/%E5%8D%95%E7%89%87%E6%9C%BA/"}],"tags":[{"name":"STM32","slug":"STM32","permalink":"http://uscair.club/tags/STM32/"}],"author":{"name":"Page"}},{"title":"卷积神经网络（一）","slug":"卷积神经网络（一）","date":"2020-02-08T16:00:00.000Z","updated":"2020-02-08T16:00:00.000Z","comments":true,"path":"2020/02/09/卷积神经网络（一）/","link":"","permalink":"http://uscair.club/2020/02/09/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%80%EF%BC%89/","excerpt":"","text":"一.概念局部感受野（Local Receptive Fields）卷积神经网络则是把每一个隐藏节点只连接到图像的某个局部区域，从而减少参数训练的数量。例如，一张1024×720的图像，使用9×9的感受野，则只需要81个权值参数。对于一般的视觉也是如此，当观看一张图像时，更多的时候关注的是局部。 共享权值(Shared Weights）卷积神经网络卷积层中，神经元对应的权值是相同，共享的权值和偏置也被称作卷积核或滤汲器。 池化（Pooling)通过对图像卷积进行压缩，卷积之后，通过一个下采样过程，来调整图像大小。Lp池化 监督学习根据已有的数据集，知道输入和输出结果之间的关系。根据这种已知的关系，训练得到一个最优的模型。也就是说，在监督学习中训练数据既有特征(feature)又有标签(label)，通过训练，让机器可以自己找到特征和标签之间的联系，在面对只有特征没有标签的数据时，可以判断出标签。 非监督学习我们不知道数据集中数据、特征之间的关系，而是要根据聚类或一定的模型得到数据之间的关系。 二.结构输入层一维卷积神经网络的输入层接收一维或二维数组，其中一维数组通常为时间或频谱采样；二维数组可能包含多个通道；二维卷积神经网络的输入层接收二维或三维数组；三维卷积神经网络的输入层接收四维数组 隐含层由卷积层、池化层和全连接层组成 卷积层~内部包含多个卷积核，功能是对输入数据进行特征提取.上图中间则为卷积核，以下为卷积公式。 池化层在卷积层进行特征提取后，输出的特征图会被传递至池化层进行特征选择和信息过滤。池化层包含预设定的池化函数，其功能是将特征图中单个点的结果替换为其相邻区域的特征图统计量。池化层选取池化区域与卷积核扫描特征图步骤相同，由池化大小、步长和填充控制 。 全连接层~ 卷积神经网络中的全连接层等价于传统前馈神经网络中的隐含层。全连接层位于卷积神经网络隐含层的最后部分，并只向其它全连接层传递信号。特征图在全连接层中会失去空间拓扑结构，被展开为向量并通过激励函数 。按表征学习观点，卷积神经网络中的卷积层和池化层能够对输入数据进行特征提取，全连接层的作用则是对提取的特征进行非线性组合以得到输出，即全连接层本身不被期望具有特征提取能力，而是试图利用现有的高阶特征完成学习目标。在一些卷积神经网络中，全连接层的功能可由全局均值池化（global average pooling）取代 ，全局均值池化会将特征图每个通道的所有值取平均，即若有7×7×256的特征图，全局均值池化将返回一个256的向量，其中每个元素都是7×7，步长为7，无填充的均值池化 。 输出层卷积神经网络中输出层的上游通常是全连接层，因此其结构和工作原理与传统前馈神经网络中的输出层相同。对于图像分类问题，输出层使用逻辑函数或归一化指数函数输出分类标签。在物体识别问题中，输出层可设计为输出物体的中心坐标、大小和分类 。在图像语义分割中，输出层直接输出每个像素的分类结果。","categories":[{"name":"数字图像处理","slug":"数字图像处理","permalink":"http://uscair.club/categories/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}],"tags":[{"name":"CNN","slug":"CNN","permalink":"http://uscair.club/tags/CNN/"}],"author":{"name":"ffffff"}},{"title":"线性回归的几种解法","slug":"机器学习-线性回归","date":"2020-02-08T16:00:00.000Z","updated":"2020-02-08T16:00:00.000Z","comments":true,"path":"2020/02/09/机器学习-线性回归/","link":"","permalink":"http://uscair.club/2020/02/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/","excerpt":"线性回归的几种简单解法总结","text":"线性回归的几种简单解法总结 最小二乘 和 正规方程假设线性回归方程为 $Y = W_0+W_1X1+W_2X_2+….$ 则最小二乘的条件是 $S =\\sum_1^n(y_i-(w_0+w_1x_{1i}+…))^2 = min$ 且 $$\\frac{\\sigma S}{\\sigma x_i} = 0$$ 令$X=\\begin{bmatrix}1&amp;x_1^1&amp;\\cdots&amp;x_n^1\\1&amp;x_1^2&amp;\\cdots&amp;x_n^2\\\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\1&amp;x_1^n&amp;\\cdots&amp;x_n^n\\\\end{bmatrix}$ $Y =\\begin{bmatrix}y_1\\y_2\\\\vdots\\y_n\\end{bmatrix}$ $W=[W_0,W_1,W_2,W_3 ,….]$ 则 $Y=XW^T$ $\\sum_1^n(y_i-(w_0+w_1x_{1i}+…))^2$ $=(XW^T-Y)^T(XW^T-Y)$ $=(WX^T-Y^T)(XW^T-Y)$ $=WX^TXW^T-Y^TXW^T-WX^TY+Y^TY$ 对W求导，可得 $2WX^TX-2Y^TX=0$ $W=(Y^TX)(X^TX)^{-1}$ $W^T=(XX^T)^{-1}X^TY$ 123456# 1 正规方程解法# W = (XTX)-1XTYdef Fun(X, Y): XTY = np.dot(X.T, Y) XTX = np.dot(X.T, X) return np.dot(np.linalg.inv(XTX), XTY) 梯度下降假设函数 $h(X)=w_0+w_1x_1+ …$ 代价函数 $J(W)=\\frac{1}{2n}\\sum_1^n(h(x^i)-y_i)^2$ 梯度下降算法 $w_i=w_i-\\alpha \\frac{J(W)}{\\alpha w_i}$ 其中$\\alpha$为学习率 即为 $w_i = w_i - \\alpha \\frac{1}{n}(h(x^i)-y_i)x_i$ 样例如下: 12345678910111213141516171819202122232425import numpy as np# 数据生成num = 8num_examples = 1000 # 样例数# 真实参数 f(x1,x2,x2,x4) = w0+w1x3+w2x3+w3x3+w4x4true_w = np.random.randint(-10000, 10000, num)X = np.random.randint(-10000, 10000, (num_examples, num))X[:, 0] = 1# Y= XWY = np.dot(X, true_w)# 预置a = 0.000000001W = np.zeros(num)def BP(X, Y): for i in range(X.shape[0]): h = np.dot(X[i], W) for j in range(W.shape[0]): W[j] = W[j] - a *(h-Y[i]) * X[i][j] /num_examplesfor i in range(1000): BP(X,Y)print(\"原: \",true_w )print(\"解: \", W)","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://uscair.club/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"线性回归","slug":"线性回归","permalink":"http://uscair.club/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"}],"author":{"name":"RE9T"}},{"title":"Robocup新手指南","slug":"Robocup新手指南","date":"2020-02-07T16:00:00.000Z","updated":"2020-02-07T16:00:00.000Z","comments":true,"path":"2020/02/08/Robocup新手指南/","link":"","permalink":"http://uscair.club/2020/02/08/Robocup%E6%96%B0%E6%89%8B%E6%8C%87%E5%8D%97/","excerpt":"","text":"初学者该从哪些方面了解1.robocup比赛过程以及相关规则 2.什么是robocup robocup简介RoboCup (Robot World Cup)，即机器人世界杯足球锦标赛。它是国际上一项为提高相关领域的教育和研究水平而举行的大型比赛和学术活动,通过提供一个标准任务来促进分布式人工智能、智能机器人技术、及其相关领域的研究与发展。 server能在server上工作是建立在对SPADES上的，所以接下来主要介绍一下SPADES相关的两点主要内容，即Agent可接收的感觉和动作 感觉感觉信息格式：Stime time data其中第一个time指的是感觉发出的周期，其二个time指的是信息到达agent的周期，data指感觉信息的字符串，值得注意的是一条感觉信息可以包含多种感觉。1.视觉：全方向，所感观物体是透明的，物体位置以相对于agent的极坐标形式给出，坐标参数为（距离，theta，phi）2.competition state即比赛状态：主要提供信息，例如球门球员尺寸,物体质量，时间以及比赛模式，球员号码，球员是左还是右的位置3.agent状态：主要提供自身内部信息，即电池状态和温度4.听觉：可通过听说来相互通讯 动作与感觉一样，通过一些动作来实现agent对环境的作用。每种动作信息以字母”A”开头，后面是字符串。格式：Adatadata包含动作信息Creat：这是agent必须发送的第一个动作。这个动作使得server登录agent并创建与agent的通讯。格式如下： A(create) 类似的还有Init，Beam，Drive，Kick，Catch，Say等，具体内容可点击下方链接查看。 关于3D的具体内容指导","categories":[{"name":"人工智能","slug":"人工智能","permalink":"http://uscair.club/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"robocup","slug":"robocup","permalink":"http://uscair.club/tags/robocup/"}],"author":{"name":"徐雯君"}},{"title":"数字图像处理——拉普拉斯算子【像素级别处理】（python）","slug":"数字图像处理——拉普拉斯算子【像素级别处理】（python）","date":"2020-02-06T12:34:46.135Z","updated":"2020-02-06T12:34:46.135Z","comments":true,"path":"2020/02/06/数字图像处理——拉普拉斯算子【像素级别处理】（python）/","link":"","permalink":"http://uscair.club/2020/02/06/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E7%AE%97%E5%AD%90%E3%80%90%E5%83%8F%E7%B4%A0%E7%BA%A7%E5%88%AB%E5%A4%84%E7%90%86%E3%80%91%EF%BC%88python%EF%BC%89/","excerpt":"","text":"简介：==拉普拉斯算子是一种微分算子常在图像处理中强调灰度值的突变，不强调灰度变换缓慢的地方，得到的图层与原图像叠加在一起可以得到锐化的效果== 一个二维图像的拉普拉斯算子可以定义为$$\\nabla^{2}f=\\frac{\\partial^2 f}{\\partial x^2}+\\frac{\\partial^2 f}{\\partial y^2}$$ 所以:在X方向上存在$$\\frac{\\partial^2 f}{\\partial x}=f(x+1,y)+f(x-1,y)-2f(x,y)$$ 在Y方向上存在$$\\frac{\\partial^2 f}{\\partial y}=f(x,y+1)+f(x,y-1)-2f(x,y)$$ 可得：$$\\nabla^2f=f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)-4f(x,y)$$ 扩展至对角线：$$\\nabla^2f=f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)+f(x-1,y-1)+f(x-1,y+1)+f(x+1,y-1)+f(x+1,y+1)-8f(x,y)$$ 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186import cv2import numpy as npimport matplotlib.pyplot as pltimg = cv2.imread('Fig0338.tif') # 测试图片H = img.shape[0]W = img.shape[1]pixa = np.zeros((H, W), np.int32)mImgae = np.zeros((H, W, 3), np.uint8) # 标定(scale)前的滤波图像smImga = np.zeros((H, W, 3), np.uint8) # 标定(scale)后的滤波图像pixb = np.zeros((H, W), np.int32)mImgbe = np.zeros((H, W, 3), np.uint8) # 标定前的滤波图像smImgb = np.zeros((H, W, 3), np.uint8) # 标定后的滤波图像imga = np.zeros((H, W, 3), np.uint8) # xy方向模板滤波后图像imgb = np.zeros((H, W, 3), np.uint8) # 加上对角方向模板滤波后图像# a用到的算子是 b用到的算子是# 0 1 0 1 1 1# 1 -4 1 1 -8 1# 0 1 0 1 1 1# 先绘制标定滤波图像# 标定指的是最小值设置为0，最大值设置为255的进行归一化的结果for i in range(1, H - 1): for j in range(1, W - 1): pixa[i, j] = int(img[i - 1, j, 0]) + img[i + 1, j, 0] + img[i, j - 1, 0] + img[i, j + 1, 0] - 4 * int( img[i, j, 0]) pixb[i, j] = int(img[i - 1, j - 1, 0]) + img[i - 1, j, 0] + img[i - 1, j + 1, 0] + img[i, j - 1, 0] + img[ i, j + 1, 0] + img[i + 1, j - 1, 0] + img[i + 1, j, 0] + img[i + 1, j + 1, 0] - 8 * int(img[i, j, 0])maxa = 0maxb = 0mina = 255minb = 255for i in range(H): for j in range(W): # 求出像素最大值和最小值，以利于scale if pixa[i, j] &gt; maxa: maxa = pixa[i, j] if pixa[i, j] &lt; mina: mina = pixa[i, j] if pixb[i, j] &gt; maxb: maxb = pixb[i, j] if pixb[i, j] &lt; minb: minb = pixb[i, j] if pixa[i, j] &lt; 0: mImgae[i, j] = [0, 0, 0] else: mImgae[i, j, 0] = pixa[i, j] mImgae[i, j, 1] = pixa[i, j] mImgae[i, j, 2] = pixa[i, j] if pixb[i, j] &lt; 0: mImgbe[i, j] = [0, 0, 0] else: mImgbe[i, j, 0] = pixb[i, j] mImgbe[i, j, 1] = pixb[i, j] mImgbe[i, j, 2] = pixb[i, j]ka = 0kb = 0if maxa &gt; mina: ka = 255 / (maxa - mina)if maxb &gt; minb: kb = 255 / (maxb - minb)# scale处理for i in range(H): for j in range(W): smImga[i, j, 0] = (pixa[i, j] - mina) * ka smImga[i, j, 1] = smImga[i, j, 0] smImga[i, j, 2] = smImga[i, j, 0] smImgb[i, j, 0] = (pixb[i, j] - minb) * kb smImgb[i, j, 1] = smImgb[i, j, 0] smImgb[i, j, 2] = smImgb[i, j, 0]# 加上拉普拉斯算子# pixa和pixb里面就是两个算子的结果# lapa和lapb是原图加算子的结果，用来裁剪或者scale的原始数据lapa = np.zeros((H, W), np.int32)lapb = np.zeros((H, W), np.int32)# 缩放处理# maxa = 0# maxb = 0# mina = 255# minb = 255for i in range(H): for j in range(W): lapa[i, j] = img[i, j, 0] - pixa[i, j] lapb[i, j] = img[i, j, 0] - pixb[i, j] # 裁剪处理 if lapa[i, j] &gt; 255: lapa[i, j] = 255 if lapa[i, j] &lt; 0: lapa[i, j] = 0 if lapb[i, j] &gt; 255: lapb[i, j] = 255 if lapb[i, j] &lt; 0: lapb[i, j] = 0 # 缩放处理 # if lapa[i, j] &gt; maxa: # maxa = lapa[i, j] # if lapa[i, j] &lt; mina: # mina = lapa[i, j] # if lapb[i, j] &gt; maxb: # maxb = lapb[i, j] # if lapb[i, j] &lt; minb: # minb = lapb[i, j]# 缩放处理# ka = 0# kb = 0# if maxa &gt; mina:# ka = 255 / maxa# if maxb &gt; minb:# kb = 255 / maxb# scale处理for i in range(H): for j in range(W): # 裁剪处理 imga[i, j, 0] = lapa[i, j] imga[i, j, 1] = lapa[i, j] imga[i, j, 2] = lapa[i, j] imgb[i, j, 0] = lapb[i, j] imgb[i, j, 1] = lapb[i, j] imgb[i, j, 2] = lapb[i, j] # 缩放处理 # if lapa[i, j] &gt; 0: # imga[i, j, 0] = lapa[i, j] * ka # else: # imga[i, j, 0] = 0 # imga[i, j, 1] = imga[i, j, 0] # imga[i, j, 2] = imga[i, j, 0] # if lapb[i, j] &gt; 0: # imgb[i, j, 0] = lapb[i, j] * kb # else: # imgb[i, j, 0] = 0 # imgb[i, j, 1] = imgb[i, j, 0] # imgb[i, j, 2] = imgb[i, j, 0]# 原图plt.subplot(1, 4, 1)plt.axis('off')plt.title('Original image')plt.imshow(img)# 图3.37a的模板plt.subplot(2, 4, 2)plt.axis('off')plt.title('Before sale a')plt.imshow(mImgae)# scale后图3.37a的模板plt.subplot(2, 4, 3)plt.axis('off')plt.title('After sale a')plt.imshow(smImga)# 图3.37a的模板锐化后的图像plt.subplot(2, 4, 4)plt.axis('off')plt.title('Sharpened Image a')plt.imshow(imga)# 图3.37b的模板plt.subplot(2, 4, 6)plt.axis('off')plt.title('Before sale b')plt.imshow(mImgbe)# scale后图3.37b的模板plt.subplot(2, 4, 7)plt.axis('off')plt.title('After sale b')plt.imshow(smImgb)# 图3.37b的模板锐化后的图像plt.subplot(2, 4, 8)plt.axis('off')plt.title('Sharpened Image b')plt.imshow(imgb)plt.show()","categories":[{"name":"数字图像处理","slug":"数字图像处理","permalink":"http://uscair.club/categories/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}],"tags":[{"name":"拉普拉斯","slug":"拉普拉斯","permalink":"http://uscair.club/tags/%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF/"}],"author":{"name":"Gowi"}},{"title":"吴恩达机器学习第三章【Linear Algebra Revie】（线性代数回顾）","slug":"吴恩达机器学习第三章【Linear Algebra Revie】","date":"2020-02-06T04:58:30.386Z","updated":"2020-02-06T04:58:30.386Z","comments":true,"path":"2020/02/06/吴恩达机器学习第三章【Linear Algebra Revie】/","link":"","permalink":"http://uscair.club/2020/02/06/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%B8%89%E7%AB%A0%E3%80%90Linear%20Algebra%20Revie%E3%80%91/","excerpt":"","text":"Matrices and Vectors【矩阵和向量】在$\\begin{bmatrix}{1402}&amp;{191}\\\\{1371}&amp;{821}\\\\{949}&amp;{1437}\\\\{147}&amp;{1448}\\end{bmatrix}$中，这是一个这个是4×2矩阵，即4行2列，如$m$为行，$n$为列，那么$m×n$即4×2，其中$A_{ij}$指第$i$行，第$j$列的元素。 向量是一种特殊的矩阵，向量一般都是列向量，如：$y=\\left[ \\begin{matrix} {460} \\ {232} \\ {315} \\ {178} \\\\\\end{matrix} \\right]$为四维列向量（4×1）。 Addition and Scalar Multiplication【加法和标量乘法】矩阵的加法：行列数相等的各元素相加。 $\\begin{bmatrix}{1}&amp;{0}\\\\{2}&amp;{5}\\\\{3}&amp;{1}\\end{bmatrix}+\\begin{bmatrix}{4}&amp;{0.5}\\\\{2}&amp;{5}\\\\{0}&amp;{1}\\end{bmatrix}=\\begin{bmatrix}{5}&amp;{0.5}\\\\{4}&amp;{10}\\\\{3}&amp;{2}\\end{bmatrix}$ 矩阵的数乘：每个元素都要乘。 $3\\times\\begin{bmatrix}{1}&amp;{0}\\\\{2}&amp;{5}\\\\{3}&amp;{1}\\end{bmatrix}=\\begin{bmatrix}{3}&amp;{0}\\\\{6}&amp;{15}\\\\{9}&amp;{3}\\end{bmatrix}=\\begin{bmatrix}{1}&amp;{0}\\\\{2}&amp;{5}\\\\{3}&amp;{1}\\end{bmatrix}\\times3$ Matrix Vector Multiplication【矩阵向量乘法】 Matrix Matrix Multiplication【矩阵乘法】矩阵乘法： $m×n$矩阵乘以$n×o$矩阵，变成$m×o$矩阵。 在单变量线性回归中的应用 Matrix Multiplication Properties【矩阵乘法的性质】矩阵乘法的性质： 矩阵的乘法不满足交换律：$A×B≠B×A$ 矩阵的乘法满足结合律。即：$A×(B×C)=(A×B)×C$ 单位矩阵：在矩阵的乘法中，有一种矩阵起着特殊的作用，如同数的乘法中的1,我们称这种矩阵为单位矩阵．它是个方阵，一般用 $I$ 或者 $E$ 表示,从左上角到右下角的对角线（称为主对角线）上的元素均为1以外全都为0 $A{{A}^{-1}}={{A}^{-1}}A=I$ 对于单位矩阵，有$AI=IA=A$ Inverse and Transpose【逆、转置】矩阵的逆：如矩阵$A$是一个$m×m$矩阵（方阵），如果有逆矩阵，则：$A{{A}^{-1}}={{A}^{-1}}A=I$ 矩阵的转置：设$A$为$m×n$阶矩阵（即$m$行$n$列），第$i $行$j $列的元素是$a(i,j)$，即：$A=a(i,j)$ 定义$A$的转置为这样一个$n×m$阶矩阵$B$，满足$B=a(j,i)$，即 $b (i,j)=a(j,i)$（$B$的第$i$行第$j$列元素是$A$的第$j$行第$i$列元素），记${{A}^{T}}=B$。(有些书记为A’=B） ${{\\begin{bmatrix} a& b \\\\ c& d \\\\ e& f \\\\\\end{bmatrix} }^{T}}=\\begin{bmatrix} a&amp; c &amp; e \\ b&amp; d &amp; f \\\\\\end{bmatrix}$ 矩阵的转置基本性质: $ {{\\left( A\\pm B \\right)}^{T}}={{A}^{T}}\\pm {{B}^{T}} $${{\\left( A\\times B \\right)}^{T}}={{B}^{T}}\\times {{A}^{T}}$${{\\left( {{A}^{T}} \\right)}^{T}}=A $${{\\left( KA \\right)}^{T}}=K{{A}^{T}} $","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://uscair.club/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://uscair.club/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"},{"name":"数理基础","slug":"数理基础","permalink":"http://uscair.club/tags/%E6%95%B0%E7%90%86%E5%9F%BA%E7%A1%80/"}],"author":{"name":"Gowi"}},{"title":"吴恩达机器学习第二章【Linear Regression with One Variable】（单变量线性回归）","slug":"Linear Regression with One Variable","date":"2020-02-06T04:58:25.879Z","updated":"2020-02-06T04:58:25.879Z","comments":true,"path":"2020/02/06/Linear Regression with One Variable/","link":"","permalink":"http://uscair.club/2020/02/06/Linear%20Regression%20with%20One%20Variable/","excerpt":"","text":"##Model Representation【模型表示】 在一个房价预测中，我们根据房屋大小的面积来估计房价，诺房屋面积与价格满足以下关系 由图可知为监督学习，诺一种可能的表达方式为：$h_\\theta \\left( x \\right)=\\theta_{0} + \\theta_{1}x$，因为只含有一个特征/输入变量，因此这样的问题叫作单变量线性回归(Linear Regression with One Variable)问题。 图为用单变量线性回归模型来预测面积为1250的房价 我们将要用来描述这个回归问题的标记如下: $m$ 代表训练集中实例的数量 $x$ 代表特征/输入变量 $y$ 代表目标变量/输出变量 $\\left( x,y \\right)$ 代表训练集中的实例 $({{x}^{(i)}},{{y}^{(i)}})$ 代表第$i$ 个观察实例 $h$ 代表学习算法的解决方案或函数也称为假设（hypothesis） Cost Function【代价函数】我们选择的参数决定了我们得到的直线相对于我们的训练集的准确程度，模型所预测的值与训练集中实际值之间的差距（下图中蓝线所指）就是建模误差（modeling error）。 在单变量线性回归中，即使得代价函数(Cost Function) $J \\left( \\theta_0, \\theta_1 \\right) = \\frac{1}{2m}\\sum\\limits_{i=1}^m \\left( h_{\\theta}(x^{(i)})-y^{(i)} \\right)^{2}$最小。 Cost Function - Intuition I【代价函数的直观理解I】 在单变量线性回归中，存在点$(1,1),(2,2),(3,3)$，在$\\theta_0=0$的情况下，表达式为$h(x)=\\theta_1x$来估计 $\\theta_1=1$时： $\\theta_1=\\frac{1}{2}$时： $\\theta_1=0$时： 描绘$J(\\theta_1)-\\theta_1$图得： Cost Function - Intuition II【代价函数的直观理解II】在$J \\left( \\theta_0, \\theta_1 \\right)$、$\\theta_0$与$\\theta_1$的三维图中 可知存在使得$J(\\theta_0,\\theta_1)$最小的$\\theta_0和\\theta_1$ 利用等高图表示 Gradient Descent【梯度下降】梯度下降(Gradient Descent)背后的思想是：开始时我们随机选择一个参数的组合$\\left( {\\theta_{0}},{\\theta_{1}},……,{\\theta_{n}} \\right)$，计算代价函数，然后我们寻找下一个能让代价函数值下降最多的参数组合。我们持续这么做直到找到一个局部最小值（local minimum），因为我们并没有尝试完所有的参数组合，所以不能确定我们得到的局部最小值是否便是全局最小值（global minimum），选择不同的初始参数组合，可能会找到不同的局部最小值。 即$Min\\sum_{\\theta_1、\\theta_2、\\theta_3···\\theta_n}J(\\theta_1,\\theta_2,\\theta_3···\\theta_n)$ 批量梯度下降（batch gradient descent）算法的公式为： 其中$a$是学习率（learning rate），它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大在批量梯度下降中，我们每一次都同时让所有的参数减去学习速率乘以代价函数的导数。其中:=相当于计算机中的赋值号。 Gradient Descent Intuition【梯度下降的直观理解】梯度下降算法如下： ${\\theta_{j}}:={\\theta_{j}}-\\alpha \\frac{\\partial }{\\partial {\\theta_{j}}}J\\left(\\theta \\right)$ 描述：对$\\theta $赋值，使得$J\\left( \\theta \\right)$按梯度下降最快方向进行，一直迭代下去，最终得到局部最小值。其中$a$是学习率（learning rate），它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大 其中$\\frac{\\partial }{\\partial {\\theta_{j}}}J\\left(\\theta \\right)$表示切线的斜率 让我们来看看如果$a$太小或$a$太大会出现什么情况： 如果$a$太小了，即我的学习速率太小，结果就是只能这样像小宝宝一样一点点地挪动，去努力接近最低点，这样就需要很多步才能到达最低点，所以如果$a$太小的话，可能会很慢，因为它会一点点挪动，它会需要很多步才能到达全局最低点。 如图： 如果$a$太大，那么梯度下降法可能会越过最低点，甚至可能无法收敛，下一次迭代又移动了一大步，越过一次，又越过一次，一次次越过最低点，直到你发现实际上离最低点越来越远，所以，如果$a$太大，它会导致无法收敛，甚至发散。 如图： 假设你将${\\theta_{1}}$初始化在局部最低点，在这儿，它已经在一个局部的最优处或局部最低点。结果是局部最优点的导数将等于零，因为它是那条切线的斜率。这意味着你已经在局部最优点，它使得${\\theta_{1}}$不再改变，也就是新的${\\theta_{1}}$等于原来的${\\theta_{1}}$，因此，如果你的参数已经处于局部最低点，那么梯度下降法更新其实什么都没做，它不会改变参数的值。这也解释了为什么即使学习速率$a$保持不变时，梯度下降也可以收敛到局部最低点。 首先初始化我的梯度下降算法，在那个品红色的点初始化，如果我更新一步梯度下降，也许它会带我到这个点，因为这个点的导数是相当陡的。现在，在这个绿色的点，如果我再更新一步，你会发现我的导数，也即斜率，是没那么陡的。随着我接近最低点，我的导数越来越接近零，所以，梯度下降一步后，新的导数会变小一点点。然后我想再梯度下降一步，在这个绿点，我自然会用一个稍微跟刚才在那个品红点时比，再小一点的一步，到了新的红色点，更接近全局最低点了，因此这点的导数会比在绿点时更小。所以，我再进行一步梯度下降时，我的导数项是更小的，${\\theta_{1}}$更新的幅度就会更小。所以随着梯度下降法的运行，你移动的幅度会自动变得越来越小，直到最终移动幅度非常小，你会发现，已经收敛到局部极小值。在梯度下降法中，当我们接近局部最低点时，梯度下降法会自动采取更小的幅度，这是因为当我们接近局部最低点时，很显然在局部最低时导数等于零，所以当我们接近局部最低时，导数值会自动变得越来越小，所以梯度下降将自动采取较小的幅度，这就是梯度下降的做法。所以实际上没有必要再另外减小$a$。 Gradient Descent For Linear Regression【梯度下降的线性回归】 $\\frac{\\partial }{\\partial {{\\theta }_{j}}}J({{\\theta }_{0}},{{\\theta }_{1}})=\\frac{\\partial }{\\partial {{\\theta }_{j}}}\\frac{1}{2m}{{\\sum\\limits_{i=1}^{m}{\\left( {{h}_{\\theta }}({{x}^{(i)}})-{{y}^{(i)}} \\right)}}^{2}}$ $j=0$ 时：$\\frac{\\partial }{\\partial {{\\theta }_{0}}}J({{\\theta }_{0}},{{\\theta }_{1}})=\\frac{1}{m}{{\\sum\\limits_{i=1}^{m}{\\left( {{h}_{\\theta }}({{x}^{(i)}})-{{y}^{(i)}} \\right)}}}$ $j=1$ 时：$\\frac{\\partial }{\\partial {{\\theta }_{1}}}J({{\\theta }_{0}},{{\\theta }_{1}})=\\frac{1}{m}\\sum\\limits_{i=1}^{m}{\\left( \\left( {{h}_{\\theta }}({{x}^{(i)}})-{{y}^{(i)}} \\right)\\cdot {{x}^{(i)}} \\right)}$ 则算法改写成： Repeat { ​ ${\\theta_{0}}:={\\theta_{0}}-a\\frac{1}{m}\\sum\\limits_{i=1}^{m}{ \\left({{h}_{\\theta }}({{x}^{(i)}})-{{y}^{(i)}} \\right)}$ ​ ${\\theta_{1}}:={\\theta_{1}}-a\\frac{1}{m}\\sum\\limits_{i=1}^{m}{\\left( \\left({{h}_{\\theta }}({{x}^{(i)}})-{{y}^{(i)}} \\right)\\cdot {{x}^{(i)}} \\right)}$ ​ } 在梯度下降中会一步步逼近代价函数最小的值","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://uscair.club/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://uscair.club/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"author":{"name":"Gowi"}},{"title":"吴恩达机器学习第一章【Introduction】","slug":"Introduction","date":"2020-02-06T04:58:21.048Z","updated":"2020-02-06T04:58:21.048Z","comments":true,"path":"2020/02/06/Introduction/","link":"","permalink":"http://uscair.club/2020/02/06/Introduction/","excerpt":"","text":"Machine Learning机器学习所研究的主要内容，是关于计算机上从数据中产生“模型”（model）的算法，即“学习算法”（learning algorithm），有了学习算法，我们把经验数据提供给它，它就能基于这些数据产生模型；面对新的情况时，模型会给我们提供相应的判断。其中从数据中学得模型的过程称为称为“训练”（training）或“学习”（learning） 123graph LR机器学习--有标记信息--&gt;监督学习机器学习--无标记信息--&gt;无监督学习 机器学习的目标是使学得的模型能很好的适应于“新样本”，而不是在新样本上工作的好好的，学得的模型适用于新样本的能力，称为“泛化”能力。 Supervised Learning【监督学习】定义：根据已有的数据集，知道输入和输出结果之间的关系。根据这种已知的关系，训练得到一个最优的模型。也就是说，在监督学习中训练数据==既有特征(feature)又有标签(label)==，通过训练，让机器可以自己找到特征和标签之间的联系，在面对只有特征没有标签的数据时，可以判断出标签。 监督学习的分类：回归(Regression）、分类（Classification) 回归问题：针对连续型问题 回归通俗一点就是，对已经存在的点（训练数据）进行分析，拟合出适当的函数模型y=f(x)，这里y就是数据的标签，而对于一个新的自变量x，通过这个函数模型得到标签y。 分类问题：针对离散型问题 Unsupervised Learning【无监督学习】定义：我们不知道数据集中数据、特征之间的关系，而是要根据聚类或一定的模型得到数据之间的关系。 可以这么说，比起监督学习，无监督学习更像是自学，让机器学会自己做事情，是没有标签（label）的。我们只是给定了一组数据，我们的目标是发现这组数据中的特殊结构。例如我们使用无监督学习算法会将这组数据分成两个不同的簇,，这样的算法就叫聚类算法。 Answer : B、C","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://uscair.club/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://uscair.club/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"author":{"name":"Gowi"}},{"title":"博客模板","slug":"博客模板","date":"2020-02-05T16:00:00.000Z","updated":"2020-02-05T16:00:00.000Z","comments":true,"path":"2020/02/06/博客模板/","link":"","permalink":"http://uscair.club/2020/02/06/%E5%8D%9A%E5%AE%A2%E6%A8%A1%E6%9D%BF/","excerpt":"模板格式","text":"模板格式 -— title: 文章标题 date: 2019-08-18 author: &nbsp;&nbsp;name: 作者名 categories: &nbsp;&nbsp;-&nbsp;数字图像处理 #分类 tags: &nbsp;&nbsp;-&nbsp;OpenCV #标签 music: &nbsp;&nbsp;enable: true # true（文章内和文章列表都显示） internal（只在文章内显示） &nbsp;&nbsp;server: netease # netease（网易云音乐）tencent（QQ音乐） xiami（虾米） kugou（酷狗） &nbsp;&nbsp;type: song # song （单曲） album （专辑） playlist （歌单） search （搜索） &nbsp;&nbsp;id: 1321385758 # 歌曲/专辑/歌单 ID mathjax: true #博客内有公式要加上 -— 摘要 &lt;!-- more --&gt; (上为摘要，下为正文) 正文 将需要放大预览的图片用 &lt;fancybox&gt; &lt;\\fancybox&gt; 包含起来。 音乐id获取方法：eg: 网页版网易云搜索歌曲 如图（可能出现：“由于版权问题无法生成外链，建议换一首没有版权限制的”） markdown编辑器：typora 关于markdown加载图片：推荐使用图床(https://zhuanlan.zhihu.com/p/35270383?ivk_sa=1023345p) 填入图床连接 关于markdown数学公式可以使用mathjax(https://www.jianshu.com/p/a0aa94ef8ab2)","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://uscair.club/categories/Hexo/"}],"tags":[{"name":"模板","slug":"模板","permalink":"http://uscair.club/tags/%E6%A8%A1%E6%9D%BF/"}]},{"title":"支持向量机(SVM)","slug":"支持向量机-SVM","date":"2020-01-23T08:16:00.000Z","updated":"2020-01-23T08:16:00.000Z","comments":true,"path":"2020/01/23/支持向量机-SVM/","link":"","permalink":"http://uscair.club/2020/01/23/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA-SVM/","excerpt":"2020/01/23","text":"2020/01/23 支持向量机（Support vector machines）一、简介支持向量机（support vector machines）是一种二分类模型，它的目的是寻找一个超平面来对样本进行分割，分割的原则是间隔最大化，最终转化为一个凸二次规划问题来求解。由简至繁的模型包括： 当训练样本线性可分时，通过硬间隔最大化，学习一个线性可分支持向量机； 当训练样本近似线性可分时，通过软间隔最大化，学习一个线性支持向量机； 当训练样本线性不可分时，通过核技巧和软间隔最大化，学习一个非线性支持向量机； 与逻辑回归和神经网络相比，支持向量机，或者简称SVM，在学习复杂的非线性方程时提供了一种更为清晰，更加强大的方式。 二、SVM 与 Logistic regression逻辑回归预测函数： 现在考虑下我们想要逻辑回归做什么：当 y=1 时， 我们需要预测函数 h(x)≈1, 需要 Z &gt;= 0当 y=0 时， 我们需要预测函数 h(x)≈0, 需要 Z &lt;= 0则对应的代价函数(z = theta.T * x) 当y值不同时，J(z)函数的曲线可大致拟合成一条折线cost(z)。将逻辑回归中J(z)替换为拟合的这条折线cost(z)，我们得到一个新的最小化函数: 加入正则项，再让其在逻辑回归代价函数上面稍加变形，则得到了SVM的函数: 最后有别于逻辑回归输出的概率。在这里，我们的代价函数，当最小化代价函数，获得参数theta时，支持向量机所做的是它来直接预测y的值等于1，还是等于0。 三、SVM人们有时将支持向量机看作是大间距分类器。在训练得到最小化的theta过程中，先忽略参数C和正则项,则theta的变化方向是使得 当 y=1 时, z&gt;= 1 ，当 y=0 时, z&lt;=-1 （而不是逻辑回归中的0) 如果你考察这样一个数据集，其中有正样本，也有负样本，可以看到这个数据集是线性可分的。我的意思是，存在一条直线把正负样本分开。当然有多条不同的直线，可以把正样本和负样本完全分开。 这些决策边界看起来都不是特别好的选择，支持向量机将会选择这个黑色的决策边界，相较于之前我用粉色或者绿色画的决策界。这条黑色的看起来好得多，黑线看起来是更稳健的决策界。在分离正样本和负样本上它显得的更好。数学上来讲，这是什么意思呢？这条黑线有更大的距离，这个距离叫做间距(margin)。 当画出这两条额外的蓝线，我们看到黑色的决策界和训练样本之间有更大的最短距离。然而粉线和蓝线离训练样本就非常近，在分离样本的时候就会比黑线表现差。因此，这个距离叫做支持向量机的间距，而这是支持向量机具有鲁棒性的原因，因为它努力用一个最大间距来分离样本。因此支持向量机有时被称为大间距分类器。 参数C对划分的影响: C较大时，可能会导致过拟合,高方差 C较小时，可能会导致欠拟合,高偏差 例如：当 C较小时会得到黑线，而增大C使得C非常大时，会得到粉色线 关于SVM如何做到大间距分类这里先不解释。 四、核函数许多时候，我们面临的分类问题并不只是线性分类，还会遇到很多无法通过直线进行分隔的分类情况： 我们可以用一系列的新的特征f来替换模型中的每一项。将f代替x来对进行分类。而这个代替的变化函数则叫做核函数。例如： 这是一个高斯核函数(Gaussian Kernel)。其中l为landmark，为数据中的地标，使用数据与地标的距离大小计算用来取新的特征，距离越大获得的f值则越小，当距离为0时，f达到最大为1。例如在坐标中取3个地标: 这样得到的新特征与地标相关系，关联到数据与地标间的欧式距离，而训练出的theta也会通过这个核函数得到复杂的拟合边界。 其中高斯核函数中的参数 sigma 为用户定义的到达率，为核函数跌至0的速率参数 一般实现核函数SVM时使用的地标为整个数据集，即如果训练集有m个样本，则选取m个地标。 两个参数 C 和 sigma 的影响 C较大时，可能会导致过拟合,高方差 C较小时，可能会导致欠拟合,高偏差 sigma 较大时，可能导致低方差，高偏差 （欠拟合） sigma 较小时，可能导致低偏差，高方差 （过拟合） 除了高斯核函数外，还有很多其他的核函数，这里不一一介绍了。 这里只是初步对 SVM 作介绍和一些使用方法，其数学原理将在后续补充。 了解更多人工智能方面欢迎光顾个人博客： 戴挽舟的博客","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://uscair.club/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"AI大数据","slug":"AI大数据","permalink":"http://uscair.club/tags/AI%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"author":{"name":"戴挽舟（BbiHH）","url":"https://戴挽舟.fun"}},{"title":"Hello World","slug":"hello-world","date":"2020-01-13T08:55:07.598Z","updated":"2020-01-13T08:55:07.598Z","comments":true,"path":"2020/01/13/hello-world/","link":"","permalink":"http://uscair.club/2020/01/13/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[{"name":"test","slug":"test","permalink":"http://uscair.club/categories/test/"}],"tags":[{"name":"test","slug":"test","permalink":"http://uscair.club/tags/test/"}]},{"title":"NAO机器人的小记","slug":"NAO机器人的小记","date":"2019-11-09T16:00:00.000Z","updated":"2019-11-09T16:00:00.000Z","comments":true,"path":"2019/11/10/NAO机器人的小记/","link":"","permalink":"http://uscair.club/2019/11/10/NAO%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9A%84%E5%B0%8F%E8%AE%B0/","excerpt":"","text":"joint 摄像机相关参数 APIALAutonomousLife孤立状态solitary任何活动都可以通过ALAutonomousLifeProxy :: switchFocus（）启动。启动交互式Activity将切换到交互状态。在保障和禁用状态可以进入。无法停止自动启动板，其建议的活动将自动聚焦，可能会中断正在运行的活动。 交互状态interactive可以通过ALAutonomousLifeProxy :: switchFocus（）启动交互式活动聚焦新的交互式Activity将重新进入交互状态。孤立活动可能无法启动，这将导致孤立状态强制执行其规则并与用户创建不良生命周期。（这可能在未来发生变化）在保障和禁用状态可入以被输。自动启动板可以启动，它不会强制关注其建议。它不会中断正在运行的Activity。当整个交互活动堆栈退出时，将进入单独状态。当所有人都失去时，互动活动将被强行退出。（这尚未实施） 禁用状态disabled没有Activity可以通过ALAutonomousLifeProxy :: switchFocus（）启动无法启动自动启动板。该保障或交互状态可能无法进入。（可调用ALAutonomousLifeProxy :: setState（）退出此状态） 保护状态safeguard没有Activity可以通过ALAutonomousLifeProxy :: switchFocus（）启动 停止聚焦活动并清除堆栈。基本意识和呼吸服务如果正在运行则会停止。自动启动板已停止。然后处理反射。根据反射的结果，可以重新进入孤立状态。（对于损坏的硬件，机器人不会退出保护状态。对于过热，机器人在充分冷却后退出保护状态。） ALRobotPostureALRobotPostureProxy :: getPostureList std :: vector ALRobotPostureProxy :: getPostureList （） 返回：所有预定义姿势的矢量（名称） ALRobotPostureProxy :: getPosture std :: string ALRobotPostureProxy :: getPosture （） 返回当前预定义姿势的名称。如果当前姿势不在预定义姿势中，则返回“未知”。 ALRobotPostureProxy :: goToPosture bool ALRobotPostureProxy :: goToPosture （const std :: string postureName，const float speed ） 使机器人进入参数中要求的预定义姿势。可以修改移动的速度。移动是“智能的”：它将从机器人的开始姿势开始，并选择所有步骤以达到要求的姿势。这是一个阻塞调用。 ALMotionALMotionProxy :: setStiffnesses void ALMotionProxy :: setStiffnesses （const AL :: ALValue＆ names，const AL :: ALValue＆ stiffnesses ）设置一个或多个关节的刚度。这是一个非阻塞调用。names - 关节，链条，“主体”，“JointActuators”，“接头”或“执行器”的名称。stiffnesses - 零和一之间的一个或多个刚度。 示例：＃显示如何将刚度设置为1.0 。 ＃注意，这样做可能很危险，使用 ＃stiffnessInterpolation方法更安全，该方法需要持续时间参数。 names =’Body’ ＃如果只接收到一个参数，这将应用于所有关节 stiffnesses = 1.0 motionProxy.setStiffnesses(names, stiffnesses) ALMotionProxy :: getStiffnesses) std::vectorALMotionProxy::getStiffnesses(const AL::ALValue&amp; jointName)获取关节或关节组的刚度jointName - 关节，链，“Body”，“JointActuators”，“Joints”或“Actuators”的名称。返回：一个或多个刚度。1.0表示最大刚度。0.0表示最小刚度 ALMotionProxy :: angleInterpolation void ALMotionProxy :: angleInterpolation （const AL :: ALValue＆ names，const AL :: ALValue＆ angleLists，const AL :: ALValue＆ timeLists，const bool＆isAbsolute ）将一个或多个关节插值到目标角度或沿着定时轨迹。这是一个阻塞调用。names– 关节，链条，“主体”，“JointActuators”，“接头”或“执行器”的名称或名称。angleLists - 以弧度表示的角度，角度列表或角度列表列表timeLists - 时间，时间列表或时间列表列表，以秒为单位isAbsolute - 如果为true，则以绝对角度描述运动，否则角度相对于当前角度。 示例：＃显示一个关节的单个目标角度的示例 ＃在1.0秒内将头部偏航插入1.0弧度 names =“HeadYaw” angleLists = 50.0 * almath.TO_RAD timeLists = 1.0 isAbsolute = True motionProxy.angleInterpolation（names，angleLists，timeLists，isAbsolute） ＃显示一个关节的单个轨迹的示例 ＃将头部偏航插入1.0弧度，并在2.0秒内回零 names =“HeadYaw” ＃2角度 angleLists = [30.0 * almath.TO_RAD，0.0] ＃ 2次 timeLists = [1.0,2.0] #后面的时间一定要比原来的大（timeLists = [1.0,1.0] 报错：times must be increasing 所以应该表示的是总的时间 在1s内转30度 在2s内转30度再转回来 即转回的时间也是1s） isAbsolute = True motionProxy.angleInterpolation（names，angleLists，timeLists，isAbsolute） ＃显示多个轨迹的示例 names = [“HeadYaw”，“HeadPitch”] angleLists = [30.0 almath.TO_RAD，30.0 almath.TO_RAD] #左下方 timeLists = [1.0,1.2] #（可以为timeLists = [1.0,1.0]） isAbsolute = True motionProxy.angleInterpolation（names，angleLists，timeLists，isAbsolute） ＃显示多个轨迹的示例 ＃将头部偏航插入1.0弧度，并在2.0秒内回零 ＃在长时间内上下插入HeadPitch。 names = [“HeadYaw”，“HeadPitch”] ＃每个关节可以有不同长度的列表，但数量 ＃角度和每个关节的次数必须相同。 ＃这里，第二个关节（“HeadPitch”）有三个角度，和 ＃三个相应的时间。 angleLists = [[50.0 almath.TO_RAD，0.0]， [-30.0 almath.TO_RAD，30.0 * almath.TO_RAD，0.0]] timeLists = [[1.0,2.0]，[1.0,2.0,3.0]] isAbsolute = True motionProxy.angleInterpolation（names，angleLists，timeLists，isAbsolute） ALMotionProxy :: angleInterpolationWithSpeed) void ALMotionProxy :: angleInterpolationWithSpeed （const AL :: ALValue＆ names，const AL :: ALValue＆targetAngles，const float＆maxSpeedFraction ）使用最大速度的一小部分将一个或多个关节插值到目标角度。每个关节只允许一个目标角度。这是一个阻塞调用。names - 关节，链条，“主体”，“JointActuators”，“接头”或“执行器”的名称或名称。targetAngles - 以弧度表示的角度或角度列表maxSpeedFraction - 一个分数 示例：＃显示一个关节的单个目标的示例 names =“HeadYaw” targetAngles = 1.0 maxSpeedFraction = 0.2＃使用最大关节速度的20％ motionProxy.angleInterpolationWithSpeed（names，targetAngles，maxSpeedFraction） ＃显示多个关节的示例 ＃而不是列出每个关节，您可以使用链名称 #bein扩展为包含链中的所有关节。在这种情况下， ＃“Head”将被解释为[“HeadYaw”，“HeadPitch”] names =“Head” ＃我们仍然需要指定正确的目标角度数 targetAngles = [0.5,0.25] maxSpeedFraction = 0.2＃使用最大关节速度的20％ motionProxy.angleInterpolationWithSpeed（names，targetAngles，maxSpeedFraction） ＃显示体零位置的示例 ＃而不是列出每个关节，您可以使用名称“Body” names =’Body’ ＃我们仍然需要指定正确的目标角度数，所以 ＃我们需要找到这个Nao的关节数量。 ＃这里我们使用getBodyNames方法，它告诉我们所有人 ＃别名“Body”中关节的名称。 ＃我们可以将此列表用于“names”参数。 numJoints = len(motionProxy.getBodyNames(“Body”)) ＃列出正确的长度。所有角度都为零。 targetAngles = [0.0] * numJoints ＃使用最大关节速度的10％ maxSpeedFraction = 0.1 motionProxy.angleInterpolationWithSpeed(names, targetAngles, maxSpeedFraction) ALMotionProxy :: move) void ALMotionProxy :: move （const float＆ x，const float＆ y，const float＆theta，const AL :: ALValue moveConfig ）1方法的重载使机器人以给定的速度移动，以FRAME_ROBOT表示，具有移动配置。这是一个非阻塞调用。x - 沿X轴的速度，以米/秒为单位。向后运动使用负值y - 沿Y轴的速度，以米/秒为单位。使用正值向左移动theta - 绕Z轴的速度，以弧度/秒为单位。使用负值顺时针旋转moveConfig - 具有自定义移动配置的ALValue。 ALMotionProxy :: moveTowardvoid ALMotionProxy :: moveToward （const float＆ x，const float＆ y，const float＆theta，const AL :: ALValue moveConfig ）使机器人以给定的标准化速度移动，以FRAME_ROBOT表示，具有移动配置。这是一个非阻塞调用。 x - 沿X轴标准化，无单位，速度。+1和-1分别对应于前向和后向的最大速度。y - 沿Y轴标准化，无单位，速度。+1和-1分别对应于左右方向上的最大速度。theta-标准化，无单位，绕Z轴的速度。+1和-1分别对应于逆时针和顺时针方向的最大速度moveConfig - 具有自定义移动配置的ALValue。 ＃示例显示moveToward的使用 ＃参数是最大值的分数 ＃这里我们要求全速前进 x = 1.0 y = 0.0 theta = 0.0 frequency = 1.0 motionProxy.moveToward(x, y, theta, [[“Frequency”, frequency]])＃如果我们不发送另一个命令，他将永远移动 ＃让我们让他慢下来（步长），并打开后3秒time.sleep(3) x = 0.5 theta = 0.6motionProxy.moveToward(x, y, theta, [[“Frequency”, frequency]]) ALMotionProxy :: setFootStepsWithSpeed) void ALMotionProxy :: setFootStepsWithSpeed （const std :: vector ＆ legName，const AL :: ALValue＆ footSteps，const std :: vector ＆ fractionMaxSpeed，const bool＆ clearExisting ）仅限NAO使机器人快速地做足步计划器。这是一个阻塞调用。legName - 要移动的腿的名称（’LLeg’or’RLeg’）footSteps - [x，y，theta]，[沿X / Y的位置，Z轴的方向]，相对于另一个腿，以[米，米，弧度]为单位。必须小于[MaxStepX，MaxStepY，MaxStepTheta]fractionMaxSpeed - 每步脚的速度。必须介于0和1之间clearExisting - 清除现有的脚步 ＃小步前进和逆时针用左脚 legName = [“LLeg”] X = 0.04 Y = 0.1 Theta = 0.3 footSteps = [[X, Y, Theta]] fractionMaxSpeed = [1.0] clearExisting = False motionProxy.setFootStepsWithSpeed(legName, footSteps, fractionMaxSpeed, clearExisting) ＃小步前进和逆时针用左脚 legName = [“LLeg”, “RLeg”] X = 0.04 Y = 0.1 Theta = 0.3 footSteps = [[X, Y, Theta], [X, -Y, Theta]] fractionMaxSpeed = [1.0, 1.0] clearExisting = FalsemotionProxy.setFootStepsWithSpeed(legName, footSteps, fractionMaxSpeed, clearExisting) ALMotionProxy :: waitUntilMoveIsFinished void ALMotionProxy :: waitUntilMoveIsFinished （） 等待MoveTask结束：此方法可用于阻止脚本/代码执行，直到完成移动任务。 ALMemoryALMemoryProxy :: getData ALMemoryProxy :: getDataList ALMemoryProxy :: declareEvent ALMemoryProxy :: insertData ALTrackerALTrackerProxy :: getActiveTarget ALTrackerProxy :: getMaximumDistanceDetection ALTrackerProxy::getMode ALTrackerProxy :: getRelativePosition ALTrackerProxy :: isNewTargetDetected ALTrackerProxy::isSearchEnabled ALTrackerProxy :: getTargetPosition ALTrackerProxy::isTargetLost ALTrackerProxy::setTimeOut ALVideoDeviceALVideoDeviceProxy :: getImagesRemote EventsALLandMarkDetection 结果变量的组织方式 ①如果未检测到Naomarks，则变量为空。更确切地说，它是一个零元素的数组（即在python中打印为[]） ②如果检测到N个Naomarks，则变量结构由两个字段组成：[[TimeStampField] [Mark_info_0，Mark_info_1 ,. 。。，Mark_info_N-1]]：A：TimeStampField = [TimeStamp_seconds，Timestamp_microseconds]。该字段是用于执行检测的图像的时间戳。B：Mark_info = [ShapeInfo，ExtraInfo]。对于每个检测到的标记，我们有一个Mark_info字段。B\\1 ShapeInfo = [1，alpha，beta，sizeX，sizeY，heading]。alpha和beta表示Naomark在摄像机角度方面的位置 - sizeX和sizeY是摄像机角度的标记大小 - 航向角描述了Naomark关于机器人头部的垂直轴方向。B\\2 ExtraInfo = [MarkID]。标记ID是写在Naomark上的编号，与其图案相对应。 ALRedBallDetection ALRedBallDetection基于摄像机给出的图像中红色像素的检测。这些像素根据它们与YUV颜色空间中的红色值的距离进行滤波，使用计算的阈值，即使在光照条件变化的情况下也可以进行检测。然后，从所有检测到的红色像素组中，仅保留定义圆形形状的红色像素。当在当前图像上找到一组像素时，将更新ALMemory键redBallDetected。 结果变量的组织形式 TimeStamp：此字段是用于执行检测的图像的时间戳 centerX和centerY是球的中心角度坐标（弧度）角度的原点是图像的中间。centerX 对应于沿Z轴的直接（逆时针）旋转，centerY对应于沿Y轴的直接旋转，如下图所示： sizeX和sizeY是球在角度（弧度）的球“水平和垂直半径 相关名词参考系 FRAME_TORSO：这是附加到机器人的躯干参考上的，因此机器人在走路时随其移动，在他倾斜时改变方向。当您执行非常局部的任务时（在躯干框架的方向上有意义），此空间很有用。 FRAME_ROBOT：这是围绕垂直Z轴投影的两只脚位置的平均值。该空间很有用，因为x轴始终向前，因此提供了一个以自我为中心的自然参考。 FRAME_WORLD：这是一个固定的原点，永远不会改变。当机器人行走时，它会被留下，并且在机器人转动之后z旋转会有所不同。此空间对于需要外部绝对参考框架的计算很有用。 执行任务时，空间是在任务开始时确定的，并且在其余的插值过程中始终保持不变。也就是说，插值一旦定义就不会随着腿的移动或躯干方向的变化而随着参考值的变化而变化。 刚度 阻塞方法与非阻塞方法 Position6DPosition6D是一个6维向量，由3个平移（以米为单位）和3个旋转（以弧度为单位）组成。 基于NAO机器人目标识别与定位算法 选自：柏雪峰,杨斌.基于NAO机器人目标识别与定位算法[J].成都信息工程学院学报,2014,29(06):625-629.","categories":[{"name":"NAO","slug":"NAO","permalink":"http://uscair.club/categories/NAO/"}],"tags":[{"name":"NAOqi","slug":"NAOqi","permalink":"http://uscair.club/tags/NAOqi/"}],"author":{"name":"Gowi"}},{"title":"OpenCV—Python:（二）视频","slug":"OpenCV——Python（二）视频","date":"2019-08-21T09:34:16.000Z","updated":"2019-08-21T09:34:16.000Z","comments":true,"path":"2019/08/21/OpenCV——Python（二）视频/","link":"","permalink":"http://uscair.club/2019/08/21/OpenCV%E2%80%94%E2%80%94Python%EF%BC%88%E4%BA%8C%EF%BC%89%E8%A7%86%E9%A2%91/","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132333435#-*- coding:utf-8 -*-import numpy as npimport cv2 as cv#创建一个VideoCapture对象用于捕获视频，参数：设备索引或视频文件的名称cap=cv.VideoCapture(0) #0：调用电脑内置摄像头#定义编解码器并创建VideoWriter对象fourcc=cv.VideoWriter_fourcc(*\"DIVX\") #定义编码器（windows适用），可以(\"D\",\"I\",\"V\",\"X\")传输，也可以(*\"DIVX\")# &lt;VideoWriter object&gt; = cv.VideoWriter( filename, fourcc, fps, frameSize[, isColor]# filename 输出视频文件的名称。# fourcc 用于压缩帧的4字符编解码器# fps 创建的视频流的帧率。越大，保存的视频播放的越快，反之越慢。# frameSize 视频帧的大小。# isColor 如果它不为零，则编码器将期望并编码彩色帧，否则它将与灰度帧一起使用（该标志目前仅在Windows上受支持），默认值为Trueout=cv.VideoWriter(\"output.avi\",fourcc,50.0,(640,480),0) #True OR False 要与图像每一帧翻转时相对应，翻转灰度图用0，翻转彩图用1或者不填，默认为1'''out=cv.VideoWriter(\"output.avi\",fourcc,50.0,(640,480))'''#录制彩色视频while cap.isOpened(): ret,frame=cap.read() if not ret: print(\"Cannot receive frame (stream end?).Exiting...\") break frame=cv.flip(frame,1)#0图像是倒的，1图像是正的，0时图像原点为左上角，1时图像原点为左下角 gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY) # 将图像从一个颜色空间转换为另一个颜色空间，彩色转灰度 #写下翻转的帧 out.write(gray) '''out.write(frame)''' cv.imshow(\"frame\",frame) #frame显示原来彩图，gray显示变换后的灰度图 if cv.waitKey(1)==ord(\"q\"): #播放视频时，cv.waitKey()括号里的参数控制播放速度，0不播放；录制视频时，cv.waitKey()里的参数越大，捕获视频越慢 break#释放所有内容cap.release()out.release()cv.destroyAllWindows()","categories":[{"name":"数字图像处理","slug":"数字图像处理","permalink":"http://uscair.club/categories/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://uscair.club/tags/OpenCV/"}],"author":{"name":"Adans"}},{"title":"OpenCV—Python:（一）图片的读取、显示、保存","slug":"opencv-read","date":"2019-08-18T09:34:16.000Z","updated":"2019-08-18T09:34:16.000Z","comments":true,"path":"2019/08/18/opencv-read/","link":"","permalink":"http://uscair.club/2019/08/18/opencv-read/","excerpt":"这篇文章描述了使用OpenCV进行图片的读取、显示、保存的方法。","text":"这篇文章描述了使用OpenCV进行图片的读取、显示、保存的方法。 图片的阅读、显示、保存：阅读：cv2.imread(“图片的路径”, 打开方式) 图片路径： 绝对路径：与代码不在同一目录里，写出详细地址，如“E:\\\\Photos\\\\aobing.jpg” 相对路径:代码相同目录中，只需写出图片名即可，如：“ao_bing.jpg” 注：不知道图片路径时，pycharm支持查看：点击图片文件名，单机单击鼠标右键， “Copy Path” 是绝对路径，”Copy Relative Path” 是相对路径! 打开方式： “ 1 “， 默认打开方式，加载彩色图像，任何图像的透明度都将忽略 “ 0 “， 加载灰度图像 “ -1 “，加载图像，包括alpha通道 显示：cv2.imshow(“窗口名称”，图片) 窗口名称：自己命名（不同的窗口使用不同的名称，但可以是同一张图片） 图片：打开图片时自己命名的变量,如 12#img即图片img=cv2.imread(\"ao_bing.jpg\") 保存：cv2.imwrite(“文件名”,要保存的图像) 总结：完整代码如下： 123456789101112131415161718192021222324#-*- coding:utf-8 -*-#也可以 import cv2 as cv ,使用时用cv代替cv2import cv2#宏定义文件名，便于修改filename=\"ao_bing.jpg\" #这里取的是相对路径#读入图片img=cv2.imread(filename) #默认打开，彩色图像img_gray=cv2.imread(filename,0)#灰度图打开，黑白图像#显示图片cv2.imshow(\"Img\",img)cv2.imshow(\"Img_gray\",img_gray)#使图片长时间停留，不闪退cv2.waitKey(0)#保存图片cv2.imwrite(\"ao_bing_gray.jpg\",img_gray)#摧毁所有窗口cv2.destroyAllWindows()","categories":[{"name":"数字图像处理","slug":"数字图像处理","permalink":"http://uscair.club/categories/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://uscair.club/tags/OpenCV/"}],"author":{"name":"Adans"}},{"title":"openCV(色彩通道的分离与合并)","slug":"openCV-色彩通道的分离与合并","date":"2019-08-18T03:36:00.000Z","updated":"2019-08-18T03:36:00.000Z","comments":true,"path":"2019/08/18/openCV-色彩通道的分离与合并/","link":"","permalink":"http://uscair.club/2019/08/18/openCV-%E8%89%B2%E5%BD%A9%E9%80%9A%E9%81%93%E7%9A%84%E5%88%86%E7%A6%BB%E4%B8%8E%E5%90%88%E5%B9%B6/","excerpt":"(原创)","text":"(原创) 本篇来看一下opencv的两个函数 通道cv2.split 和 通道cv2.merge 操作像素直接操作像素来分离通道得到单通道的灰度图 首先了解一下python中获取的图片信息 : 一张图片由[h*w]个像素构成，每个像素点有组成其颜色的参数，事实上就是BGR三通道的分量值 。 1234567891011121314151617#coding=utf-8import cv2import numpy as npfrom matplotlib import pyplot as pltimg = cv2.imread(\"D:\\图片\\Saved Pictures\\qianxun.jpg\",cv2.IMREAD_COLOR)#直接获取图片中通道的值b = img[:,:,0]g = img[:,:,1]r = img[:,:,2]cv2.imshow(\"blue\",b)cv2.imshow(\"green\",g)cv2.imshow(\"red\",r)cv2.waitKey(0) 函数实现通道拆分 cv2.split cv2.split(image) 将图片拆分成 B G R 三个通道(顺序就是为BGR)返回一个单通道的数组 (色彩图片是由三个数组构成，就是BGR三个通道的数组) 1234567891011121314151617#coding=utf-8# 导入库import cv2import numpy as npfrom matplotlib import pyplot as pltimg = cv2.imread(\"D:\\图片\\Saved Pictures\\qianxun.jpg\",cv2.IMREAD_COLOR)#通道分离b,g,r = cv2.split(img)cv2.imshow(\"Original\",img)cv2.imshow(\"Red\", r)cv2.imshow(\"Green\", g)cv2.imshow(\"Blue\", b)cv2.waitKey(0) 输出效果 为黑白灰度的单通道图片 cv2.split 函数分离得到各个通道的灰度值(单通道图像) 通道合并cv2.merge cv2.merge 将表颜色的数组合成构成图片， 参数为 [B,G,R] 若想得到色彩分离的图片(例如:红通道就变成只有红色合成的图片) ，实际上是在多通道下其他通道的分量值变为0。可以通过通道合并再将通道分量值取0。 123456789101112131415161718192021222324#coding=utf-8import cv2import numpy as npfrom matplotlib import pyplot as pltimg = cv2.imread(\"D:\\图片\\Saved Pictures\\qianxun.jpg\",cv2.IMREAD_COLOR)#通道分离b,g,r = cv2.split(img)cv2.imshow(\"Original\",img)cv2.imshow(\"Red\", r)cv2.imshow(\"Green\", g)cv2.imshow(\"Blue\", b)cv2.waitKey(0)# 生成一个值为0的单通道数组zeros = np.zeros(img.shape[:2], dtype = \"uint8\")# 分别扩展B、G、R成为三通道。另外两个通道用上面的值为0的数组填充cv2.imshow(\"blue\", cv2.merge([b, zeros, zeros]))cv2.imshow(\"green\", cv2.merge([zeros, g, zeros]))cv2.imshow(\"red\", cv2.merge([zeros, zeros, r]))cv2.waitKey(0) cv2 中不支持直接创建图片， 要依靠 np里面的初始化函数来生成一个图片数据组 ， 其初始化的数值为 0 。 效果如下 不同灰度图下的图片","categories":[{"name":"openCV","slug":"openCV","permalink":"http://uscair.club/categories/openCV/"},{"name":"图片变化","slug":"openCV/图片变化","permalink":"http://uscair.club/categories/openCV/%E5%9B%BE%E7%89%87%E5%8F%98%E5%8C%96/"}],"tags":[{"name":"Naoqi机器人","slug":"Naoqi机器人","permalink":"http://uscair.club/tags/Naoqi%E6%9C%BA%E5%99%A8%E4%BA%BA/"}],"author":{"name":"BbiHH"}},{"title":"Opencv——Python","slug":"Opencv的一些基操作——Python","date":"2019-08-17T09:23:13.000Z","updated":"2019-08-17T09:23:13.000Z","comments":true,"path":"2019/08/17/Opencv的一些基操作——Python/","link":"","permalink":"http://uscair.club/2019/08/17/Opencv%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9F%BA%E6%93%8D%E4%BD%9C%E2%80%94%E2%80%94Python/","excerpt":"","text":"Opencv——Python首先说一下Opencv是什么：Opencv是一个用图像处理、分析、机器视觉方面的开源数据库，是免费的。 我现在是刚开始学习opencv，而我现在所学习的语言是python语言，在遇到许多问题的时候百度，发现很多案例基本都是用c++写的，而我自己所学的c++没有学很好，所以造成许多需要慢慢探索、慢慢解决的问题。现在我把自己遇到的问题列出来供以后参考。 1.python的程序识别不了中文：通常python程序开头都会写注释 #--coding:utf-8 -- ，但是你可能运行的时候会发现识别不了中文，输出的中文会变成乱码，这是要将这个注释改成 #--coding:cp936 -- 这样就行了，而用opencv调取图片时，如果图片文件名是中文，也有可能识别不了，改成这样同样可以解决问题。2.图片调取代码： 123456789#-*-coding:cp936 -*-import cv2img&#x3D;cv2.imread(&quot;F:\\\\易烊千玺 .jpg&quot;)cv2.namedWindow(&quot;Image&quot;)cv2.imshow(&quot;Image&quot;,img)cv2.waitKey(0)cv2.destroyAllWindows() 运行结果：2.灰度化处理图片。代码： 12gray&#x3D;cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)cv2.imshow(&quot;gray_image&quot;,gray) 承接上一个代码，这样处理图片就会变为灰度图像3.对图像进行灰度变换。先把像素变成一个二维数组，再用函数进行处理代码： 12345678#对灰度图像进行y&#x3D;-x+255g&#x3D;copy.deepcopy(gray)rows&#x3D;img.shape[0]cols&#x3D;img.shape[1]for i in range(rows): for j in range(cols): g[i][j]&#x3D;255-g[i][j]cv2.imshow(&quot;g_image&quot;,g) 4.三色道直方图。代码： 12345678color&#x3D;(&#39;b&#39;,&#39;g&#39;,&#39;r&#39;)def image_hist(image): for i,col in enumerate(color): hist&#x3D;cv2.calcHist([image],[i],None,[256],[0,256]) plt.plot(hist,color&#x3D;col) plt.title(&quot;RGB&quot;) plt.xlim([0,256]) plt.show() 运行结果：这就是三色道直方图。5.灰度直方图。代码： 12plt.hist(gray.ravel(),255,[0,256])plt.show() 6.opencv中的createTrackbar函数。代码： 123456789101112131415161718192021#-*-coding:utf-8 -*-#使用opencv中的creatTrackbar函数来调节一些参数观察图像变化import cv2import numpy as np# 添加新窗口#读入原始图像cv2.namedWindow(&#39;image&#39;)filename &#x3D; &#39;F:\\\\jackson8.jpg&#39;img&#x3D;cv2.imread(filename)def turn(c): num&#x3D;cv2.getTrackbarPos(&quot;num&quot;,&quot;image&quot;) ret,thresh&#x3D; cv2.threshold(img,num,255,cv2.THRESH_BINARY) cv2.imshow(&#39;image&#39;,thresh)cv2.createTrackbar(&#39;num&#39;,&#39;image&#39;, 0,255,turn) # 创建滑块turn(0)cv2.waitKey(0)cv2.destroyAllWindows()","categories":[{"name":"数字图像处理","slug":"数字图像处理","permalink":"http://uscair.club/categories/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://uscair.club/tags/OpenCV/"}],"author":{"name":"You_shuangshuang"}},{"title":"nao机器人的多线程编程","slug":"nao机器人","date":"2019-08-13T09:01:04.000Z","updated":"2019-08-13T09:01:04.000Z","comments":true,"path":"2019/08/13/nao机器人/","link":"","permalink":"http://uscair.club/2019/08/13/nao%E6%9C%BA%E5%99%A8%E4%BA%BA/","excerpt":"","text":"nao机器人的多线程编程首先，我在机器人编程这方面还是小白，不是很懂，如果有错误或者要补充的可以留言哦！ 什么是线程 线程：是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。在Unix System V及SunOS中也被称为轻量进程（lightweight processes），但轻量进程更多指内核线程（kernel thread），而把用户线程（user thread）称为线程。 多线程：是指从软件或者硬件上实现多个线程并发执行的技术。具有多线程能力的计算机因有硬件支持而能够在同一时间执行多于一个线程，进而提升整体处理性能。具有这种能力的系统包括对称多处理机、多核心处理器以及芯片级多处理（Chip-level multithreading）或同时多线程（Simultaneous multithreading）处理器。在一个程序中，这些独立运行的程序片段叫作“线程”（Thread），利用它编程的概念就叫作“多线程处理（Multithreading）”。具有多线程能力的计算机因有硬件支持而能够在同一时间执行多于一个线程（台湾译作“执行绪”），进而提升整体处理性能。 这些都是专业解释，听起来比较抽象，更多的在于运用中去理解。 机器人在执行一个任务的同时，如果只用单线程，那不能同时执行别的任务。要实现nao机器人在走路的同时被摸了前额，机器人就停下来休息，我就遇到了这个问题。 在没有使用多线程的时候，机器人总是一直走下去，或者在刚开始的时候，还没有开始走就摸它的头，它会停下来休息。我本来一直以为是我在API的使用方面不对，后来才意识到机器人可能不能同时执行多个任务。 API上面的事件是可以直接用的，我现在才知道，开始我一直不知道怎么用，就仿照事件上的代码在写，发现又长又容易看 不懂。其实是可以直接用的，这样的代码比较简单。 接下来看实现机器人走路的同时被摸了一下就休息的代码 1234567891011121314151617181920212223242526272829303132# -*-encoding:UTF-8 -*-from nao import ALProxyrobotIP&#x3D;&quot;&quot;PORT&#x3D;9559import argparseimport mathimport threadingmotion&#x3D;ALProxy(&quot;ALMotion&quot;,robotIP,PORT)posture&#x3D;ALProxy(&quot;ALRobotPosture&quot;,robotIP,PORT)memory&#x3D;ALProxy(&quot;ALMemory&quot;,robotIP,PORT)config&#x3D;[] #这里可以自己设定参数def move(): motion.wakeUP() posture.goToPosture(&quot;StandInit&quot;,0.5) motion.moveTo(1.0,0.0,0.0,config)def Touch(): while Ture: front&#x3D;memory.getData(&quot;FrontTactilTouched&quot;) if front&#x3D;&#x3D;1: motion.rest() breakif _name_&#x3D;&quot;_main_&quot;: t1&#x3D;threading.Thread(target&#x3D;move) t2&#x3D;threading.Thread(target&#x3D;Touch) t1.start() t2.start() t1.join() t2.join() 这就是一个多线程编程","categories":[{"name":"NAO","slug":"NAO","permalink":"http://uscair.club/categories/NAO/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://uscair.club/tags/Python/"},{"name":"多线程","slug":"多线程","permalink":"http://uscair.club/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"author":{"name":"You_shuangshuang"}},{"title":"Python学习笔记","slug":"学习python的心得（1） (1)","date":"2019-08-09T03:41:43.000Z","updated":"2019-08-09T03:41:43.000Z","comments":true,"path":"2019/08/09/学习python的心得（1） (1)/","link":"","permalink":"http://uscair.club/2019/08/09/%E5%AD%A6%E4%B9%A0python%E7%9A%84%E5%BF%83%E5%BE%97%EF%BC%881%EF%BC%89%20(1)/","excerpt":"","text":"python与c和c++数据类型之间的比较这是我第一次自己写博客，在学长的强烈推荐之下，我开始写自己的博客，由于我还是刚刚开始学习python,所以有什么错误欢迎大家指出，希望自己和大家一起进步。 c语言的数据类型1.基本类型 （1）数值类型 a.整型 1).短整型short 2).整型int 3).长整型long b.浮点型 1).单精度型float 2).双精度型double (2）字符串类型char 2.构造类型 （1）数组 （2）结构体struct （3）共用体union （4）枚举类型enum 3.指针类型 4.空类型void c++的数据类型 这里与c相比新增了布尔型（bool）和类（class） python的数据类型整数浮点数字符串布尔值空值此外，python还提供了列表(list)、元组(tuple)、字典(dict)/集合(set),这四种数据类型属于集合类型。 list、tuple、dict、set属于python中新增的数据类型。下面单独介绍这些数据类型。 list(列表):list是一种有序的集合，可以随时添加和删除其中的元素 123&gt;&gt;&gt;names&#x3D;[&#39;Mike&#39;,&#39;Bob&#39;,&#39;Lisa&#39;]&gt;&gt;&gt;names[&#39;Mike&#39;,&#39;Bob&#39;,&#39;Lisa&#39;] 这就是一个列表 可以用len()可以获得list元素的个数用索引可以访问list中每一个元素的位置，如果你想访问列表中第一个元素，则可以用 12&gt;&gt;&gt;names[0]&#39;Mike&#39; 以此类推,当超过了索引范围就会报错。想要把元素插入到指定位置用names.insert(n,’Nini’),n为指定位置的编号。要删除list末尾的元素，用pop()方法。要删除list指定位置的元素，用pop(n)的方法，n为指定位置的编号。要把某个元素替换成别的元素，可以直接赋值给对应的索引位置。list中可以包含其他的list,就像一个二维数组一样，以此类推，就不细说了。 tuple(元组)tuple与list类似，只是tuple一旦初始化就不能修改，tuple的写法只是把list的[ ]改成了( )。用以上的例子做说明 123&gt;&gt;&gt;names&#x3D;（&#39;Mike&#39;,&#39;Bob&#39;,&#39;Lisa&#39;)&gt;&gt;&gt;names(&#39;Mike&#39;,&#39;Bob&#39;,&#39;Lisa&#39;) 这就是一个元组，但是不能用上面list的方法来修改里面的元素。 只有一个元素的tuple需要加一个逗号，列如：L(1,) ,不加逗号会造成误解。 dict(字典)使用键-值（key-value）存储，具有极快的查找速度。再次用上面的例子加上身高举例： 123&gt;&gt;&gt;names&#x3D;&#123;&#39;Mike&#39;:175,&#39;Bob&#39;:171,&#39;Lisa&#39;:158&#125;&gt;&gt;&gt;names[&#39;Mike&#39;]175 这就是一个dict，姓名与身高一一对应，dict用{ }表示。想要在dict中增加数据，可以通过key放入，例如：names[‘Nini’]=162 ,这个数据就会放入names这个dict。由于一个key只能对应一个value，所以，多次对一个key放入value，后面的值会把前面的值冲掉。list和dict都可以查找数据，但有不同的特点：list:查找和插入的时间会随着元素的增加而增加，但是占用空间小，浪费内存少。dict:查找和插入速度很快，不受影响，但要占用大量内存，浪费多。 set(集合)set和dict类似，但是set不储存value.要创建一个set，需要提供一个list作为输入集合，例如： 123&gt;&gt;&gt;names&#x3D;set([&#39;Mike&#39;,&#39;Bob&#39;,&#39;Lisa&#39;])&gt;&gt;&gt;namesset([&#39;Mike&#39;,&#39;Bob&#39;,&#39;Lisa&#39;]) 这就是一个set 重复元素在set中可以自动被过滤。想要在set中增加元素，可以用add(key)的方法。例如：names.add(‘Nini’)。想要删除元素，可以用remove(key)的方法，例如：names.remove(‘Nini’)。set可以看成数学意义上的无序和无重复元素的集合，因此，两个set可以做数学意义上的交集、并集等。set和dict的唯一区别仅在于没有存储对应的value，但是，set的原理和dict一样，所以，同样不可以放入可变对象，因为无法判断两个可变对象是否相等，也就无法保证set内部“不会有重复元素”。","categories":[{"name":"Naoqi","slug":"Naoqi","permalink":"http://uscair.club/categories/Naoqi/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://uscair.club/tags/Python/"}],"author":{"name":"You_shuangshuang"}}]}