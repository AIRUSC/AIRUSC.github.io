<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  <title>从Lentet-5看CNN | AIR</title>
  
  <meta name="keywords" content="AI ,NAO ,Scientific Research">
  
  
  <meta name="description" content="AIR">
  

  
  <link rel="alternate" href="/atom.xml" title="AIR">
  

  <meta name="HandheldFriendly" content="True" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <!-- meta -->
  

  <!-- link -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.css">
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.10.1/css/all.min.css">
  

  

  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@19.11.26/css/style.css">

  

  <script>
    function setLoadingBarProgress(num) {
      document.getElementById('loading-bar').style.width=num+"%";
    }
  </script>

  
  
  <script>(function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/e92a8350.js","daovoice")</script>

	<meta charset="UTF-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0" />
	<meta http-equiv="X-UA-Compatible" content="ie=edge" />
	<title>Document</title>
	<style type="text/css">
		canvas {
		  position: fixed;
		  right: 0px;
		  bottom: 0px;
		  min-width: 100%;
		  min-height: 100%;
		  height: auto;
		  width: auto;
		  z-index: -1;
		}
	</style>
<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="AIR" type="application/atom+xml">
</head>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">

    <!-- The loading of KaTeX is deferred to speed up page rendering -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>

    <!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>

<body>
  
  
  <div class="cover-wrapper">
    <cover class='cover post half'>
      
        
  <h1 class='title'>AIR</h1>


  <div class="m_search">
    <form name="searchform" class="form u-search-form">
      <input type="text" class="input u-search-input" placeholder="" />
      <i class="icon fas fa-search fa-fw"></i>
    </form>
  </div>

<div class='menu navgation'>
  <ul class='h-list'>
    
      
        <li>
          <a class="nav home" href="/"
            
            
            id="home">
            <i class='fas fa-rss fa-fw'></i>&nbsp;博文
          </a>
        </li>
      
        <li>
          <a class="nav home" href="/projects/"
            
            
            id="projects">
            <i class='fas fa-code-branch fa-fw'></i>&nbsp;项目
          </a>
        </li>
      
        <li>
          <a class="nav home" href="/about/"
            
              rel="nofollow"
            
            
            id="about">
            <i class='fas fa-info-circle fa-fw'></i>&nbsp;关于
          </a>
        </li>
      
    
  </ul>
</div>

      
    </cover>
    <header class="l_header pure">
  <div id="loading-bar-wrapper">
    <div id="loading-bar" class="pure"></div>
  </div>

	<div class='wrapper'>
		<div class="nav-main container container--flex">
      <a class="logo flat-box" href='/' >
        
          AIR
        
      </a>
			<div class='menu navgation'>
				<ul class='h-list'>
          
  					
  						<li>
								<a class="nav flat-box" href="/"
                  
                  
                  id="home">
									<i class='fas fa-grin fa-fw'></i>&nbsp;示例
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/archives/"
                  
                    rel="nofollow"
                  
                  
                  id="archives">
									<i class='fas fa-archive fa-fw'></i>&nbsp;归档
								</a>
							</li>
      			
      		
				</ul>
			</div>

			
				<div class="m_search">
					<form name="searchform" class="form u-search-form">
						<input type="text" class="input u-search-input" placeholder="Search" />
						<i class="icon fas fa-search fa-fw"></i>
					</form>
				</div>
			
			<ul class='switcher h-list'>
				
					<li class='s-search'><a class="fas fa-search fa-fw" href='javascript:void(0)'></a></li>
				
				<li class='s-menu'><a class="fas fa-bars fa-fw" href='javascript:void(0)'></a></li>
			</ul>
		</div>

		<div class='nav-sub container container--flex'>
			<a class="logo flat-box"></a>
			<ul class='switcher h-list'>
				<li class='s-comment'><a class="flat-btn fas fa-comments fa-fw" href='javascript:void(0)'></a></li>
        
          <li class='s-toc'><a class="flat-btn fas fa-list fa-fw" href='javascript:void(0)'></a></li>
        
			</ul>
		</div>
	</div>
</header>
	<aside class="menu-phone">
    <header>
		<nav class="menu navgation">
      <ul>
        
          
            <li>
							<a class="nav flat-box" href="/"
                
                
                id="home">
								<i class='fas fa-clock fa-fw'></i>&nbsp;回到主页
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/archives/"
                
                  rel="nofollow"
                
                
                id="archives">
								<i class='fas fa-archive fa-fw'></i>&nbsp;文章归档
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="https://xaoxuu.com/wiki/material-x/"
                
                  rel="nofollow"
                
                
                id="https:xaoxuu.comwikimaterial-x">
								<i class='fas fa-book fa-fw'></i>&nbsp;主题文档
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/about/"
                
                  rel="nofollow"
                
                
                id="about">
								<i class='fas fa-info-circle fa-fw'></i>&nbsp;关于小站
							</a>
            </li>
          
       
      </ul>
		</nav>
    </header>
	</aside>
<script>setLoadingBarProgress(40);</script>

  </div>


  <div class="l_body">
    <div class='body-wrapper'>
      <div class='l_main'>
  

  <article id="post" class="post white-box article-type-post" itemscope itemprop="blogPost">
    


  <section class='meta'>
    
      
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.7.0/dist/APlayer.min.css">
  <div class="aplayer"
    data-theme=""
    data-mini=true 
    
    data-mode="circulation"
    data-server="netease"
    data-type="playlist"
    data-id="2615636388"
    data-volume="0.7">
  </div>
  <script src="https://cdn.jsdelivr.net/npm/aplayer@1.7.0/dist/APlayer.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/meting@1.1.0/dist/Meting.min.js"></script>


    
    
    <div class="meta" id="header-meta">
      
        
  
    <h1 class="title">
      <a href="/2020/03/15/%E4%BB%8ELentet-5%E7%9C%8BCNN/">
        从Lentet-5看CNN
      </a>
    </h1>
  


      
      <div class='new-meta-box'>
        
          
        
          
            
  <div class='new-meta-item author'>
    
      <a href="/" rel="nofollow">
        
          <i class="fas fa-user" aria-hidden="true"></i>
        
        <p>Gowi</p>
      </a>
    
  </div>


          
        
          
            <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt" aria-hidden="true"></i>
    <p>2020-03-15</p>
  </a>
</div>

          
        
          
            
  
  <div class='new-meta-item category'>
    <a href='/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/' rel="nofollow">
      <i class="fas fa-folder-open" aria-hidden="true"></i>
      <p>神经网络</p>
    </a>
  </div>


          
        
          
            
  
    <div class="new-meta-item browse busuanzi">
      <a class='notlink'>
        <i class="fas fa-eye" aria-hidden="true"></i>
        <p>
          <span id="busuanzi_value_page_pv">
            <i class="fas fa-spinner fa-spin fa-fw" aria-hidden="true"></i>
          </span>
        </p>
      </a>
    </div>
  


          
        
          
            
  
    <div class="new-meta-item wordcount">
      <a class='notlink'>
        <i class="fas fa-keyboard" aria-hidden="true"></i>
        <p>字数统计:</p>
        <p>4.5k字</p>
      </a>
    </div>
    <div class="new-meta-item readtime">
      <a class='notlink'>
        <i class="fas fa-hourglass-half" aria-hidden="true"></i>
        <p>阅读时长≈</p>
        <p>18分</p>
      </a>
    </div>
  

          
        
          
            

          
        
      </div>
      
        <hr>
      
    </div>
  </section>


    <section class="article typo">
      <div class="article-entry" itemprop="articleBody">
        <h2 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h2><p>首先我们用一个$3 \times 3$的核对一个$6 \times 6$的矩阵进行卷积运算，会得到一个$4 \times 4$的矩阵</p>
<p><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/20200217200522.png" alt=""></p>
<p><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/20200217200745.png" alt=""></p>
<p>我们把核映射到矩阵上对应相乘相加，比如$4 \times 4$矩阵的第一个元素-5</p>
<p><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/20200217200937.png" alt=""></p>
<p>但是我们也得知卷积会使矩阵变小</p>
<p>其中在tensorflow中可以使用<code>tf.nn.conv2d()</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.conv2d(</span><br><span class="line">    input,</span><br><span class="line">    filters,</span><br><span class="line">    strides,</span><br><span class="line">    padding,</span><br><span class="line">    data_format=<span class="string">'NHWC'</span>,</span><br><span class="line">    dilations=<span class="literal">None</span>,</span><br><span class="line">    name=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>其中卷积可以用于边缘检测，如图</p>
<p><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/20200217202921.png" alt=""></p>
<p>因为$3\times3$的矩阵太小使用边缘比较粗</p>
<p>由此可见上面的卷积都使原图像的大小变小了，为了使大小不变，我们使用了提高padding（即在原图像边缘填充像素）</p>
<p>设源图像大小为$n \times n$,卷积核为$f \times f$，padding为p，所以卷积后图像大小为$[(n+2p-f+1) \times (n+2p-f+1)]$。</p>
<p>同时我们引入步长这一个概念（即卷积核每次移动的单位长度）。</p>
<p><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/20200224135351.png" alt=""></p>
<p>设源图像大小为$n \times n$,卷积核为$f \times f$，padding为p，步长为s，所以卷积后图像大小为$[(\frac{n+2p-f}{s}+1) \times (\frac{n+2p-f}{s}+1)]$。</p>
<p>如果第L层是卷积层：</p>
<p>其中：</p>
<p>$f^{[l]}$:卷积核大小</p>
<p>$p^{[l]}$:填充大小</p>
<p>$s^{[l]}$:步长大小</p>
<p>$n^{[l]}_c$:卷积层数目</p>
<p>输入：$n^{[l-1]}_H\times n^{[l-1]}_W\times n^{[l-1]}_c$</p>
<p>输出:$n^{[l]}_H\times n^{[l]}_W\times n^{[l]}_c$</p>
<p>每个卷积核 :$f^{[l]}\times f^{[l]}\times f_c^{[l-1]}$</p>
<p>激活函数:$a^{[l]}\to n^{[l]}_H\times n^{[l]}_W\times n^{[l]}_c$</p>
<p>权重:$f^{[l]}\times f^{[l]}\times n_c^{[l-1]}\times n_c^{[l-1]}$</p>
<p>偏差：$n_c^{[l]}-(1,1,1,n_c^{[l]})$</p>
<p><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/20200224170921.png" alt=""></p>
<h2 id="卷积神经网络的结构"><a href="#卷积神经网络的结构" class="headerlink" title="卷积神经网络的结构"></a>卷积神经网络的结构</h2><p>一般卷积神经网络是由输入层、卷积层、激活层、池化层、全连接层、输出层组成</p>
<h3 id="输入层"><a href="#输入层" class="headerlink" title="输入层"></a>输入层</h3><p>输入层要进行数据的预处理，比如去均值、归一化、PCA/SVD降维等</p>
<h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><p>卷积层主要通过对每一个局部感知，然后更高层次的局部感知，最终得到全局信息。</p>
<p>其中卷积有两个大杀器一个是局部感知野，另一个是权值共享。</p>
<h4 id="局部感知野"><a href="#局部感知野" class="headerlink" title="局部感知野"></a>局部感知野</h4><p>如果我们有1000x1000像素的图像，有1百万个隐层神经元，那么他们全连接的话（每个隐层神经元都连接图像的每一个像素点），就有1000x1000x1000000=10^12^个连接，也就是10^12^个权值参数。</p>
<p>图像的空间联系也是局部的像素联系较为紧密，而距离较远的像素相关性则较弱。因而，每个神经元其实没有必要对全局图像进行感知，只需要对局部进行感知，然后在更高层将局部的信息综合起来就得到了全局的信息。图像的空间联系是局部的，就像人是通过一个局部的感受野去感受外界图像一样，每一个神经元都不需要对全局图像做感受，每个神经元只感受局部的图像区域，然后在更高层，将这些感受不同局部的神经元综合起来就可以得到全局的信息了</p>
<p>假如局部感受野是10x10，就有10x10x1000000=10^8^个连接减少了4个数量级，也就是减少了4个数量级的参数</p>
<p><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/20200313134349.png" alt=""></p>
<h4 id="权值共享"><a href="#权值共享" class="headerlink" title="权值共享"></a>权值共享</h4><p>假如使用一个卷积层，参数都是一样的，那只能提取一个特征了，我们总需要提取多个特征的啊，那我们就加多个卷积，每个卷积层不同。那么隐层的神经元个数怎么确定呢？它和原图像，也就是输入的大小（神经元个数）、滤波器的大小和滤波器在图像中的滑动步长都有关。</p>
<h3 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h3><ol>
<li>降维，减少网络要学习的参数数量</li>
<li>防止过拟合</li>
<li>扩大感受野</li>
<li>实现不变性（平移、旋转、尺度不变性）</li>
</ol>
<h2 id="Lenet-5"><a href="#Lenet-5" class="headerlink" title="Lenet-5"></a>Lenet-5</h2><p>下面我们从著名的神经网络Lenet-5来看卷积</p>
<p><a href="https://ieeexplore.ieee.org/abstract/document/726791" target="_blank" rel="noopener">paper地址</a></p>
<p><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/20200313111602.png" alt=""></p>
<p><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/20200313172945.png" alt=""></p>
<p>效果图：</p>
<p><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/asamples.gif" alt=""></p>
<p><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/legend-bottom.gif" alt=""></p>
<p>上图包含输入层总共8层网络，分别为：输入层（INPUT）、卷积层（Convolutions,C1）、池化层（Subsampling，S2）、卷积层（C3）、池化层（Subsampling，S4）、卷积层（C5）、全连接层（F6）、输出层（径向基层）</p>
<p>卷积和子采样过程：卷积过程包括：用一个可训练的滤波器fx去卷积一个输入的图像（第一阶段是输入的图像，后面的阶段就是卷积特征map了），然后加一个偏置bx，得到卷积层Cx。子采样过程包括：每邻域四个像素求和变为一个像素，然后通过标量Wx+1加权，再增加偏置bx+1，然后通过一个sigmoid激活函数，产生一个大概缩小四倍的特征映射图Sx+1。</p>
<p>我们输入32x32的图像经过6通道的5x5的卷积后，特征图为28x28，其中C1的训练参数个数是(5x5+1)x6=156，连接数是156x(28x28)=122304。其中5x5是卷积核大小为5x5，+1个偏置单元，6个通道。</p>
<p>其中S2是一个下采样层，利用图像局部相关性的原理，对图像进行子抽样，可以减少数据处理量同时保留有用信息，其中C1通过下采样层得到一个14x14的特征图，其中14x14的特征图的每一个单元与C1中的与之相对应的2x2的邻域有关。C1层每个单元的4个输入相加，乘以一个可训练参数，再加上一个可训练偏置。结果通过sigmoid函数计算。如果系数比较小，那么运算近似于线性运算，亚采样相当于模糊图像。如果系数比较大，根据偏置的大小亚采样可以被看成是有噪声的“或”运算或者有噪声的“与”运算。每个单元的2x2感受野并不重叠，因此S2中每个特征图的大小是C1中特征图大小的1/4（行和列各1/2）。其中S2的训练参数是(1x1+1)x6=12，连接数是(2x2+1)x6x(14x14)=5880</p>
<p>用一个16通道的5x5的卷积核去卷积S2可以得到C3，其大小为10x10的16通道的一个特征图，其中C3中的每个特征map是连接到S2中的所有6个或者几个特征map的，表示本层的特征map是上一层提取到的特征map的不同组合。</p>
<p><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/20200315093709.png" alt=""></p>
<p>如上图，横向的数表示卷积层C3的特征平面，纵向表示池化层的6个采样平面，我们以卷积层C3的第0号特征平面为例，它对应了池化层的前三个采样平面即0,1,2，三个平面使用的是三个卷积核（每个采样平面是卷积核相同，权值相等，大小为5x5）,既然对应三个池化层平面，那么也就是说有5x5x3个连接到卷积层特征平面的一个神经元，因为池化层所有的样本均为14x14的，而卷积窗口为5x5的，因此卷积特征平面为10x10（大家可按照第一个卷积计算求的）。只是这里的卷积操作要更复杂，他不是所有的都是特征平面对应三个池化层平面，而是变化的，从上图我们可以清楚的看到前6个特征平面对应池化层的三个平面即0,1,2,3,4,5 ， 而6~14每张特征平面对应4个卷积层，此时每个特征平面的一个神经元的连接数为5x5x4，最后一个特征平面是对应池化层所有的样本平面，</p>
<p>连接数： (5x5x3+1)x10x10x6+(5x5x4+1)x10x10x9+(5x5x6+1)x10x10 = 45600+90900+15100=151600</p>
<p>权值数： (5x5x3+1)x6 + (5x5x4+1)x9 + 5x5x6+1  = 456 + 909+151 = 1516</p>
<p>S4层是一个下采样层，由16个5x5大小的特征图构成。特征图中的每个单元与C3中相应特征图的2x2邻域相连接，跟C1和S2之间的连接一样。S4层有(1x1+1)x16=32个可训练参数（每个特征图1个因子和一个偏置）和(2x2+1)x16x(5x5)=2000个连接。</p>
<p><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/2A213DB7AC18701508AD8F879C425B43.jpg" alt=""></p>
<p>原因有两方面：采用非连接的方案将连接数保持在合理的范围内，而且破坏了神经网络的对称性（我也没太理解清楚。。。）</p>
<p>C5是卷积层。。。</p>
<p><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/20200314182451.png" alt=""></p>
<p>好像是用一个120个通道的5x5的卷积核与S4做卷积，正好构成全连接的关系。（以上是个人猜测）</p>
<p>目前我也没搞懂。。。先留着</p>
<p>F6有84个单元，因为在计算机中字符的编码是ASCII编码，这些图是用7x12大小的位图表示的，也就是高宽比为7:12，如下图，选择这个大小可以用于对每一个像素点的值进行估计。</p>
<p><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/20200314230357.png" alt=""></p>
<p>这一层其实就是BP网络的隐层，且为全连接层，即这一层有84个神经元，每一个神经元都和上一次的120个神经元相连接，那么连接数为(120+1)x84 = 10164,因为权值不共享，隐层权值数也是10164，至于为什么隐层是84个神经元稍后解释，本层的输出有激活函数，激活函数为双曲正切函数：<br><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/20200315114304.png" alt=""></p>
<p> 根据论文解释：A的幅值，S是原点处的倾斜率，A的经验值是1.7159，原因没说。</p>
<p>输出层：有10个输出，对应0-9的数字</p>
<p>首先大家应该明白什么是径向基神经网络，他基于距离进行衡量两个数据的相近程度的，RBF网最显著的特点是隐节点采用输人模式与中心向量的距离（如欧氏距离）作为函数的自变量，并使用径向基函数（如函数）作为激活函数。径向基函数关于N维空间的一个中心点具有径向对称性，而且神经元的输人离该中心点越远，神经元的激活程度就越低。上式是基于欧几里得距离，怎么理解那个式子呢？就是说F6层为84个输入用$x_j$表示，而输出有10个用$y_i$表示，而权值使用$w_{ji}$表示，上式说明所有输入和权值的距离平方和为依据判断，如果越相近距离越小，输出越小则去哪个，如果我们存储的到$w_{ji}$的值为标准的输出，如标准的手写体0,1,2,3等，那么最后一层就说明。F6层和标准的作比较，和标准的那个图形越相似就说明就越是那个字符的可能性更大。</p>
<h2 id="卷积神经网络关于感受野的计算"><a href="#卷积神经网络关于感受野的计算" class="headerlink" title="卷积神经网络关于感受野的计算"></a>卷积神经网络关于感受野的计算</h2><h3 id="什么是感受野"><a href="#什么是感受野" class="headerlink" title="什么是感受野"></a>什么是感受野</h3><p>在计算机视觉领域的深度神经网络中有一个概念叫做感受野，用来表示网络内部的不同位置的神经元对原图像的感受范围的大小。</p>
<blockquote>
<p>白话版：<strong>感受野（Receptive Field），指的是神经网络中神经元“看到的”输入区域，在卷积神经网络中，feature map上某个元素的计算受输入图像上某个区域的影响，这个区域即该元素的感受野。</strong></p>
</blockquote>
<p>神经元之所以无法对原始图像的所有信息进行感知，是因为在这些网络结构中普遍使用卷积层和pooling层，在层与层之间均为局部相连（通过sliding filter）。神经元感受野的值越大表示其能接触到的原始图像范围就越大，也意味着他可能蕴含更为全局、语义层次更高的特征；而值越小则表示其所包含的特征越趋向于局部和细节。因此感受野的值可以大致用来判断每一层的抽象层次。</p>
<p><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/20200303183041.png" alt=""></p>
<p>可以看到在Conv1中的每一个单元所能看到的原始图像范围是3*3，而由于Conv2的每个单元都是由 <img src="https://www.zhihu.com/equation?tex=2%5Ctimes2" alt="[公式]"> 范围的Conv1构成，因此回溯到原始图像，其实是能够看到 <img src="https://www.zhihu.com/equation?tex=5%5Ctimes5" alt="[公式]"> 的原始图像范围的。因此我们说Conv1的感受野是3，Conv2的感受野是5. 输入图像的每个单元的感受野被定义为1，这应该很好理解，因为每个像素只能看到自己。</p>
<p><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/20200303190423.png" alt=""></p>
<h3 id="感受野的计算"><a href="#感受野的计算" class="headerlink" title="感受野的计算"></a>感受野的计算</h3><p><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/20200303190604.png" alt=""></p>
<p>K：卷积核大小</p>
<p>P：填充块大小</p>
<p>S：步长</p>
<p>Layer：用Layer表示 (特征图)feature map，特别地Layer 0为输入图像</p>
<p>n：特征图的大小</p>
<p>r：感受野大小</p>
<p>j：特征图上相邻的像素距离，即：在特征图上前进1步相当于输入图像上前进多少个像素</p>
<p>如下图所示，feature map上前进1步，相当于输入图像上前进2个像素，𝑗=2</p>
<p><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/QH9BKH.gif" alt=""></p>
<p>start：在特征图左上角第一个像素在输入图像上的感受野中心坐标。</p>
<p>在上图中，左上角绿色块感受野中心坐标为(0.5,0.5)，即左上角蓝色块中心的坐标，左上角白色虚线块中心的坐标为(−0.5,−0.5)；</p>
<p>再看上面的动图，如果feature map Layer2 上的一个元素A看到feature map 𝐿𝑎𝑦𝑒𝑟 1上的范围为3×3（图中绿色块），其大小等于kernel size $𝑘_2$，所以，A看到的感受野范围$r_2$等价于Layer 1上3×3窗口看到的Layer 0 范围，据此可以建立起相邻Layer感受野的关系，如下所示，其中$r_{l-1}$为Layer l-1的感受野，$r_l−1$为Layer l−1 的感受野，<br>$$<br>𝑟_𝑙=𝑟_{𝑙−1}+(𝑘_𝑙−1)\times 𝑗_𝑙−1<br>$$</p>
<ul>
<li>𝐿𝑎𝑦𝑒𝑟 𝑙 一个元素的感受野𝑟𝑙等价于𝐿𝑎𝑦𝑒𝑟 𝑙−1上𝑘×𝑘个感受野的叠加；</li>
<li>𝐿𝑎𝑦𝑒𝑟 𝑙−1上一个元素的感受野为$r_{l−1}$；</li>
<li>𝐿𝑎𝑦𝑒𝑟 𝑙−1上连续𝑘k 个元素的感受野可以看成是，第1个元素看到的感受野加上剩余k−1步扫过的范围，𝐿𝑎𝑦𝑒𝑟 𝑙−1 上每前进1个元素相当于在输入图像上前进$𝑗_{𝑙−1}$个像素，结果等于$𝑟_{𝑙−1}+(𝑘−1)×𝑗_{𝑙−1}$</li>
</ul>
<p><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/20200303192216.png" alt=""></p>
<h3 id="感受野中心"><a href="#感受野中心" class="headerlink" title="感受野中心"></a>感受野中心</h3><p><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/20200303192254.png" alt=""></p>
<p><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/20200303192312.png" alt=""></p>
<p><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/20200303192334.png" alt=""></p>
<p><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/20200303192342.png" alt=""></p>
<p><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/20200303192452.png" alt=""></p>
<h3 id="感受野小结"><a href="#感受野小结" class="headerlink" title="感受野小结"></a>感受野小结</h3><p><img src="https://gowi-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/20200303192510.png" alt=""></p>
<h2 id="关于卷积神经网络的部分代码"><a href="#关于卷积神经网络的部分代码" class="headerlink" title="关于卷积神经网络的部分代码"></a>关于卷积神经网络的部分代码</h2><h3 id="二维卷积"><a href="#二维卷积" class="headerlink" title="二维卷积"></a>二维卷积</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">corr2d</span><span class="params">(X, K)</span>:</span>  </span><br><span class="line">    h, w = K.shape</span><br><span class="line">    Y = torch.zeros((X.shape[<span class="number">0</span>] - h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - w + <span class="number">1</span>)) <span class="comment"># 卷积输出的图像大小</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br></pre></td></tr></table></figure>

<h3 id="多输入通道"><a href="#多输入通道" class="headerlink" title="多输入通道"></a>多输入通道</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">corr2d_multi_in</span><span class="params">(X,K)</span>:</span></span><br><span class="line">    <span class="comment"># 沿着X和K的第0维（通道维）分别计算再相加</span></span><br><span class="line">    res = corr2d(X[<span class="number">0</span>, :, :], K[<span class="number">0</span>, :, :])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, X.shape[<span class="number">0</span>]):</span><br><span class="line">        res += corr2d(X[i, :, :], K[i, :, :])</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line">X = torch.tensor([[[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], </span><br><span class="line">                   [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">                   [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]],</span><br><span class="line">                  [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">                   [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>],</span><br><span class="line">                   [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]]])</span><br><span class="line">K = torch.tensor([[[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">                   [<span class="number">2</span>, <span class="number">3</span>]],</span><br><span class="line">                  [[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">                   [<span class="number">3</span>, <span class="number">4</span>]]])</span><br><span class="line"></span><br><span class="line">print(X.size())</span><br><span class="line">print(K.size())</span><br><span class="line">print(corr2d_multi_in(X, K))</span><br><span class="line">print([k <span class="keyword">for</span> k <span class="keyword">in</span> K])</span><br></pre></td></tr></table></figure>

<h3 id="多输出通道"><a href="#多输出通道" class="headerlink" title="多输出通道"></a>多输出通道</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">corr2d_multi_in_out</span><span class="params">(X, K)</span>:</span></span><br><span class="line">    <span class="comment"># 对K的第0维遍历，每次同输入X做互相关计算。所有结果使用stack函数合并在一起</span></span><br><span class="line">    <span class="keyword">return</span> torch.stack([corr2d_multi_in(X, k) <span class="keyword">for</span> k <span class="keyword">in</span> K])</span><br><span class="line"></span><br><span class="line">K=torch.stack([K,K+<span class="number">1</span>,K+<span class="number">2</span>])</span><br><span class="line">print(K.shape)</span><br><span class="line"></span><br><span class="line">print(corr2d_multi_in_out(X,K))</span><br></pre></td></tr></table></figure>

<h3 id="1x1卷积层"><a href="#1x1卷积层" class="headerlink" title="1x1卷积层"></a>1x1卷积层</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">corr2d_multi_in_out_1x1</span><span class="params">(X,K)</span>:</span></span><br><span class="line">    c_i,h,w=X.shape</span><br><span class="line">    c_o=K.shape[<span class="number">0</span>]</span><br><span class="line">    X=X.view(c_i,h*w)</span><br><span class="line">    print(<span class="string">'X.view('</span>,c_i,<span class="string">','</span>,h*w,<span class="string">'):\n'</span>,X)</span><br><span class="line">    K=K.view(c_o,c_i)</span><br><span class="line">    print(<span class="string">'K.view('</span>,c_o,<span class="string">','</span>,c_i,<span class="string">'):\n'</span>,K)</span><br><span class="line">    Y=torch.mm(K,X)</span><br><span class="line">    <span class="keyword">return</span> Y.view(c_o,h,w)</span><br><span class="line">    </span><br><span class="line">X=torch.rand(<span class="number">3</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">K=torch.rand(<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'X:\n'</span>,X)</span><br><span class="line">print(X.size())</span><br><span class="line">print(<span class="string">'K:\n'</span>,K)</span><br><span class="line">print(K.size())</span><br><span class="line"></span><br><span class="line">Y1=corr2d_multi_in_out_1x1(X,K)</span><br><span class="line">Y2=corr2d_multi_in_out(X,K)</span><br><span class="line"></span><br><span class="line">print((Y1-Y2).norm().item()&lt;<span class="number">1e-6</span>)</span><br></pre></td></tr></table></figure>

<h3 id="最大池化层和ping"><a href="#最大池化层和ping" class="headerlink" title="最大池化层和ping"></a>最大池化层和ping</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pool2d</span><span class="params">(X, pool_size, mode=<span class="string">'max'</span>)</span>:</span></span><br><span class="line">    X=X.float()</span><br><span class="line">    p_w,p_h=pool_size</span><br><span class="line">    Y=torch.zeros(X.shape[<span class="number">0</span>]-p_h+<span class="number">1</span>,X.shape[<span class="number">1</span>]-p_w+<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            <span class="keyword">if</span> mode==<span class="string">'max'</span>:</span><br><span class="line">                Y[i,j]=X[i:i+p_h,j:j+p_w].max()</span><br><span class="line">            <span class="keyword">if</span> mode==<span class="string">'avg'</span>:</span><br><span class="line">                Y[i,j]=X[i:i+p_h,j:j+p_w].mean()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br><span class="line"></span><br><span class="line">X=torch.tensor([[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">                [<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>],</span><br><span class="line">                [<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>]])</span><br><span class="line">print(pool2d(X,(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">print(pool2d(X,(<span class="number">2</span>,<span class="number">2</span>),mode=<span class="string">'avg'</span>))</span><br></pre></td></tr></table></figure>

<h3 id="填充和步幅"><a href="#填充和步幅" class="headerlink" title="填充和步幅"></a>填充和步幅</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x=torch.arange(<span class="number">16</span>).view(<span class="number">1</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure>

<h3 id="Lenet-5-1"><a href="#Lenet-5-1" class="headerlink" title="Lenet-5"></a>Lenet-5</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LeNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(LeNet,self).__init__()</span><br><span class="line">        self.conv=nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, <span class="number">5</span>), <span class="comment"># in_channels, out_channels, kernel_size</span></span><br><span class="line">            nn.Sigmoid(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>), <span class="comment"># kernel_size, stride</span></span><br><span class="line">            nn.Conv2d(<span class="number">6</span>,<span class="number">16</span>,<span class="number">5</span>),</span><br><span class="line">            nn.Sigmoid(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">        )</span><br><span class="line">        self.fc=nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">16</span>*<span class="number">4</span>*<span class="number">4</span>,<span class="number">120</span>),</span><br><span class="line">            nn.Sigmoid(),</span><br><span class="line">            nn.Linear(<span class="number">120</span>,<span class="number">84</span>),</span><br><span class="line">            nn.Sigmoid(),</span><br><span class="line">            nn.Linear(<span class="number">84</span>,<span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, img)</span>:</span></span><br><span class="line">        feature=self.conv(img)</span><br><span class="line">        output=self.fc(feature.view(img.shape[<span class="number">0</span>],<span class="number">-1</span>))</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net=LeNet()</span><br><span class="line">print(net)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data_fashion_mnist</span><span class="params">(batch_size, resize=None, root=<span class="string">'./data'</span>)</span>:</span></span><br><span class="line">    <span class="string">"""Download the fashion mnist dataset and then load into memory."""</span></span><br><span class="line">    trans = []</span><br><span class="line">    <span class="keyword">if</span> resize:</span><br><span class="line">        trans.append(torchvision.transforms.Resize(size=resize))</span><br><span class="line">    trans.append(torchvision.transforms.ToTensor()) <span class="comment"># 将PIL image或numpy.darray 转化成tensor</span></span><br><span class="line"></span><br><span class="line">    transform = torchvision.transforms.Compose(trans)</span><br><span class="line">    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line"></span><br><span class="line">    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=<span class="literal">True</span>, num_workers=<span class="number">4</span>)</span><br><span class="line">    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=<span class="literal">False</span>, num_workers=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_iter, test_iter</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">128</span></span><br><span class="line"><span class="comment"># 如出现“out of memory”的报错信息，可减小batch_size或resize</span></span><br><span class="line">train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=<span class="number">224</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">train_iter, test_iter = load_data_fashion_mnist(batch_size=batch_size)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span><span class="params">(data_iter, net, device=None)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> device <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> isinstance(net, torch.nn.Module):</span><br><span class="line">        <span class="comment"># 如果没指定device就使用net的device</span></span><br><span class="line">        device = list(net.parameters())[<span class="number">0</span>].device</span><br><span class="line">    acc_sum, n = <span class="number">0.0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">            <span class="keyword">if</span> isinstance(net, torch.nn.Module):</span><br><span class="line">                net.eval() <span class="comment"># 评估模式, 这会关闭dropout</span></span><br><span class="line">                acc_sum += (net(X.to(device)).argmax(dim=<span class="number">1</span>) == y.to(device)).float().sum().cpu().item()</span><br><span class="line">                net.train() <span class="comment"># 改回训练模式</span></span><br><span class="line">            <span class="keyword">else</span>: </span><br><span class="line">                <span class="keyword">if</span>(<span class="string">'is_training'</span> <span class="keyword">in</span> net.__code__.co_varnames): <span class="comment"># 如果有is_training这个参数</span></span><br><span class="line">                    <span class="comment"># 将is_training设置成False</span></span><br><span class="line">                    acc_sum += (net(X, is_training=<span class="literal">False</span>).argmax(dim=<span class="number">1</span>) == y).float().sum().item() </span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    acc_sum += (net(X).argmax(dim=<span class="number">1</span>) == y).float().sum().item() </span><br><span class="line">            n += y.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> acc_sum / n</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_ch5</span><span class="params">(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)</span>:</span></span><br><span class="line">    net = net.to(device)</span><br><span class="line">    print(<span class="string">"training on "</span>, device)</span><br><span class="line">    loss = torch.nn.CrossEntropyLoss()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">        train_l_sum, train_acc_sum, n, batch_count, start = <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0</span>, <span class="number">0</span>, time.time()</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            X = X.to(device)</span><br><span class="line">            y = y.to(device)</span><br><span class="line">            y_hat = net(X)</span><br><span class="line">            l = loss(y_hat, y)</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            l.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            train_l_sum += l.cpu().item()</span><br><span class="line">            train_acc_sum += (y_hat.argmax(dim=<span class="number">1</span>) == y).sum().cpu().item()</span><br><span class="line">            n += y.shape[<span class="number">0</span>]</span><br><span class="line">            batch_count += <span class="number">1</span></span><br><span class="line">        test_acc = evaluate_accuracy(test_iter, net)</span><br><span class="line">        print(<span class="string">'epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'</span></span><br><span class="line">              % (epoch + <span class="number">1</span>, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lr, num_epochs = <span class="number">0.001</span>, <span class="number">5</span></span><br><span class="line">optimizer = torch.optim.Adam(net.parameters(), lr=lr)</span><br><span class="line">train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)</span><br></pre></td></tr></table></figure>


      </div>
	  
            <! -- 添加版权信息 -->
<div class="article-footer-copyright">
<center>本文由<b><a href="/index.html" target="_blank" title="AIR@USC">AIR@USC</a></b>创作和发表,采用<b>BY</b>-<b>NC</b>-<b>SA</b>国际许可协议进行许可</center>
 
<center>转载请注明作者及出处,本文作者为<b><a href="/index.html" target="_blank" title="AIR@USC">AIR@USC</a></b>,本文标题为<b><a href="/2020/03/15/从Lentet-5看CNN/" target="_blank" title="从Lentet-5看CNN">从Lentet-5看CNN</a></b></center>
 
<center>本文链接为<b><a href="/2020/03/15/从Lentet-5看CNN/" target="_blank" title="从Lentet-5看CNN">http://uscair.club/2020/03/15/从Lentet-5看CNN/</a></b>.</center>
</div>
<! -- 添加版权信息 -->
        
      
      
        <br>
        


  <section class='meta' id="footer-meta">
    <div class='new-meta-box'>
      
        
          <div class="new-meta-item date" itemprop="dateUpdated" datetime="2020-03-15T00:00:00+08:00">
  <a class='notlink'>
    <i class="fas fa-clock" aria-hidden="true"></i>
    <p>updated at Mar 15, 2020</p>
  </a>
</div>

        
      
        
          
  
  <div class="new-meta-item meta-tags"><a class="tag" href="/tags/CNN/" rel="nofollow"><i class="fas fa-tag" aria-hidden="true"></i><p>CNN</p></a></div>


        
      
        
          
  <div class="new-meta-item share -mob-share-list">
  <div class="-mob-share-list share-body">
    
      
        <a class="-mob-share-qq" title="QQ好友" rel="external nofollow noopener noreferrer"
          
          href="http://connect.qq.com/widget/shareqq/index.html?url=http://uscair.club/2020/03/15/%E4%BB%8ELentet-5%E7%9C%8BCNN/&title=从Lentet-5看CNN | AIR&summary="
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/qq.png">
          
        </a>
      
    
      
        <a class="-mob-share-qzone" title="QQ空间" rel="external nofollow noopener noreferrer"
          
          href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=http://uscair.club/2020/03/15/%E4%BB%8ELentet-5%E7%9C%8BCNN/&title=从Lentet-5看CNN | AIR&summary="
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/qzone.png">
          
        </a>
      
    
      
        <a class="-mob-share-weibo" title="微博" rel="external nofollow noopener noreferrer"
          
          href="http://service.weibo.com/share/share.php?url=http://uscair.club/2020/03/15/%E4%BB%8ELentet-5%E7%9C%8BCNN/&title=从Lentet-5看CNN | AIR&summary="
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/weibo.png">
          
        </a>
      
    
  </div>
</div>



        
      
    </div>
  </section>


      
      
          <div class="prev-next">
              
                  <section class="prev">
                      <span class="art-item-left">
                          <h6><i class="fas fa-chevron-left" aria-hidden="true"></i>&nbsp;Previous</h6>
                          <h4>
                              <a href="/2020/03/15/K-means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/" rel="prev" title="K-means聚类算法">
                                
                                    K-means聚类算法
                                
                              </a>
                          </h4>
                          
                              
                              <h6 class="tags">
                                  <a class="tag" href="/tags/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> 聚类算法</a>
                              </h6>
                          
                      </span>
                  </section>
              
              
                  <section class="next">
                      <span class="art-item-right" aria-hidden="true">
                          <h6>Next&nbsp;<i class="fas fa-chevron-right" aria-hidden="true"></i></h6>
                          <h4>
                              <a href="/2020/03/14/spyderd%E7%9A%84%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/" rel="prev" title="spyderd的简单使用">
                                  
                                      spyderd的简单使用
                                  
                              </a>
                          </h4>
                          
                      </span>
                  </section>
              
          </div>
      
    </section>
  </article>



  <!-- 显示推荐文章和评论 -->



  <article class="post white-box comments">
    <section class="article typo">
      <h4><i class="fas fa-comments fa-fw" aria-hidden="true"></i>&nbsp;Comments</h4>
      
      
        <section id="comments">
          <div id="lv-container" data-id="city" data-uid="MTAyMC80ODI4NC8yNDc3OA==">
            <noscript><div><i class='fas fa-exclamation-triangle'>&nbsp;Unable to load Livere, please make sure your network can access.</div></noscript>
          </div>
        </section>
      
      
      
    </section>
  </article>






<!-- 根据页面mathjax变量决定是否加载MathJax数学公式js -->

  <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": {
      preferredFont: "TeX",
      availableFonts: ["STIX","TeX"],
      linebreaks: { automatic:true },
      EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
      inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
      processEscapes: true,
      ignoreClass: "tex2jax_ignore|dno",
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: { autoNumber: "AMS" },
      noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
      Macros: { href: "{}" }
    },
    messageStyle: "none"
  });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += (all[i].SourceElement().parentNode.className ? ' ' : '') + 'has-jax';
    }
  });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>




  <script>
    window.subData = {
      title: '从Lentet-5看CNN',
      tools: true
    }
  </script>


</div>
<aside class='l_side'>
  
    
    
      
      
        
          
          
            
              <section class='widget author'>
  <div class='content pure'>
    
	<a href="https://github.com/AIRUSC" target="_blank" rel="noopener" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
      <div class='avatar'>
        <img class='avatar' src='https://img.vim-cn.com/b5/c85ca5730c5889d433b1d0958d0d1d0b478687.png'/>
      </div>
    
    
      <div class='text'>
        
        
        
          <p><span id="jinrishici-sentence">AIR</span></p>
          <script src="https://sdk.jinrishici.com/v2/browser/jinrishici.js" charset="utf-8"></script>
        
      </div>
    
    
      <div class="social-wrapper">
        
          
            <a href="/atom.xml"
              class="social fas fa-rss flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
            </a>
          
        
          
            <a href="mailto:airusc@foxmail.com"
              class="social fas fa-envelope flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
            </a>
          
        
          
            <a href="https://github.com/AIRUSC"
              class="social fab fa-github flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
            </a>
          
        
      </div>
    
	<hr/>
	<font color="#2EF0FF" >&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;访客地图 </font>
  </div>
  <script type="text/javascript" src="//rf.revolvermaps.com/0/0/6.js?i=597ckzulxto&amp;m=7&amp;c=e63100&amp;cr1=ffffff&amp;f=arial&amp;l=0&amp;bv=90&amp;lx=-420&amp;ly=420&amp;hi=20&amp;he=7&amp;hc=a8ddff&amp;rs=80" async="async"></script>
</section>

            
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
      
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
      
        
          
          
        
          
          
            
              
  <section class='widget toc-wrapper'>
    
<header class='pure'>
  <div><i class="fas fa-list fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;TOC</div>
  
    <!-- <div class='wrapper'><a class="s-toc rightBtn" rel="external nofollow noopener noreferrer" href="javascript:void(0)"><i class="fas fa-thumbtack fa-fw"></i></a></div> -->
  
</header>

    <div class='content pure'>
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#卷积"><span class="toc-text">卷积</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#卷积神经网络的结构"><span class="toc-text">卷积神经网络的结构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#输入层"><span class="toc-text">输入层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#卷积层"><span class="toc-text">卷积层</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#局部感知野"><span class="toc-text">局部感知野</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#权值共享"><span class="toc-text">权值共享</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#池化层"><span class="toc-text">池化层</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Lenet-5"><span class="toc-text">Lenet-5</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#卷积神经网络关于感受野的计算"><span class="toc-text">卷积神经网络关于感受野的计算</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#什么是感受野"><span class="toc-text">什么是感受野</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#感受野的计算"><span class="toc-text">感受野的计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#感受野中心"><span class="toc-text">感受野中心</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#感受野小结"><span class="toc-text">感受野小结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#关于卷积神经网络的部分代码"><span class="toc-text">关于卷积神经网络的部分代码</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#二维卷积"><span class="toc-text">二维卷积</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#多输入通道"><span class="toc-text">多输入通道</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#多输出通道"><span class="toc-text">多输出通道</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1x1卷积层"><span class="toc-text">1x1卷积层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#最大池化层和ping"><span class="toc-text">最大池化层和ping</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#填充和步幅"><span class="toc-text">填充和步幅</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Lenet-5-1"><span class="toc-text">Lenet-5</span></a></li></ol></li></ol>
    </div>
  </section>


            
          
        
          
          
        
          
          
        
          
          
        
          
          
        
      
        
          
          
        
          
          
        
          
          
            
              <section class='widget grid'>
  
<header class='pure'>
  <div><i class="fas fa-map-signs fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;站内导航</div>
  
</header>

  <div class='content pure'>
    <ul class="grid navgation">
      
        <li><a class="flat-box" title="/" href="/"
          
          
          id="home">
          
            <i class="fas fa-clock fa-fw" aria-hidden="true"></i>
          
          近期文章
        </a></li>
      
        <li><a class="flat-box" title="/archives/" href="/archives/"
          
            rel="nofollow"
          
          
          id="archives">
          
            <i class="fas fa-archive fa-fw" aria-hidden="true"></i>
          
          文章归档
        </a></li>
      
        <li><a class="flat-box" title="https://xaoxuu.com/wiki/material-x/" href="https://xaoxuu.com/wiki/material-x/"
          
            rel="nofollow"
          
          
          id="https:xaoxuu.comwikimaterial-x">
          
            <i class="fas fa-book fa-fw" aria-hidden="true"></i>
          
          主题文档
        </a></li>
      
        <li><a class="flat-box" title="/about/" href="/about/"
          
            rel="nofollow"
          
          
          id="about">
          
            <i class="fas fa-info-circle fa-fw" aria-hidden="true"></i>
          
          关于小站
        </a></li>
      
    </ul>
  </div>
</section>

            
          
        
          
          
        
          
          
        
          
          
        
      
        
          
          
        
          
          
        
          
          
        
          
          
            
              
  <section class='widget category'>
    
<header class='pure'>
  <div><i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;Categories</div>
  
    <a class="rightBtn"
    
      rel="nofollow"
    
    
    href="/blog/categories/"
    title="blog/categories/">
    <i class="fas fa-expand-arrows-alt fa-fw"></i></a>
  
</header>

    <div class='content pure'>
      <ul class="entry">
        
          <li><a class="flat-box" title="/categories/C/" href="/categories/C/"><div class='name'>C++</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Hexo/" href="/categories/Hexo/"><div class='name'>Hexo</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/NAO/" href="/categories/NAO/"><div class='name'>NAO</div><div class='badge'>(4)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Naoqi/" href="/categories/Naoqi/"><div class='name'>Naoqi</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Python/" href="/categories/Python/"><div class='name'>Python</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Python%E7%BC%96%E7%A8%8B/" href="/categories/Python%E7%BC%96%E7%A8%8B/"><div class='name'>Python编程</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/openCV/" href="/categories/openCV/"><div class='name'>openCV</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/openCV/%E5%9B%BE%E7%89%87%E5%8F%98%E5%8C%96/" href="/categories/openCV/%E5%9B%BE%E7%89%87%E5%8F%98%E5%8C%96/"><div class='name'>图片变化</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box" title="/categories/python/" href="/categories/python/"><div class='name'>python</div><div class='badge'>(3)</div></a></li>
        
          <li><a class="flat-box" title="/categories/python%E5%9F%BA%E7%A1%80/" href="/categories/python%E5%9F%BA%E7%A1%80/"><div class='name'>python基础</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/test/" href="/categories/test/"><div class='name'>test</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"><div class='name'>人工智能</div><div class='badge'>(5)</div></a></li>
        
          <li><a class="flat-box" title="/categories/%E5%8D%95%E7%89%87%E6%9C%BA/" href="/categories/%E5%8D%95%E7%89%87%E6%9C%BA/"><div class='name'>单片机</div><div class='badge'>(3)</div></a></li>
        
          <li><a class="flat-box" title="/categories/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" href="/categories/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"><div class='name'>数字图像处理</div><div class='badge'>(9)</div></a></li>
        
          <li><a class="flat-box" title="/categories/%E6%99%BA%E8%83%BD%E7%AE%97%E6%B3%95/" href="/categories/%E6%99%BA%E8%83%BD%E7%AE%97%E6%B3%95/"><div class='name'>智能算法</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><div class='name'>机器学习</div><div class='badge'>(17)</div></a></li>
        
          <li><a class="flat-box" title="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%93%E6%A0%8F/" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%93%E6%A0%8F/"><div class='name'>机器学习专栏</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><div class='name'>深度学习</div><div class='badge'>(3)</div></a></li>
        
          <li><a class="flat-box" title="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E6%A0%8F/" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E6%A0%8F/"><div class='name'>深度学习专栏</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" href="/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><div class='name'>神经网络</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box" title="/categories/%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86/" href="/categories/%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86/"><div class='name'>网络原理</div><div class='badge'>(3)</div></a></li>
        
      </ul>
    </div>
  </section>


            
          
        
          
          
        
          
          
        
      
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
            
              
  <section class='widget tagcloud'>
    
<header class='pure'>
  <div><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;Hot Tags</div>
  
    <a class="rightBtn"
    
      rel="nofollow"
    
    
    href="/blog/tags/"
    title="blog/tags/">
    <i class="fas fa-expand-arrows-alt fa-fw"></i></a>
  
</header>

    <div class='content pure'>
      <a href="/tags/AI%E5%A4%A7%E6%95%B0%E6%8D%AE/" style="font-size: 19px; color: #777">AI大数据</a> <a href="/tags/CNN/" style="font-size: 20.67px; color: #6c6c6c">CNN</a> <a href="/tags/DNN/" style="font-size: 14px; color: #999">DNN</a> <a href="/tags/NAOqi/" style="font-size: 17.33px; color: #828282">NAOqi</a> <a href="/tags/Naoqi%E6%9C%BA%E5%99%A8%E4%BA%BA/" style="font-size: 14px; color: #999">Naoqi机器人</a> <a href="/tags/Numpy/" style="font-size: 14px; color: #999">Numpy</a> <a href="/tags/OpenCV/" style="font-size: 22.33px; color: #606060">OpenCV</a> <a href="/tags/Python/" style="font-size: 20.67px; color: #6c6c6c">Python</a> <a href="/tags/Pytorh/" style="font-size: 15.67px; color: #8e8e8e">Pytorh</a> <a href="/tags/STM32/" style="font-size: 14px; color: #999">STM32</a> <a href="/tags/STM32F407/" style="font-size: 15.67px; color: #8e8e8e">STM32F407</a> <a href="/tags/TensorFlow/" style="font-size: 15.67px; color: #8e8e8e">TensorFlow</a> <a href="/tags/robocup/" style="font-size: 14px; color: #999">robocup</a> <a href="/tags/test/" style="font-size: 14px; color: #999">test</a> <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" style="font-size: 14px; color: #999">人工智能</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" style="font-size: 14px; color: #999">图像处理</a> <a href="/tags/%E5%9B%BE%E7%89%87%E5%8F%98%E5%8C%96/" style="font-size: 14px; color: #999">图片变化</a> <a href="/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/" style="font-size: 14px; color: #999">多线程</a> <a href="/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/" style="font-size: 14px; color: #999">字符串</a> <a href="/tags/%E5%B0%8F%E7%99%BD%E5%AD%A6%E4%B9%A0/" style="font-size: 14px; color: #999">小白学习</a> <a href="/tags/%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF/" style="font-size: 14px; color: #999">拉普拉斯</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E9%9B%86%E9%A2%84%E5%A4%84%E7%90%86/" style="font-size: 15.67px; color: #8e8e8e">数据集预处理</a> <a href="/tags/%E6%95%B0%E7%90%86%E5%9F%BA%E7%A1%80/" style="font-size: 14px; color: #999">数理基础</a> <a href="/tags/%E6%96%87%E4%BB%B6/" style="font-size: 14px; color: #999">文件</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" style="font-size: 24px; color: #555">机器学习基础</a> <a href="/tags/%E6%A8%A1%E6%9D%BF/" style="font-size: 14px; color: #999">模板</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 15.67px; color: #8e8e8e">神经网络</a> <a href="/tags/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/" style="font-size: 14px; color: #999">算法学习</a> <a href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" style="font-size: 14px; color: #999">线性回归</a> <a href="/tags/%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86/" style="font-size: 17.33px; color: #828282">网络原理</a> <a href="/tags/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/" style="font-size: 17.33px; color: #828282">聚类算法</a>
    </div>
  </section>


            
          
        
          
          
        
      
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
      
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
      
    

  
</aside>

<footer id="footer" class="clearfix">
  
  
    <div class="social-wrapper">
      
        
          <a href="/atom.xml"
            class="social fas fa-rss flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
        
          <a href="mailto:airusc@foxmail.com"
            class="social fas fa-envelope flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
        
          <a href="https://github.com/AIRUSC"
            class="social fab fa-github flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
    </div>
  
  <br>
  <div><p>Blog content follows the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener">Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License</a></p>
</div>
  <div>
    Use
    <a href="https://xaoxuu.com/wiki/material-x/" target="_blank" class="codename">Material X</a>
    as theme
    
      , 
      total visits
      <span id="busuanzi_value_site_pv"><i class="fas fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span>
      times
    
    . 
  </div>
  
  <span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span>
<script>
    var now = new Date(); 
    function createtime() { 
        var grt= new Date("01/13/2020 16:36:00");//在此处修改你的建站时间，格式：月/日/年 时:分:秒
        now.setTime(now.getTime()+250); 
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); 
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); 
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); 
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;} 
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); 
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;} 
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 "; 
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒"; 
    } 
setInterval("createtime()",250);
</script>
  
</footer>
<script>setLoadingBarProgress(80);</script>



      <script>setLoadingBarProgress(60);</script>
    </div>
    <a class="s-top fas fa-arrow-up fa-fw" href='javascript:void(0)'></a>
  </div>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>

  <script>
    var GOOGLE_CUSTOM_SEARCH_API_KEY = "";
    var GOOGLE_CUSTOM_SEARCH_ENGINE_ID = "";
    var ALGOLIA_API_KEY = "";
    var ALGOLIA_APP_ID = "";
    var ALGOLIA_INDEX_NAME = "";
    var AZURE_SERVICE_NAME = "";
    var AZURE_INDEX_NAME = "";
    var AZURE_QUERY_KEY = "";
    var BAIDU_API_ID = "";
    var SEARCH_SERVICE = "hexo" || "hexo";
    var ROOT = "/"||"/";
    if(!ROOT.endsWith('/'))ROOT += '/';
  </script>

<script src="//instant.page/1.2.2" type="module" integrity="sha384-2xV8M5griQmzyiY3CDqh1dn4z3llDVqZDqzjzcY+jCBCk/a5fXJmuZ/40JJAPeoU"></script>


  <script async src="https://cdn.jsdelivr.net/npm/scrollreveal@4.0.5/dist/scrollreveal.min.js"></script>
  <script type="text/javascript">
    $(function() {
      const $reveal = $('.reveal');
      if ($reveal.length === 0) return;
      const sr = ScrollReveal({ distance: 0 });
      sr.reveal('.reveal');
    });
  </script>


  <script src="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.js"></script>
  <script type="text/javascript">
    $(function() {
      Waves.attach('.flat-btn', ['waves-button']);
      Waves.attach('.float-btn', ['waves-button', 'waves-float']);
      Waves.attach('.float-btn-light', ['waves-button', 'waves-float', 'waves-light']);
      Waves.attach('.flat-box', ['waves-block']);
      Waves.attach('.float-box', ['waves-block', 'waves-float']);
      Waves.attach('.waves-image');
      Waves.init();
    });
  </script>


  <script async src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-busuanzi@2.3/js/busuanzi.pure.mini.js"></script>




  
  
  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-backstretch/2.0.4/jquery.backstretch.min.js"></script>
    <script type="text/javascript">
      $(function(){
        if ('.cover') {
          $('.cover').backstretch(
          ["http://gss0.baidu.com/-fo3dSag_xI4khGko9WTAnF6hhy/zhidao/pic/item/00e93901213fb80e3db9657d31d12f2eb938942b.jpg"],
          {
            duration: "6000",
            fade: "2500"
          });
        } else {
          $.backstretch(
          ["http://gss0.baidu.com/-fo3dSag_xI4khGko9WTAnF6hhy/zhidao/pic/item/00e93901213fb80e3db9657d31d12f2eb938942b.jpg"],
          {
            duration: "6000",
            fade: "2500"
          });
        }
      });
    </script>
  






  <script type="text/javascript">
    (function(d, s) {
      var j, e = d.getElementsByTagName(s)[0];
      if (typeof LivereTower === 'function') { return; }
      j = d.createElement(s);
      j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
      j.async = true;
      e.parentNode.insertBefore(j, e);
    })(document, 'script');
  </script>






  
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@19.11/js/app.js"></script>



  
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@19.11/js/search.js"></script>





<!-- 复制 -->
<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  let COPY_SUCCESS = "Copied";
  let COPY_FAILURE = "Copy failed";
  /*页面载入完成后，创建复制按钮*/
  !function (e, t, a) {
    /* code */
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '  <i class="fa fa-copy"></i><span>Copy</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });

      clipboard.on('success', function(e) {
        //您可以加入成功提示
        console.info('Action:', e.action);
        console.info('Text:', e.text);
        console.info('Trigger:', e.trigger);
        success_prompt(COPY_SUCCESS);
        e.clearSelection();
      });
      clipboard.on('error', function(e) {
        //您可以加入失败提示
        console.error('Action:', e.action);
        console.error('Trigger:', e.trigger);
        fail_prompt(COPY_FAILURE);
      });
    }
    initCopyCode();

  }(window, document);

  /**
   * 弹出式提示框，默认1.5秒自动消失
   * @param message 提示信息
   * @param style 提示样式，有alert-success、alert-danger、alert-warning、alert-info
   * @param time 消失时间
   */
  var prompt = function (message, style, time)
  {
      style = (style === undefined) ? 'alert-success' : style;
      time = (time === undefined) ? 1500 : time*1000;
      $('<div>')
          .appendTo('body')
          .addClass('alert ' + style)
          .html(message)
          .show()
          .delay(time)
          .fadeOut();
  };

  // 成功提示
  var success_prompt = function(message, time)
  {
      prompt(message, 'alert-success', time);
  };

  // 失败提示
  var fail_prompt = function(message, time)
  {
      prompt(message, 'alert-danger', time);
  };

  // 提醒
  var warning_prompt = function(message, time)
  {
      prompt(message, 'alert-warning', time);
  };

  // 信息提示
  var info_prompt = function(message, time)
  {
      prompt(message, 'alert-info', time);
  };

</script>


<!-- fancybox -->
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script>
  let LAZY_LOAD_IMAGE = "";
  $(".article-entry").find("fancybox").find("img").each(function () {
      var element = document.createElement("a");
      $(element).attr("data-fancybox", "gallery");
      $(element).attr("href", $(this).attr("src"));
      /* 图片采用懒加载处理时,
       * 一般图片标签内会有个属性名来存放图片的真实地址，比如 data-original,
       * 那么此处将原本的属性名src替换为对应属性名data-original,
       * 修改如下
       */
       if (LAZY_LOAD_IMAGE) {
         $(element).attr("href", $(this).attr("data-original"));
       }
      $(this).wrap(element);
  });
</script>





  <script>setLoadingBarProgress(100);</script>
  
  <canvas id="canvas" width="1440" height="900" ></canvas>
<script>
	window.onload = function(){
    //获取画布对象
    var canvas = document.getElementById("canvas");
    //获取画布的上下文
    var context =canvas.getContext("2d");
    var s = window.screen;
    var W = canvas.width = s.width;
    var H = canvas.height;
    //获取浏览器屏幕的宽度和高度
    //var W = window.innerWidth;
    //var H = window.innerHeight;
    //设置canvas的宽度和高度
    canvas.width = W;
    canvas.height = H;
    //每个文字的字体大小
    var fontSize = 12;
    //计算列
    var colunms = Math.floor(W /fontSize);	
    //记录每列文字的y轴坐标
    var drops = [];
    //给每一个文字初始化一个起始点的位置
    for(var i=0;i<colunms;i++){
        drops.push(0);
    }
    //运动的文字
    var str ="WELCOME TO SH.ITRHX.COM";
    //4:fillText(str,x,y);原理就是去更改y的坐标位置
    //绘画的函数
    function draw(){
        context.fillStyle = "rgba(238,238,238,.08)";//遮盖层
        context.fillRect(0,0,W,H);
        //给字体设置样式
        context.font = "600 "+fontSize+"px  Georgia";
        //给字体添加颜色
        context.fillStyle = ["#2EF0FF", "#2EF0FF", "#2EF0FF", "#2EF0FF", "#2EF0FF", "#2EF0FF", "#2EF0FF", "#2EF0FF", "#2EF0FF", "#2EF0FF"][parseInt(Math.random() * 10)];//randColor();可以rgb,hsl, 标准色，十六进制颜色
        //写入画布中
        for(var i=0;i<colunms;i++){
            var index = Math.floor(Math.random() * str.length);
            var x = i*fontSize;
            var y = drops[i] *fontSize;
            context.fillText(str[index],x,y);
            //如果要改变时间，肯定就是改变每次他的起点
            if(y >= canvas.height && Math.random() > 0.99){
                drops[i] = 0;
            }
            drops[i]++;
        }
    };
    function randColor(){//随机颜色
        var r = Math.floor(Math.random() * 256);
        var g = Math.floor(Math.random() * 256);
        var b = Math.floor(Math.random() * 256);
        return "rgb("+r+","+g+","+b+")";
    }
    draw();
    setInterval(draw,35);
};
</script>
  
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/miku.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7}});</script></body>
<script type='text/javascript' src='/js/DaoVoice.js'></script>

<!--彩带2.自动飘动-->

    <!-- <script src="https://g.joyinshare.com/hc/piao.js" type="text/javascript"></script> -->
    <script type="text/javascript" src="/js/ribbon_flow.js"></script>


<!--动态线条背景-->
<!--<script type="text/javascript"-->
<!--color="56,239,243" opacity='0.9' zIndex="-2" count="200" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js">-->
<!--</script>-->
</html>
